{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91548549-f872-4a66-baef-f87a396c44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6328b747-55c9-4edc-80a2-b5639f0be74e",
   "metadata": {
    "id": "6cdpG2ZoV1ig"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "\n",
    "TRAIN_DIR = f'{DATA_DIR}/train'\n",
    "TEST_DIR = f'{DATA_DIR}/test'\n",
    "\n",
    "PLOTS_DIR = f'{DATA_DIR}/plots'\n",
    "\n",
    "OUTPUT_DIR = f'{DATA_DIR}/output'\n",
    "MODEL_CHECKPOINT_DIR = f'{DATA_DIR}/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582aecf4-5edb-4873-bf6f-283408af4214",
   "metadata": {},
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12be5e-18a3-41a1-8edf-1c11d355aa5c",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ac5e40-0217-46dc-b9c1-dbc2e041e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = pd.read_csv(f'{TRAIN_DIR}/Train.csv')\n",
    "desc = pd.read_csv(f'{DATA_DIR}/DataDictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3225aa83-9537-4413-890b-356368f581d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CAT = desc[36:]['Column Name'].tolist()\n",
    "train_df = train.drop(columns=CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c6953e-bc77-4002-817d-28998d1ca0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil.preprocessing import FossilPreprocessor, LabelEncoder\n",
    "from fossil.config import ModelsConfig\n",
    "\n",
    "np.random.seed(ModelsConfig.SEED)\n",
    "sku_encoder = LabelEncoder(train.sku_name.sample(frac=0.95, random_state=ModelsConfig.SEED).unique())\n",
    "\n",
    "fossil_preproc = FossilPreprocessor(sku_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baba318f-5ce5-47d4-bc62-8b5c552191b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fcfe81fe6b4253a5e5fbda3fc61599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bc09fb73cb46bf9e1bdb3f9af36b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6507f22530044ebb427b63fdfd8ecf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c0996f831b41f5bf8645dbcce9490f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dd4c2c0e4840d6bf24beaadfbc6f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca59e9ea91f456290a19428afa58982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7aff6b99994e7ea23cf32cdbd8599d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55b3a191ff4432da4b146201631dd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_data = fossil_preproc.prepare_primary_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8787d673-2122-4f91-a4b1-f09b52d88022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fossil_preproc.pca_feature_selection(base_data, eda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f949a20-cfb6-4f8c-86cc-3814ade79290",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_features = fossil_preproc.pca_feature_selection(base_data, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b1eba-5500-435d-ae44-71278f558cb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61402e21-a61b-4e7d-84c6-9904dfd44f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil.models.gbdt import FossilGBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f24593a-9a12-4841-8788-ca4670ceef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_models = FossilGBDT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bad2c512-d139-4639-8e8e-12320bf1014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = principal_features+['sku_name','sku_coded', 'month', 'year']\n",
    "feature_cols = [c for c in base_data.columns if c in cols]\n",
    "target_cols = [c for c in base_data.columns if 'target' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "945baea6-488c-4a94-be11-1fd898392dc8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\ttraining's l1: 113999\tvalid_1's l1: 155863\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[675]\ttraining's l1: 79765\tvalid_1's l1: 117185\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's l1: 78092.4\tvalid_1's l1: 127827\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[629]\ttraining's l1: 77315.8\tvalid_1's l1: 148814\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[650]\ttraining's l1: 78336.7\tvalid_1's l1: 133285\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[439]\ttraining's l1: 95652.6\tvalid_1's l1: 127419\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[423]\ttraining's l1: 87024\tvalid_1's l1: 143375\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[625]\ttraining's l1: 78730.9\tvalid_1's l1: 115586\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[625]\ttraining's l1: 76026.1\tvalid_1's l1: 131154\n",
      "Elapsed 0.32 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[482]\ttraining's l1: 84214.7\tvalid_1's l1: 130017\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[678]\ttraining's l1: 70685.3\tvalid_1's l1: 123767\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[660]\ttraining's l1: 70499.4\tvalid_1's l1: 125723\n",
      "Elapsed 0.45 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "primary_cv_models = gbdt_models.train_model(base_data, feature_cols, target_cols, True, \n",
    "                                         True, False, model_type='lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54634b66-5142-43a4-bfa2-b3b201c8ce3a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making timestep 1 predictions\n",
      "Val MAE: 133795.3755917538\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 136597.2491148936\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 130142.7268334461\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 126529.39100255941\n",
      "\n",
      "\n",
      "Average Val MAE: 131766.1856356564\n"
     ]
    }
   ],
   "source": [
    "primary_val_mae, primary_oof = gbdt_models.test_model(base_data, feature_cols, target_cols, \n",
    "                                                      primary_cv_models, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59f893b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [f'target_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "pred_cols = [f'preds_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "\n",
    "secondary_data = fossil_preproc.prepare_secondary_data(base_data, primary_oof, target_cols, pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26f1f962-c201-4183-b89e-f2e0de51e3c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 205319.0253969\ttest: 205319.0253969\ttest1: 223763.1098528\tbest: 223763.1098528 (0)\ttotal: 75.4ms\tremaining: 12m 34s\n",
      "500:\tlearn: 114058.8878551\ttest: 114058.8878551\ttest1: 130250.3634474\tbest: 130250.3634474 (500)\ttotal: 3.93s\tremaining: 1m 14s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129186.5\n",
      "bestIteration = 753\n",
      "\n",
      "Shrink model to first 754 iterations.\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 209814.7152313\ttest: 209814.7152313\ttest1: 214766.9149703\tbest: 214766.9149703 (0)\ttotal: 8.12ms\tremaining: 1m 21s\n",
      "500:\tlearn: 118838.0963947\ttest: 118838.0963947\ttest1: 118788.1659704\tbest: 118788.1659704 (500)\ttotal: 3.95s\tremaining: 1m 14s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117848.3308\n",
      "bestIteration = 748\n",
      "\n",
      "Shrink model to first 749 iterations.\n",
      "Elapsed 0.26 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 219292.0251461\ttest: 219292.0251461\ttest1: 195876.2841560\tbest: 195876.2841560 (0)\ttotal: 12.8ms\tremaining: 2m 7s\n",
      "500:\tlearn: 122442.8890003\ttest: 122442.8890003\ttest1: 112246.1184457\tbest: 112246.1184457 (500)\ttotal: 3.89s\tremaining: 1m 13s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 111781.2925\n",
      "bestIteration = 673\n",
      "\n",
      "Shrink model to first 674 iterations.\n",
      "Elapsed 0.35 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['sku_name','sku_coded','preds', 'time_step', 'month', 'year']\n",
    "secondary_features = [c for c in secondary_data.columns if 'lag' in c or c in cols]\n",
    "secondary_targets = 'target'\n",
    "\n",
    "secondary_cv_models = gbdt_models.train_model(secondary_data, secondary_features, secondary_targets, False, False,\n",
    "                                              False, ModelsConfig.META_LEARNER,  'meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dab6b62-d260-43c2-bb6c-9ee21569736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 129186.49995364537\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 117848.33075800075\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 111781.29247147623\n",
      "\n",
      "\n",
      "Average Val MAE: 119676.25688484599\n"
     ]
    }
   ],
   "source": [
    "secondary_val_mae, secondary_oof = gbdt_models.test_model(secondary_data, secondary_features, secondary_targets,\n",
    "                                      secondary_cv_models, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f88d53-1113-4b90-ae4c-4939c38a3977",
   "metadata": {},
   "source": [
    "## Meta Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf93777-924a-4491-8b69-584e3a84659f",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a219fd-ba60-4eac-841a-52460619f80b",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63beb5a2-a4f7-4e67-800a-5626b842c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv(f'{TEST_DIR}/Test.csv')\n",
    "train = pd.read_csv(f'{TRAIN_DIR}/Train.csv')\n",
    "desc = pd.read_csv(f'{DATA_DIR}/DataDictionary.csv')\n",
    "\n",
    "CAT = desc[36:]['Column Name'].tolist()\n",
    "train_df = train.drop(columns=CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff72446c-7fdf-4e4b-9ae2-ea3b34c65e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil.inference import prepare_test_context, prepare_submission_data, prepare_test_dates\n",
    "from fossil.config import ModelsConfig\n",
    "from fossil.preprocessing import FossilData, LabelEncoder\n",
    "\n",
    "np.random.seed(ModelsConfig.SEED)\n",
    "sku_encoder = LabelEncoder(train.sku_name.sample(frac=0.95).unique())\n",
    "\n",
    "\n",
    "fossil_preproc = FossilPreprocessor(sku_encoder)\n",
    "test_context, test_dates = prepare_test_context(train_df, test, fossil_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1af44a5e-ba5a-4691-9766-3fafdf63ee38",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2f29f286ff46d39d7de2df9401b8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41521bf5b634379a35892689b9c3d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcd4f1972c7415b9555082088390b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3562f00513914465968e2d5fb47b8dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65906a68ff74354b8df00fd4b99c19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47232f0d84fa4e71af3c3d4ca9bb1264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8908619cd17422f96918d4e84ab49ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febb8a0ae6b94910a878479097e2098e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_cols = [c for c in test_context.columns if c not in ['sku_name', 'month', 'year']\n",
    "             and all(l not in c for l in ['target', 'channel','rel'])]\n",
    "\n",
    "test_data = fossil_preproc.prepare_primary_data(test_context, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c50a2f32-e2a0-4912-ae3a-f10ac35f6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[test_data[['month', 'year']].apply(tuple, axis=1).isin(test_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8cf15e7-77a0-4263-97ff-1088f5e76323",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [f'target_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "pred_cols = [f'preds_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "\n",
    "cols = principal_features+['month','year']\n",
    "non_features = ['sku_name','sku_coded']+target_cols\n",
    "feature_cols = [c for c in test_data.columns if c not in non_features and c in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c2162f4-d300-48b1-b569-63b62a6cb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil.models.gbdt import FossilGBDT\n",
    "gbdt_models = FossilGBDT()\n",
    "\n",
    "primary_preds = gbdt_models.forecast(test_data, feature_cols, target_cols, primary_cv_models, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27286400-835e-479f-b3b3-02504653d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = prepare_submission_data(test, primary_preds, target_cols, pred_cols)\n",
    "# sub_df = fossil_preproc.adjust_expanded_dates(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46657102-b5ec-491f-9ba4-944257ce6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary_test = fossil_preproc.prepare_secondary_data(test_data, primary_preds[target_cols], target_cols, pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "411f9c5e-54b4-4275-8591-1b8f34b378db",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred_dates = prepare_test_dates(test) \n",
    "\n",
    "sub_df['month'] = pd.DataFrame(pred_dates*int(len(sub_df)/ModelsConfig.N_STEPS)).loc[:, 0].values\n",
    "sub_df['year'] = pd.DataFrame(pred_dates*int(len(sub_df)/ModelsConfig.N_STEPS)).loc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74bb2f6e-efc2-4ad7-ad7b-993605c483e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['preds', 'time_step', 'month', 'year', 'pred_month', 'pred_year']\n",
    "meta_features = [c for c in sub_df.columns if 'lag' in c or c in cols]\n",
    "meta_targets = 'Target'\n",
    "\n",
    "sub_df = gbdt_models.forecast(sub_df, meta_features, meta_targets, secondary_cv_models, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec5c1175-cb30-4361-b1ab-68a91275add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_df['Item_ID'] = sub_df['sku_name'].astype(str)+'_'+sub_df['month'].astype(int).astype(str)+'_'+sub_df['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f960042-3177-478c-a7d7-9ccbd4b17be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = f'{OUTPUT_DIR}/fossil_{ModelsConfig.BASE_MODEL}_{ModelsConfig.META_LEARNER}_{secondary_val_mae}.csv'\n",
    "sub_df[['Item_ID','Target']].to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65dd572f-a40b-46f5-9c14-d66c7bf3048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_name = f'{OUTPUT_DIR}/fossil_{ModelsConfig.BASE_MODEL}_{ModelsConfig.META_LEARNER}_{metrics_list[-1]}_cnnpred.csv'\n",
    "# sub_df[['Item_ID','Target']].to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6eb7465-6dfa-43a9-9cab-d078008739c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "      <th>Target</th>\n",
       "      <th>Item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68493.186385</td>\n",
       "      <td>0</td>\n",
       "      <td>18653.989835</td>\n",
       "      <td>ABEAHAMASHL_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>139666.726152</td>\n",
       "      <td>1</td>\n",
       "      <td>44493.463182</td>\n",
       "      <td>ABEAHAMASHL_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>125585.440628</td>\n",
       "      <td>2</td>\n",
       "      <td>57307.201628</td>\n",
       "      <td>ABEAHAMASHL_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>123148.299105</td>\n",
       "      <td>3</td>\n",
       "      <td>47657.033155</td>\n",
       "      <td>ABEAHAMASHL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEENNEARMAZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>42546.0</td>\n",
       "      <td>152963.0</td>\n",
       "      <td>58754.0</td>\n",
       "      <td>35455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>600709.0</td>\n",
       "      <td>68884.0</td>\n",
       "      <td>106365.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>262311.050127</td>\n",
       "      <td>0</td>\n",
       "      <td>154738.264677</td>\n",
       "      <td>ABEENNEARMAZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1527604.0</td>\n",
       "      <td>288705.0</td>\n",
       "      <td>199561.0</td>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>211717.0</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>304326.984856</td>\n",
       "      <td>3</td>\n",
       "      <td>191719.104550</td>\n",
       "      <td>YOSHRENECARL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>244010.740011</td>\n",
       "      <td>0</td>\n",
       "      <td>132271.452093</td>\n",
       "      <td>YOSHTLYNYOSHZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>267407.530586</td>\n",
       "      <td>1</td>\n",
       "      <td>172168.502814</td>\n",
       "      <td>YOSHTLYNYOSHZZ_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>221509.683499</td>\n",
       "      <td>2</td>\n",
       "      <td>121917.254334</td>\n",
       "      <td>YOSHTLYNYOSHZZ_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>206825.303343</td>\n",
       "      <td>3</td>\n",
       "      <td>93802.302572</td>\n",
       "      <td>YOSHTLYNYOSHZZ_2_2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1528 rows  83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month  year  starting_inventory    sellin  \\\n",
       "0        ABEAHAMASHL     11  2021            410265.0   18234.0   \n",
       "1        ABEAHAMASHL     12  2021            410265.0   18234.0   \n",
       "2        ABEAHAMASHL      1  2022            410265.0   18234.0   \n",
       "3        ABEAHAMASHL      2  2022            410265.0   18234.0   \n",
       "4      ABEENNEARMAZZ     11  2021             42546.0  152963.0   \n",
       "...              ...    ...   ...                 ...       ...   \n",
       "1523    YOSHRENECARL      2  2022           1527604.0  288705.0   \n",
       "1524  YOSHTLYNYOSHZZ     11  2021            156002.0  163093.0   \n",
       "1525  YOSHTLYNYOSHZZ     12  2021            156002.0  163093.0   \n",
       "1526  YOSHTLYNYOSHZZ      1  2022            156002.0  163093.0   \n",
       "1527  YOSHTLYNYOSHZZ      2  2022            156002.0  163093.0   \n",
       "\n",
       "      sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "0                  0.0               0.0               0.0            1013.0   \n",
       "1                  0.0               0.0               0.0            1013.0   \n",
       "2                  0.0               0.0               0.0            1013.0   \n",
       "3                  0.0               0.0               0.0            1013.0   \n",
       "4              58754.0           35455.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "1523          199561.0           79014.0               0.0               0.0   \n",
       "1524          122573.0           30390.0               0.0               0.0   \n",
       "1525          122573.0           30390.0               0.0               0.0   \n",
       "1526          122573.0           30390.0               0.0               0.0   \n",
       "1527          122573.0           30390.0               0.0               0.0   \n",
       "\n",
       "      sellin_channel_5  ...  onhand_inventory_9month_MM  \\\n",
       "0                  0.0  ...                    291744.0   \n",
       "1                  0.0  ...                    291744.0   \n",
       "2                  0.0  ...                    291744.0   \n",
       "3                  0.0  ...                    291744.0   \n",
       "4                  0.0  ...                    600709.0   \n",
       "...                ...  ...                         ...   \n",
       "1523               0.0  ...                    793179.0   \n",
       "1524               0.0  ...                    193483.0   \n",
       "1525               0.0  ...                    193483.0   \n",
       "1526               0.0  ...                    193483.0   \n",
       "1527               0.0  ...                    193483.0   \n",
       "\n",
       "      leftover_inventory_6month_MM  leftover_inventory_9month_MM  \\\n",
       "0                         -13675.5                      -16208.0   \n",
       "1                         -13675.5                      -16208.0   \n",
       "2                         -13675.5                      -16208.0   \n",
       "3                         -13675.5                      -16208.0   \n",
       "4                          68884.0                      106365.0   \n",
       "...                            ...                           ...   \n",
       "1523                      211717.0                      214756.0   \n",
       "1524                      180820.5                      200574.0   \n",
       "1525                      180820.5                      200574.0   \n",
       "1526                      180820.5                      200574.0   \n",
       "1527                      180820.5                      200574.0   \n",
       "\n",
       "      price_6month_MM  price_9month_MM  sku_coded          preds  time_step  \\\n",
       "0               149.0            149.0       74.0   68493.186385          0   \n",
       "1               149.0            149.0       74.0  139666.726152          1   \n",
       "2               149.0            149.0       74.0  125585.440628          2   \n",
       "3               149.0            149.0       74.0  123148.299105          3   \n",
       "4               129.0            129.0      633.0  262311.050127          0   \n",
       "...               ...              ...        ...            ...        ...   \n",
       "1523            129.0            129.0      248.0  304326.984856          3   \n",
       "1524            149.0            149.0     1852.0  244010.740011          0   \n",
       "1525            149.0            149.0     1852.0  267407.530586          1   \n",
       "1526            149.0            149.0     1852.0  221509.683499          2   \n",
       "1527            149.0            149.0     1852.0  206825.303343          3   \n",
       "\n",
       "             Target                 Item_ID  \n",
       "0      18653.989835     ABEAHAMASHL_11_2021  \n",
       "1      44493.463182     ABEAHAMASHL_12_2021  \n",
       "2      57307.201628      ABEAHAMASHL_1_2022  \n",
       "3      47657.033155      ABEAHAMASHL_2_2022  \n",
       "4     154738.264677   ABEENNEARMAZZ_11_2021  \n",
       "...             ...                     ...  \n",
       "1523  191719.104550     YOSHRENECARL_2_2022  \n",
       "1524  132271.452093  YOSHTLYNYOSHZZ_11_2021  \n",
       "1525  172168.502814  YOSHTLYNYOSHZZ_12_2021  \n",
       "1526  121917.254334   YOSHTLYNYOSHZZ_1_2022  \n",
       "1527   93802.302572   YOSHTLYNYOSHZZ_2_2022  \n",
       "\n",
       "[1528 rows x 83 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df#[['month','year','pred_month','pred_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b33dc77-d244-4f01-9607-56ad4b46bdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "      <th>Target</th>\n",
       "      <th>Item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68493.186385</td>\n",
       "      <td>0</td>\n",
       "      <td>18653.989835</td>\n",
       "      <td>ABEAHAMASHL_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>139666.726152</td>\n",
       "      <td>1</td>\n",
       "      <td>44493.463182</td>\n",
       "      <td>ABEAHAMASHL_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>125585.440628</td>\n",
       "      <td>2</td>\n",
       "      <td>57307.201628</td>\n",
       "      <td>ABEAHAMASHL_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>123148.299105</td>\n",
       "      <td>3</td>\n",
       "      <td>47657.033155</td>\n",
       "      <td>ABEAHAMASHL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEENNEARMAZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>42546.0</td>\n",
       "      <td>152963.0</td>\n",
       "      <td>58754.0</td>\n",
       "      <td>35455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>600709.0</td>\n",
       "      <td>68884.0</td>\n",
       "      <td>106365.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>262311.050127</td>\n",
       "      <td>0</td>\n",
       "      <td>154738.264677</td>\n",
       "      <td>ABEENNEARMAZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1527604.0</td>\n",
       "      <td>288705.0</td>\n",
       "      <td>199561.0</td>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>211717.0</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>304326.984856</td>\n",
       "      <td>3</td>\n",
       "      <td>191719.104550</td>\n",
       "      <td>YOSHRENECARL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>244010.740011</td>\n",
       "      <td>0</td>\n",
       "      <td>132271.452093</td>\n",
       "      <td>YOSHTLYNYOSHZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>267407.530586</td>\n",
       "      <td>1</td>\n",
       "      <td>172168.502814</td>\n",
       "      <td>YOSHTLYNYOSHZZ_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>221509.683499</td>\n",
       "      <td>2</td>\n",
       "      <td>121917.254334</td>\n",
       "      <td>YOSHTLYNYOSHZZ_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>206825.303343</td>\n",
       "      <td>3</td>\n",
       "      <td>93802.302572</td>\n",
       "      <td>YOSHTLYNYOSHZZ_2_2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1528 rows  83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month  year  starting_inventory    sellin  \\\n",
       "0        ABEAHAMASHL     11  2021            410265.0   18234.0   \n",
       "1        ABEAHAMASHL     12  2021            410265.0   18234.0   \n",
       "2        ABEAHAMASHL      1  2022            410265.0   18234.0   \n",
       "3        ABEAHAMASHL      2  2022            410265.0   18234.0   \n",
       "4      ABEENNEARMAZZ     11  2021             42546.0  152963.0   \n",
       "...              ...    ...   ...                 ...       ...   \n",
       "1523    YOSHRENECARL      2  2022           1527604.0  288705.0   \n",
       "1524  YOSHTLYNYOSHZZ     11  2021            156002.0  163093.0   \n",
       "1525  YOSHTLYNYOSHZZ     12  2021            156002.0  163093.0   \n",
       "1526  YOSHTLYNYOSHZZ      1  2022            156002.0  163093.0   \n",
       "1527  YOSHTLYNYOSHZZ      2  2022            156002.0  163093.0   \n",
       "\n",
       "      sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "0                  0.0               0.0               0.0            1013.0   \n",
       "1                  0.0               0.0               0.0            1013.0   \n",
       "2                  0.0               0.0               0.0            1013.0   \n",
       "3                  0.0               0.0               0.0            1013.0   \n",
       "4              58754.0           35455.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "1523          199561.0           79014.0               0.0               0.0   \n",
       "1524          122573.0           30390.0               0.0               0.0   \n",
       "1525          122573.0           30390.0               0.0               0.0   \n",
       "1526          122573.0           30390.0               0.0               0.0   \n",
       "1527          122573.0           30390.0               0.0               0.0   \n",
       "\n",
       "      sellin_channel_5  ...  onhand_inventory_9month_MM  \\\n",
       "0                  0.0  ...                    291744.0   \n",
       "1                  0.0  ...                    291744.0   \n",
       "2                  0.0  ...                    291744.0   \n",
       "3                  0.0  ...                    291744.0   \n",
       "4                  0.0  ...                    600709.0   \n",
       "...                ...  ...                         ...   \n",
       "1523               0.0  ...                    793179.0   \n",
       "1524               0.0  ...                    193483.0   \n",
       "1525               0.0  ...                    193483.0   \n",
       "1526               0.0  ...                    193483.0   \n",
       "1527               0.0  ...                    193483.0   \n",
       "\n",
       "      leftover_inventory_6month_MM  leftover_inventory_9month_MM  \\\n",
       "0                         -13675.5                      -16208.0   \n",
       "1                         -13675.5                      -16208.0   \n",
       "2                         -13675.5                      -16208.0   \n",
       "3                         -13675.5                      -16208.0   \n",
       "4                          68884.0                      106365.0   \n",
       "...                            ...                           ...   \n",
       "1523                      211717.0                      214756.0   \n",
       "1524                      180820.5                      200574.0   \n",
       "1525                      180820.5                      200574.0   \n",
       "1526                      180820.5                      200574.0   \n",
       "1527                      180820.5                      200574.0   \n",
       "\n",
       "      price_6month_MM  price_9month_MM  sku_coded          preds  time_step  \\\n",
       "0               149.0            149.0       74.0   68493.186385          0   \n",
       "1               149.0            149.0       74.0  139666.726152          1   \n",
       "2               149.0            149.0       74.0  125585.440628          2   \n",
       "3               149.0            149.0       74.0  123148.299105          3   \n",
       "4               129.0            129.0      633.0  262311.050127          0   \n",
       "...               ...              ...        ...            ...        ...   \n",
       "1523            129.0            129.0      248.0  304326.984856          3   \n",
       "1524            149.0            149.0     1852.0  244010.740011          0   \n",
       "1525            149.0            149.0     1852.0  267407.530586          1   \n",
       "1526            149.0            149.0     1852.0  221509.683499          2   \n",
       "1527            149.0            149.0     1852.0  206825.303343          3   \n",
       "\n",
       "             Target                 Item_ID  \n",
       "0      18653.989835     ABEAHAMASHL_11_2021  \n",
       "1      44493.463182     ABEAHAMASHL_12_2021  \n",
       "2      57307.201628      ABEAHAMASHL_1_2022  \n",
       "3      47657.033155      ABEAHAMASHL_2_2022  \n",
       "4     154738.264677   ABEENNEARMAZZ_11_2021  \n",
       "...             ...                     ...  \n",
       "1523  191719.104550     YOSHRENECARL_2_2022  \n",
       "1524  132271.452093  YOSHTLYNYOSHZZ_11_2021  \n",
       "1525  172168.502814  YOSHTLYNYOSHZZ_12_2021  \n",
       "1526  121917.254334   YOSHTLYNYOSHZZ_1_2022  \n",
       "1527   93802.302572   YOSHTLYNYOSHZZ_2_2022  \n",
       "\n",
       "[1528 rows x 83 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df#[['month','year','pred_month','pred_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93811f59-001d-46b9-ba10-cb30195023b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "      <th>Target</th>\n",
       "      <th>Item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68493.186385</td>\n",
       "      <td>0</td>\n",
       "      <td>18653.989835</td>\n",
       "      <td>ABEAHAMASHL_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>139666.726152</td>\n",
       "      <td>1</td>\n",
       "      <td>44493.463182</td>\n",
       "      <td>ABEAHAMASHL_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>125585.440628</td>\n",
       "      <td>2</td>\n",
       "      <td>57307.201628</td>\n",
       "      <td>ABEAHAMASHL_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>123148.299105</td>\n",
       "      <td>3</td>\n",
       "      <td>47657.033155</td>\n",
       "      <td>ABEAHAMASHL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEENNEARMAZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>42546.0</td>\n",
       "      <td>152963.0</td>\n",
       "      <td>58754.0</td>\n",
       "      <td>35455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>600709.0</td>\n",
       "      <td>68884.0</td>\n",
       "      <td>106365.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>262311.050127</td>\n",
       "      <td>0</td>\n",
       "      <td>154738.264677</td>\n",
       "      <td>ABEENNEARMAZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1527604.0</td>\n",
       "      <td>288705.0</td>\n",
       "      <td>199561.0</td>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>211717.0</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>304326.984856</td>\n",
       "      <td>3</td>\n",
       "      <td>191719.104550</td>\n",
       "      <td>YOSHRENECARL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>244010.740011</td>\n",
       "      <td>0</td>\n",
       "      <td>132271.452093</td>\n",
       "      <td>YOSHTLYNYOSHZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>267407.530586</td>\n",
       "      <td>1</td>\n",
       "      <td>172168.502814</td>\n",
       "      <td>YOSHTLYNYOSHZZ_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>221509.683499</td>\n",
       "      <td>2</td>\n",
       "      <td>121917.254334</td>\n",
       "      <td>YOSHTLYNYOSHZZ_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>206825.303343</td>\n",
       "      <td>3</td>\n",
       "      <td>93802.302572</td>\n",
       "      <td>YOSHTLYNYOSHZZ_2_2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1528 rows  83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month  year  starting_inventory    sellin  \\\n",
       "0        ABEAHAMASHL     11  2021            410265.0   18234.0   \n",
       "1        ABEAHAMASHL     12  2021            410265.0   18234.0   \n",
       "2        ABEAHAMASHL      1  2022            410265.0   18234.0   \n",
       "3        ABEAHAMASHL      2  2022            410265.0   18234.0   \n",
       "4      ABEENNEARMAZZ     11  2021             42546.0  152963.0   \n",
       "...              ...    ...   ...                 ...       ...   \n",
       "1523    YOSHRENECARL      2  2022           1527604.0  288705.0   \n",
       "1524  YOSHTLYNYOSHZZ     11  2021            156002.0  163093.0   \n",
       "1525  YOSHTLYNYOSHZZ     12  2021            156002.0  163093.0   \n",
       "1526  YOSHTLYNYOSHZZ      1  2022            156002.0  163093.0   \n",
       "1527  YOSHTLYNYOSHZZ      2  2022            156002.0  163093.0   \n",
       "\n",
       "      sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "0                  0.0               0.0               0.0            1013.0   \n",
       "1                  0.0               0.0               0.0            1013.0   \n",
       "2                  0.0               0.0               0.0            1013.0   \n",
       "3                  0.0               0.0               0.0            1013.0   \n",
       "4              58754.0           35455.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "1523          199561.0           79014.0               0.0               0.0   \n",
       "1524          122573.0           30390.0               0.0               0.0   \n",
       "1525          122573.0           30390.0               0.0               0.0   \n",
       "1526          122573.0           30390.0               0.0               0.0   \n",
       "1527          122573.0           30390.0               0.0               0.0   \n",
       "\n",
       "      sellin_channel_5  ...  onhand_inventory_9month_MM  \\\n",
       "0                  0.0  ...                    291744.0   \n",
       "1                  0.0  ...                    291744.0   \n",
       "2                  0.0  ...                    291744.0   \n",
       "3                  0.0  ...                    291744.0   \n",
       "4                  0.0  ...                    600709.0   \n",
       "...                ...  ...                         ...   \n",
       "1523               0.0  ...                    793179.0   \n",
       "1524               0.0  ...                    193483.0   \n",
       "1525               0.0  ...                    193483.0   \n",
       "1526               0.0  ...                    193483.0   \n",
       "1527               0.0  ...                    193483.0   \n",
       "\n",
       "      leftover_inventory_6month_MM  leftover_inventory_9month_MM  \\\n",
       "0                         -13675.5                      -16208.0   \n",
       "1                         -13675.5                      -16208.0   \n",
       "2                         -13675.5                      -16208.0   \n",
       "3                         -13675.5                      -16208.0   \n",
       "4                          68884.0                      106365.0   \n",
       "...                            ...                           ...   \n",
       "1523                      211717.0                      214756.0   \n",
       "1524                      180820.5                      200574.0   \n",
       "1525                      180820.5                      200574.0   \n",
       "1526                      180820.5                      200574.0   \n",
       "1527                      180820.5                      200574.0   \n",
       "\n",
       "      price_6month_MM  price_9month_MM  sku_coded          preds  time_step  \\\n",
       "0               149.0            149.0       74.0   68493.186385          0   \n",
       "1               149.0            149.0       74.0  139666.726152          1   \n",
       "2               149.0            149.0       74.0  125585.440628          2   \n",
       "3               149.0            149.0       74.0  123148.299105          3   \n",
       "4               129.0            129.0      633.0  262311.050127          0   \n",
       "...               ...              ...        ...            ...        ...   \n",
       "1523            129.0            129.0      248.0  304326.984856          3   \n",
       "1524            149.0            149.0     1852.0  244010.740011          0   \n",
       "1525            149.0            149.0     1852.0  267407.530586          1   \n",
       "1526            149.0            149.0     1852.0  221509.683499          2   \n",
       "1527            149.0            149.0     1852.0  206825.303343          3   \n",
       "\n",
       "             Target                 Item_ID  \n",
       "0      18653.989835     ABEAHAMASHL_11_2021  \n",
       "1      44493.463182     ABEAHAMASHL_12_2021  \n",
       "2      57307.201628      ABEAHAMASHL_1_2022  \n",
       "3      47657.033155      ABEAHAMASHL_2_2022  \n",
       "4     154738.264677   ABEENNEARMAZZ_11_2021  \n",
       "...             ...                     ...  \n",
       "1523  191719.104550     YOSHRENECARL_2_2022  \n",
       "1524  132271.452093  YOSHTLYNYOSHZZ_11_2021  \n",
       "1525  172168.502814  YOSHTLYNYOSHZZ_12_2021  \n",
       "1526  121917.254334   YOSHTLYNYOSHZZ_1_2022  \n",
       "1527   93802.302572   YOSHTLYNYOSHZZ_2_2022  \n",
       "\n",
       "[1528 rows x 83 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df#[['month','year','pred_month','pred_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f211af45-99c3-4a7e-b3fe-85301ebd6da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "      <th>Target</th>\n",
       "      <th>Item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68493.186385</td>\n",
       "      <td>0</td>\n",
       "      <td>32036.237317</td>\n",
       "      <td>ABEAHAMASHL_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>139666.726152</td>\n",
       "      <td>1</td>\n",
       "      <td>69860.310366</td>\n",
       "      <td>ABEAHAMASHL_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>125585.440628</td>\n",
       "      <td>2</td>\n",
       "      <td>68940.364406</td>\n",
       "      <td>ABEAHAMASHL_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>123148.299105</td>\n",
       "      <td>3</td>\n",
       "      <td>75302.944389</td>\n",
       "      <td>ABEAHAMASHL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEENNEARMAZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>42546.0</td>\n",
       "      <td>152963.0</td>\n",
       "      <td>58754.0</td>\n",
       "      <td>35455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>600709.0</td>\n",
       "      <td>68884.0</td>\n",
       "      <td>106365.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>262311.050127</td>\n",
       "      <td>0</td>\n",
       "      <td>155138.417735</td>\n",
       "      <td>ABEENNEARMAZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1527604.0</td>\n",
       "      <td>288705.0</td>\n",
       "      <td>199561.0</td>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>211717.0</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>304326.984856</td>\n",
       "      <td>3</td>\n",
       "      <td>225663.606927</td>\n",
       "      <td>YOSHRENECARL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>244010.740011</td>\n",
       "      <td>0</td>\n",
       "      <td>132067.748265</td>\n",
       "      <td>YOSHTLYNYOSHZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>267407.530586</td>\n",
       "      <td>1</td>\n",
       "      <td>162292.481192</td>\n",
       "      <td>YOSHTLYNYOSHZZ_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>221509.683499</td>\n",
       "      <td>2</td>\n",
       "      <td>129818.557819</td>\n",
       "      <td>YOSHTLYNYOSHZZ_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>206825.303343</td>\n",
       "      <td>3</td>\n",
       "      <td>135683.382317</td>\n",
       "      <td>YOSHTLYNYOSHZZ_2_2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1528 rows  83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month  year  starting_inventory    sellin  \\\n",
       "0        ABEAHAMASHL     11  2021            410265.0   18234.0   \n",
       "1        ABEAHAMASHL     12  2021            410265.0   18234.0   \n",
       "2        ABEAHAMASHL      1  2022            410265.0   18234.0   \n",
       "3        ABEAHAMASHL      2  2022            410265.0   18234.0   \n",
       "4      ABEENNEARMAZZ     11  2021             42546.0  152963.0   \n",
       "...              ...    ...   ...                 ...       ...   \n",
       "1523    YOSHRENECARL      2  2022           1527604.0  288705.0   \n",
       "1524  YOSHTLYNYOSHZZ     11  2021            156002.0  163093.0   \n",
       "1525  YOSHTLYNYOSHZZ     12  2021            156002.0  163093.0   \n",
       "1526  YOSHTLYNYOSHZZ      1  2022            156002.0  163093.0   \n",
       "1527  YOSHTLYNYOSHZZ      2  2022            156002.0  163093.0   \n",
       "\n",
       "      sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "0                  0.0               0.0               0.0            1013.0   \n",
       "1                  0.0               0.0               0.0            1013.0   \n",
       "2                  0.0               0.0               0.0            1013.0   \n",
       "3                  0.0               0.0               0.0            1013.0   \n",
       "4              58754.0           35455.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "1523          199561.0           79014.0               0.0               0.0   \n",
       "1524          122573.0           30390.0               0.0               0.0   \n",
       "1525          122573.0           30390.0               0.0               0.0   \n",
       "1526          122573.0           30390.0               0.0               0.0   \n",
       "1527          122573.0           30390.0               0.0               0.0   \n",
       "\n",
       "      sellin_channel_5  ...  onhand_inventory_9month_MM  \\\n",
       "0                  0.0  ...                    291744.0   \n",
       "1                  0.0  ...                    291744.0   \n",
       "2                  0.0  ...                    291744.0   \n",
       "3                  0.0  ...                    291744.0   \n",
       "4                  0.0  ...                    600709.0   \n",
       "...                ...  ...                         ...   \n",
       "1523               0.0  ...                    793179.0   \n",
       "1524               0.0  ...                    193483.0   \n",
       "1525               0.0  ...                    193483.0   \n",
       "1526               0.0  ...                    193483.0   \n",
       "1527               0.0  ...                    193483.0   \n",
       "\n",
       "      leftover_inventory_6month_MM  leftover_inventory_9month_MM  \\\n",
       "0                         -13675.5                      -16208.0   \n",
       "1                         -13675.5                      -16208.0   \n",
       "2                         -13675.5                      -16208.0   \n",
       "3                         -13675.5                      -16208.0   \n",
       "4                          68884.0                      106365.0   \n",
       "...                            ...                           ...   \n",
       "1523                      211717.0                      214756.0   \n",
       "1524                      180820.5                      200574.0   \n",
       "1525                      180820.5                      200574.0   \n",
       "1526                      180820.5                      200574.0   \n",
       "1527                      180820.5                      200574.0   \n",
       "\n",
       "      price_6month_MM  price_9month_MM  sku_coded          preds  time_step  \\\n",
       "0               149.0            149.0       74.0   68493.186385          0   \n",
       "1               149.0            149.0       74.0  139666.726152          1   \n",
       "2               149.0            149.0       74.0  125585.440628          2   \n",
       "3               149.0            149.0       74.0  123148.299105          3   \n",
       "4               129.0            129.0      633.0  262311.050127          0   \n",
       "...               ...              ...        ...            ...        ...   \n",
       "1523            129.0            129.0      248.0  304326.984856          3   \n",
       "1524            149.0            149.0     1852.0  244010.740011          0   \n",
       "1525            149.0            149.0     1852.0  267407.530586          1   \n",
       "1526            149.0            149.0     1852.0  221509.683499          2   \n",
       "1527            149.0            149.0     1852.0  206825.303343          3   \n",
       "\n",
       "             Target                 Item_ID  \n",
       "0      32036.237317     ABEAHAMASHL_11_2021  \n",
       "1      69860.310366     ABEAHAMASHL_12_2021  \n",
       "2      68940.364406      ABEAHAMASHL_1_2022  \n",
       "3      75302.944389      ABEAHAMASHL_2_2022  \n",
       "4     155138.417735   ABEENNEARMAZZ_11_2021  \n",
       "...             ...                     ...  \n",
       "1523  225663.606927     YOSHRENECARL_2_2022  \n",
       "1524  132067.748265  YOSHTLYNYOSHZZ_11_2021  \n",
       "1525  162292.481192  YOSHTLYNYOSHZZ_12_2021  \n",
       "1526  129818.557819   YOSHTLYNYOSHZZ_1_2022  \n",
       "1527  135683.382317   YOSHTLYNYOSHZZ_2_2022  \n",
       "\n",
       "[1528 rows x 83 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df#[['month','year','pred_month','pred_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f13d1e9a-a3f4-4822-97f3-cb43cddd3ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_6month_MM</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6844841.0</td>\n",
       "      <td>902583.0</td>\n",
       "      <td>542968.0</td>\n",
       "      <td>236029.0</td>\n",
       "      <td>34442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14182.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1529123.50</td>\n",
       "      <td>1584332.0</td>\n",
       "      <td>50143.50</td>\n",
       "      <td>56728.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>358602.0</td>\n",
       "      <td>993988.457097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6844841.0</td>\n",
       "      <td>902583.0</td>\n",
       "      <td>542968.0</td>\n",
       "      <td>236029.0</td>\n",
       "      <td>34442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14182.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1529123.50</td>\n",
       "      <td>1584332.0</td>\n",
       "      <td>50143.50</td>\n",
       "      <td>56728.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1177106.0</td>\n",
       "      <td>963319.364140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6844841.0</td>\n",
       "      <td>902583.0</td>\n",
       "      <td>542968.0</td>\n",
       "      <td>236029.0</td>\n",
       "      <td>34442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14182.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1529123.50</td>\n",
       "      <td>1584332.0</td>\n",
       "      <td>50143.50</td>\n",
       "      <td>56728.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>968428.0</td>\n",
       "      <td>638536.972105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6844841.0</td>\n",
       "      <td>902583.0</td>\n",
       "      <td>542968.0</td>\n",
       "      <td>236029.0</td>\n",
       "      <td>34442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14182.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1529123.50</td>\n",
       "      <td>1584332.0</td>\n",
       "      <td>50143.50</td>\n",
       "      <td>56728.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>470032.0</td>\n",
       "      <td>613783.671361</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEANHARLE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388992.0</td>\n",
       "      <td>321121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1201924.50</td>\n",
       "      <td>1192301.0</td>\n",
       "      <td>-20260.00</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>154989.0</td>\n",
       "      <td>420339.695346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172931</th>\n",
       "      <td>YOSHLEENBART</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>135742.0</td>\n",
       "      <td>152963.0</td>\n",
       "      <td>25325.0</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>66858.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>252490.25</td>\n",
       "      <td>251224.0</td>\n",
       "      <td>191963.50</td>\n",
       "      <td>141820.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>237042.0</td>\n",
       "      <td>132547.547953</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172932</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>76988.0</td>\n",
       "      <td>84079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>823822.25</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>219567.75</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>456863.0</td>\n",
       "      <td>187077.629589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172933</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>76988.0</td>\n",
       "      <td>84079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>823822.25</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>219567.75</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>362654.0</td>\n",
       "      <td>255827.652601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172934</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>76988.0</td>\n",
       "      <td>84079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>823822.25</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>219567.75</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>241094.0</td>\n",
       "      <td>291710.736521</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172935</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>76988.0</td>\n",
       "      <td>84079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>823822.25</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>219567.75</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>338342.0</td>\n",
       "      <td>254321.610931</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172936 rows  76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month    year  starting_inventory    sellin  \\\n",
       "0        ABEAHAMASHL    5.0  2016.0           6844841.0  902583.0   \n",
       "1        ABEAHAMASHL    5.0  2016.0           6844841.0  902583.0   \n",
       "2        ABEAHAMASHL    5.0  2016.0           6844841.0  902583.0   \n",
       "3        ABEAHAMASHL    5.0  2016.0           6844841.0  902583.0   \n",
       "4         ABEANHARLE    5.0  2016.0                 0.0  388992.0   \n",
       "...              ...    ...     ...                 ...       ...   \n",
       "172931  YOSHLEENBART    4.0  2021.0            135742.0  152963.0   \n",
       "172932  YOSHRENECARL    4.0  2021.0             76988.0   84079.0   \n",
       "172933  YOSHRENECARL    4.0  2021.0             76988.0   84079.0   \n",
       "172934  YOSHRENECARL    4.0  2021.0             76988.0   84079.0   \n",
       "172935  YOSHRENECARL    4.0  2021.0             76988.0   84079.0   \n",
       "\n",
       "        sellin_channel_1  sellin_channel_2  sellin_channel_3  \\\n",
       "0               542968.0          236029.0           34442.0   \n",
       "1               542968.0          236029.0           34442.0   \n",
       "2               542968.0          236029.0           34442.0   \n",
       "3               542968.0          236029.0           34442.0   \n",
       "4               321121.0               0.0           38494.0   \n",
       "...                  ...               ...               ...   \n",
       "172931           25325.0           10130.0           66858.0   \n",
       "172932               0.0               0.0           40520.0   \n",
       "172933               0.0               0.0           40520.0   \n",
       "172934               0.0               0.0           40520.0   \n",
       "172935               0.0               0.0           40520.0   \n",
       "\n",
       "        sellin_channel_4  sellin_channel_5  ...  onhand_inventory_6month_MM  \\\n",
       "0                    0.0           14182.0  ...                  1529123.50   \n",
       "1                    0.0           14182.0  ...                  1529123.50   \n",
       "2                    0.0           14182.0  ...                  1529123.50   \n",
       "3                    0.0           14182.0  ...                  1529123.50   \n",
       "4                    0.0               0.0  ...                  1201924.50   \n",
       "...                  ...               ...  ...                         ...   \n",
       "172931            1013.0               0.0  ...                   252490.25   \n",
       "172932               0.0            1013.0  ...                   823822.25   \n",
       "172933               0.0            1013.0  ...                   823822.25   \n",
       "172934               0.0            1013.0  ...                   823822.25   \n",
       "172935               0.0            1013.0  ...                   823822.25   \n",
       "\n",
       "        onhand_inventory_9month_MM  leftover_inventory_6month_MM  \\\n",
       "0                        1584332.0                      50143.50   \n",
       "1                        1584332.0                      50143.50   \n",
       "2                        1584332.0                      50143.50   \n",
       "3                        1584332.0                      50143.50   \n",
       "4                        1192301.0                     -20260.00   \n",
       "...                            ...                           ...   \n",
       "172931                    251224.0                     191963.50   \n",
       "172932                    793179.0                     219567.75   \n",
       "172933                    793179.0                     219567.75   \n",
       "172934                    793179.0                     219567.75   \n",
       "172935                    793179.0                     219567.75   \n",
       "\n",
       "        leftover_inventory_9month_MM  price_6month_MM  price_9month_MM  \\\n",
       "0                            56728.0            145.0            145.0   \n",
       "1                            56728.0            145.0            145.0   \n",
       "2                            56728.0            145.0            145.0   \n",
       "3                            56728.0            145.0            145.0   \n",
       "4                            10130.0            125.0            125.0   \n",
       "...                              ...              ...              ...   \n",
       "172931                      141820.0            129.0            129.0   \n",
       "172932                      214756.0            129.0            129.0   \n",
       "172933                      214756.0            129.0            129.0   \n",
       "172934                      214756.0            129.0            129.0   \n",
       "172935                      214756.0            129.0            129.0   \n",
       "\n",
       "        sku_coded     target          preds  time_step  \n",
       "0            74.0   358602.0  993988.457097          0  \n",
       "1            74.0  1177106.0  963319.364140          1  \n",
       "2            74.0   968428.0  638536.972105          2  \n",
       "3            74.0   470032.0  613783.671361          3  \n",
       "4          1223.0   154989.0  420339.695346          0  \n",
       "...           ...        ...            ...        ...  \n",
       "172931      725.0   237042.0  132547.547953          3  \n",
       "172932      248.0   456863.0  187077.629589          0  \n",
       "172933      248.0   362654.0  255827.652601          1  \n",
       "172934      248.0   241094.0  291710.736521          2  \n",
       "172935      248.0   338342.0  254321.610931          3  \n",
       "\n",
       "[172936 rows x 76 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b222630-b626-4140-afa5-c9d7abeb76b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988d8ad-e7c0-4428-8b26-5edf803407a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = [f'target_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "pred_cols = [f'preds_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "\n",
    "for i,oof in enumerate([primary_oof, secondary_oof]):\n",
    "    meta_base = base_data.copy()\n",
    "    meta_base[pred_cols] = oof.reshape(-1, ModelsConfig.N_STEPS)\n",
    "    meta_padded = meta_base.groupby(['month','year']).apply(fossil_preproc.pad_sku_sequence, pad_value=np.nan)\n",
    "    meta_padded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    meta_primary = meta_padded.drop(columns=pred_cols)\n",
    "    meta_oof = meta_padded[pred_cols].values\n",
    "    meta_expanded = fossil_preproc.expand_primary_data(meta_primary, meta_oof, target_cols, pred_cols)\n",
    "    \n",
    "    if i==0:\n",
    "        meta_data = meta_expanded.drop(columns=['preds']).copy()\n",
    "        \n",
    "    meta_data[f'preds_{i}'] = meta_expanded['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22dfa0-c8f2-4739-8289-3e2e10a58d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3858 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "meta_data['target'] = meta_data.groupby('sku_name')['target'].progress_transform(lambda x: x.fillna(x.median()))\n",
    "meta_data['target'] = meta_data.groupby(['month','year'])['target'].progress_transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a39f805-e5a6-46d2-baed-b1bac23f211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data.fillna(0, inplace=True)\n",
    "\n",
    "meta_dates = sorted([(m, y) for y,m in meta_data.groupby(['year', 'month']).groups.keys()], key=lambda d: (d[1], d[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8759edf-404f-4ceb-84b7-fe414b05f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "meta_features = [c for c in meta_data.columns if 'preds' in c]\n",
    "meta_targets = 'target'\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "x_scaler.fit(meta_data[meta_features])\n",
    "y_scaler.fit(meta_data['target'].values.reshape(-1,1))\n",
    "\n",
    "meta_data[meta_features] = x_scaler.transform(meta_data[meta_features])\n",
    "meta_data[meta_targets] = y_scaler.transform(meta_data[meta_targets].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8d6d927-d51c-4028-b976-b42d056b6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['time_step'] = meta_data.groupby(['sku_name','sku_coded','month','year']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12f4f1b0-f5d0-4a8a-8372-d22cc601400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def get_data(\n",
    "        data:pd.DataFrame, \n",
    "        dates:list, \n",
    "        feature_cols:list, \n",
    "        target_cols:list, \n",
    "        validation:bool=False\n",
    "        ):\n",
    "    \n",
    "    data_list = []\n",
    "    y_test = None\n",
    "    \n",
    "    for date in tqdm(dates):\n",
    "        time_step_data = data[data[['month','year']].apply(tuple, axis=1).isin([date])]\n",
    "        time_step_avg = time_step_data.groupby(['sku_coded','time_step']).mean().reset_index()\n",
    "        \n",
    "        grouped_data = time_step_avg.sort_values(['sku_coded','year','month']).groupby(['sku_coded'])\n",
    "                \n",
    "        sequence = np.array([v[feature_cols] for k,v in grouped_data])\n",
    "        targets = time_step_avg[target_cols].values\n",
    "        \n",
    "        if validation:\n",
    "            y_test = time_step_data[time_step_data['sku_name']!=0]\n",
    "        data_list.append(((sequence, targets), y_test))\n",
    "        \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36e73a85-7aed-4eda-86e3-7dc90d66b680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_features = [c for c in meta_data.columns if 'preds' in c]\n",
    "meta_targets = 'target'\n",
    "\n",
    "meta_train = get_data(meta_data, meta_dates[:-1], meta_features, meta_targets)\n",
    "meta_val = get_data(meta_data, meta_dates[1:], meta_features, meta_targets, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f31e01d7-3607-440e-9cea-8fd69f1486e5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step 1 from 1.0/2016.0 to 1.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.1191\tVal Loss: 0.3690\tVal MAE: 4264309.90\telapsed: 0.02 mins\n",
      "Epoch 2: Train Loss: 0.3600\tVal Loss: 0.1409\tVal MAE: 1685420.66\telapsed: 0.02 mins\n",
      "Epoch 3: Train Loss: 0.1579\tVal Loss: 0.1086\tVal MAE: 1295376.10\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.1084\tVal Loss: 0.1070\tVal MAE: 1278222.50\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.1069\tVal Loss: 0.1053\tVal MAE: 1259055.51\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.1051\tVal Loss: 0.1035\tVal MAE: 1238796.28\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.1032\tVal Loss: 0.1016\tVal MAE: 1217961.49\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.1013\tVal Loss: 0.0997\tVal MAE: 1196713.11\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0994\tVal Loss: 0.0977\tVal MAE: 1175399.43\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0974\tVal Loss: 0.0957\tVal MAE: 1154044.64\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0954\tVal Loss: 0.0938\tVal MAE: 1132702.41\telapsed: 0.02 mins\n",
      "Epoch 12: Train Loss: 0.0934\tVal Loss: 0.0919\tVal MAE: 1111464.94\telapsed: 0.02 mins\n",
      "Epoch 13: Train Loss: 0.0915\tVal Loss: 0.0899\tVal MAE: 1090238.23\telapsed: 0.02 mins\n",
      "Epoch 14: Train Loss: 0.0895\tVal Loss: 0.0880\tVal MAE: 1069123.82\telapsed: 0.02 mins\n",
      "Epoch 15: Train Loss: 0.0876\tVal Loss: 0.0861\tVal MAE: 1048053.50\telapsed: 0.02 mins\n",
      "Epoch 16: Train Loss: 0.0856\tVal Loss: 0.0842\tVal MAE: 1027257.04\telapsed: 0.02 mins\n",
      "Epoch 17: Train Loss: 0.0837\tVal Loss: 0.0824\tVal MAE: 1006764.00\telapsed: 0.02 mins\n",
      "Epoch 18: Train Loss: 0.0818\tVal Loss: 0.0805\tVal MAE: 986589.94\telapsed: 0.02 mins\n",
      "Epoch 19: Train Loss: 0.0800\tVal Loss: 0.0787\tVal MAE: 966645.32\telapsed: 0.02 mins\n",
      "Epoch 20: Train Loss: 0.0781\tVal Loss: 0.0769\tVal MAE: 946935.83\telapsed: 0.02 mins\n",
      "Epoch 21: Train Loss: 0.0763\tVal Loss: 0.0751\tVal MAE: 927480.92\telapsed: 0.02 mins\n",
      "Epoch 22: Train Loss: 0.0745\tVal Loss: 0.0733\tVal MAE: 908318.10\telapsed: 0.02 mins\n",
      "Epoch 23: Train Loss: 0.0727\tVal Loss: 0.0716\tVal MAE: 889285.98\telapsed: 0.02 mins\n",
      "Epoch 24: Train Loss: 0.0709\tVal Loss: 0.0699\tVal MAE: 870364.13\telapsed: 0.02 mins\n",
      "Epoch 25: Train Loss: 0.0691\tVal Loss: 0.0681\tVal MAE: 851504.22\telapsed: 0.02 mins\n",
      "Epoch 26: Train Loss: 0.0674\tVal Loss: 0.0664\tVal MAE: 832868.41\telapsed: 0.02 mins\n",
      "Epoch 27: Train Loss: 0.0657\tVal Loss: 0.0648\tVal MAE: 814646.76\telapsed: 0.02 mins\n",
      "Epoch 28: Train Loss: 0.0640\tVal Loss: 0.0631\tVal MAE: 796794.87\telapsed: 0.02 mins\n",
      "Epoch 29: Train Loss: 0.0623\tVal Loss: 0.0615\tVal MAE: 779217.52\telapsed: 0.02 mins\n",
      "Epoch 30: Train Loss: 0.0607\tVal Loss: 0.0599\tVal MAE: 761945.44\telapsed: 0.02 mins\n",
      "Epoch 31: Train Loss: 0.0591\tVal Loss: 0.0583\tVal MAE: 744871.82\telapsed: 0.02 mins\n",
      "Epoch 32: Train Loss: 0.0575\tVal Loss: 0.0568\tVal MAE: 728115.18\telapsed: 0.02 mins\n",
      "Epoch 33: Train Loss: 0.0559\tVal Loss: 0.0553\tVal MAE: 711569.06\telapsed: 0.02 mins\n",
      "Epoch 34: Train Loss: 0.0543\tVal Loss: 0.0537\tVal MAE: 695525.30\telapsed: 0.02 mins\n",
      "Epoch 35: Train Loss: 0.0528\tVal Loss: 0.0523\tVal MAE: 679835.60\telapsed: 0.02 mins\n",
      "Epoch 36: Train Loss: 0.0512\tVal Loss: 0.0508\tVal MAE: 664322.13\telapsed: 0.02 mins\n",
      "Epoch 37: Train Loss: 0.0497\tVal Loss: 0.0493\tVal MAE: 648726.51\telapsed: 0.02 mins\n",
      "Epoch 38: Train Loss: 0.0482\tVal Loss: 0.0479\tVal MAE: 633334.28\telapsed: 0.02 mins\n",
      "Epoch 39: Train Loss: 0.0468\tVal Loss: 0.0465\tVal MAE: 618357.13\telapsed: 0.02 mins\n",
      "Epoch 40: Train Loss: 0.0453\tVal Loss: 0.0451\tVal MAE: 603595.19\telapsed: 0.02 mins\n",
      "Epoch 41: Train Loss: 0.0439\tVal Loss: 0.0437\tVal MAE: 589027.88\telapsed: 0.02 mins\n",
      "Epoch 42: Train Loss: 0.0425\tVal Loss: 0.0424\tVal MAE: 574860.28\telapsed: 0.02 mins\n",
      "Epoch 43: Train Loss: 0.0411\tVal Loss: 0.0411\tVal MAE: 561051.60\telapsed: 0.02 mins\n",
      "Epoch 44: Train Loss: 0.0398\tVal Loss: 0.0398\tVal MAE: 547456.80\telapsed: 0.02 mins\n",
      "Epoch 45: Train Loss: 0.0385\tVal Loss: 0.0385\tVal MAE: 534168.84\telapsed: 0.02 mins\n",
      "Epoch 46: Train Loss: 0.0372\tVal Loss: 0.0373\tVal MAE: 521080.63\telapsed: 0.02 mins\n",
      "Epoch 47: Train Loss: 0.0359\tVal Loss: 0.0361\tVal MAE: 508213.70\telapsed: 0.02 mins\n",
      "Epoch 48: Train Loss: 0.0347\tVal Loss: 0.0349\tVal MAE: 495651.03\telapsed: 0.02 mins\n",
      "Epoch 49: Train Loss: 0.0334\tVal Loss: 0.0337\tVal MAE: 483422.83\telapsed: 0.02 mins\n",
      "Epoch 50: Train Loss: 0.0322\tVal Loss: 0.0325\tVal MAE: 471327.14\telapsed: 0.02 mins\n",
      "Epoch 51: Train Loss: 0.0310\tVal Loss: 0.0314\tVal MAE: 459393.26\telapsed: 0.02 mins\n",
      "Epoch 52: Train Loss: 0.0299\tVal Loss: 0.0303\tVal MAE: 447796.95\telapsed: 0.03 mins\n",
      "Epoch 53: Train Loss: 0.0287\tVal Loss: 0.0292\tVal MAE: 436467.09\telapsed: 0.03 mins\n",
      "Epoch 54: Train Loss: 0.0276\tVal Loss: 0.0282\tVal MAE: 425515.83\telapsed: 0.03 mins\n",
      "Epoch 55: Train Loss: 0.0265\tVal Loss: 0.0272\tVal MAE: 414821.70\telapsed: 0.03 mins\n",
      "Epoch 56: Train Loss: 0.0255\tVal Loss: 0.0262\tVal MAE: 404546.36\telapsed: 0.03 mins\n",
      "Epoch 57: Train Loss: 0.0244\tVal Loss: 0.0253\tVal MAE: 394488.25\telapsed: 0.03 mins\n",
      "Epoch 58: Train Loss: 0.0235\tVal Loss: 0.0244\tVal MAE: 384886.93\telapsed: 0.03 mins\n",
      "Epoch 59: Train Loss: 0.0225\tVal Loss: 0.0235\tVal MAE: 375684.15\telapsed: 0.03 mins\n",
      "Epoch 60: Train Loss: 0.0216\tVal Loss: 0.0226\tVal MAE: 366829.68\telapsed: 0.03 mins\n",
      "Epoch 61: Train Loss: 0.0207\tVal Loss: 0.0218\tVal MAE: 358136.37\telapsed: 0.03 mins\n",
      "Epoch 62: Train Loss: 0.0198\tVal Loss: 0.0210\tVal MAE: 349612.01\telapsed: 0.03 mins\n",
      "Epoch 63: Train Loss: 0.0189\tVal Loss: 0.0202\tVal MAE: 341320.27\telapsed: 0.03 mins\n",
      "Epoch 64: Train Loss: 0.0181\tVal Loss: 0.0194\tVal MAE: 333443.21\telapsed: 0.03 mins\n",
      "Epoch 65: Train Loss: 0.0173\tVal Loss: 0.0187\tVal MAE: 325792.61\telapsed: 0.03 mins\n",
      "Epoch 66: Train Loss: 0.0165\tVal Loss: 0.0180\tVal MAE: 318292.60\telapsed: 0.03 mins\n",
      "Epoch 67: Train Loss: 0.0158\tVal Loss: 0.0173\tVal MAE: 310815.00\telapsed: 0.03 mins\n",
      "Epoch 68: Train Loss: 0.0150\tVal Loss: 0.0166\tVal MAE: 303667.16\telapsed: 0.03 mins\n",
      "Epoch 69: Train Loss: 0.0143\tVal Loss: 0.0160\tVal MAE: 296851.86\telapsed: 0.03 mins\n",
      "Epoch 70: Train Loss: 0.0136\tVal Loss: 0.0154\tVal MAE: 290294.51\telapsed: 0.03 mins\n",
      "Epoch 71: Train Loss: 0.0130\tVal Loss: 0.0148\tVal MAE: 283899.00\telapsed: 0.03 mins\n",
      "Epoch 72: Train Loss: 0.0124\tVal Loss: 0.0142\tVal MAE: 277652.28\telapsed: 0.03 mins\n",
      "Epoch 73: Train Loss: 0.0118\tVal Loss: 0.0137\tVal MAE: 271609.24\telapsed: 0.03 mins\n",
      "Epoch 74: Train Loss: 0.0112\tVal Loss: 0.0131\tVal MAE: 265806.97\telapsed: 0.03 mins\n",
      "Epoch 75: Train Loss: 0.0107\tVal Loss: 0.0126\tVal MAE: 260001.85\telapsed: 0.03 mins\n",
      "Epoch 76: Train Loss: 0.0101\tVal Loss: 0.0122\tVal MAE: 254510.84\telapsed: 0.03 mins\n",
      "Epoch 77: Train Loss: 0.0096\tVal Loss: 0.0117\tVal MAE: 249303.80\telapsed: 0.03 mins\n",
      "Epoch 78: Train Loss: 0.0091\tVal Loss: 0.0113\tVal MAE: 244285.30\telapsed: 0.03 mins\n",
      "Epoch 79: Train Loss: 0.0087\tVal Loss: 0.0108\tVal MAE: 239382.47\telapsed: 0.03 mins\n",
      "Epoch 80: Train Loss: 0.0082\tVal Loss: 0.0105\tVal MAE: 234773.49\telapsed: 0.03 mins\n",
      "Epoch 81: Train Loss: 0.0078\tVal Loss: 0.0101\tVal MAE: 230492.02\telapsed: 0.03 mins\n",
      "Epoch 82: Train Loss: 0.0074\tVal Loss: 0.0097\tVal MAE: 226419.28\telapsed: 0.03 mins\n",
      "Epoch 83: Train Loss: 0.0070\tVal Loss: 0.0094\tVal MAE: 222576.27\telapsed: 0.03 mins\n",
      "Epoch 84: Train Loss: 0.0066\tVal Loss: 0.0091\tVal MAE: 218973.90\telapsed: 0.03 mins\n",
      "Epoch 85: Train Loss: 0.0063\tVal Loss: 0.0088\tVal MAE: 215553.52\telapsed: 0.03 mins\n",
      "Epoch 86: Train Loss: 0.0059\tVal Loss: 0.0085\tVal MAE: 212303.15\telapsed: 0.03 mins\n",
      "Epoch 87: Train Loss: 0.0056\tVal Loss: 0.0083\tVal MAE: 209261.94\telapsed: 0.03 mins\n",
      "Epoch 88: Train Loss: 0.0053\tVal Loss: 0.0080\tVal MAE: 206548.34\telapsed: 0.03 mins\n",
      "Epoch 89: Train Loss: 0.0050\tVal Loss: 0.0078\tVal MAE: 204152.51\telapsed: 0.03 mins\n",
      "Epoch 90: Train Loss: 0.0048\tVal Loss: 0.0076\tVal MAE: 201766.50\telapsed: 0.03 mins\n",
      "Epoch 91: Train Loss: 0.0045\tVal Loss: 0.0073\tVal MAE: 199218.24\telapsed: 0.03 mins\n",
      "Epoch 92: Train Loss: 0.0042\tVal Loss: 0.0071\tVal MAE: 196643.08\telapsed: 0.03 mins\n",
      "Epoch 93: Train Loss: 0.0040\tVal Loss: 0.0069\tVal MAE: 194088.35\telapsed: 0.03 mins\n",
      "Epoch 94: Train Loss: 0.0038\tVal Loss: 0.0068\tVal MAE: 191834.85\telapsed: 0.03 mins\n",
      "Epoch 95: Train Loss: 0.0036\tVal Loss: 0.0066\tVal MAE: 189892.26\telapsed: 0.03 mins\n",
      "Epoch 96: Train Loss: 0.0034\tVal Loss: 0.0065\tVal MAE: 188092.66\telapsed: 0.03 mins\n",
      "Epoch 97: Train Loss: 0.0032\tVal Loss: 0.0063\tVal MAE: 186263.55\telapsed: 0.03 mins\n",
      "Epoch 98: Train Loss: 0.0030\tVal Loss: 0.0062\tVal MAE: 184516.95\telapsed: 0.03 mins\n",
      "Epoch 99: Train Loss: 0.0028\tVal Loss: 0.0060\tVal MAE: 182835.51\telapsed: 0.03 mins\n",
      "Epoch 100: Train Loss: 0.0027\tVal Loss: 0.0059\tVal MAE: 181376.78\telapsed: 0.03 mins\n",
      "Epoch 101: Train Loss: 0.0025\tVal Loss: 0.0058\tVal MAE: 180031.80\telapsed: 0.03 mins\n",
      "Epoch 102: Train Loss: 0.0024\tVal Loss: 0.0057\tVal MAE: 178656.50\telapsed: 0.03 mins\n",
      "Epoch 103: Train Loss: 0.0023\tVal Loss: 0.0056\tVal MAE: 177327.48\telapsed: 0.03 mins\n",
      "Epoch 104: Train Loss: 0.0021\tVal Loss: 0.0055\tVal MAE: 176083.70\telapsed: 0.03 mins\n",
      "Epoch 105: Train Loss: 0.0020\tVal Loss: 0.0054\tVal MAE: 174888.79\telapsed: 0.03 mins\n",
      "Epoch 106: Train Loss: 0.0019\tVal Loss: 0.0054\tVal MAE: 173693.99\telapsed: 0.03 mins\n",
      "Epoch 107: Train Loss: 0.0018\tVal Loss: 0.0053\tVal MAE: 172566.36\telapsed: 0.03 mins\n",
      "Epoch 108: Train Loss: 0.0017\tVal Loss: 0.0052\tVal MAE: 171535.70\telapsed: 0.03 mins\n",
      "Epoch 109: Train Loss: 0.0016\tVal Loss: 0.0052\tVal MAE: 170546.64\telapsed: 0.03 mins\n",
      "Epoch 110: Train Loss: 0.0015\tVal Loss: 0.0051\tVal MAE: 169511.28\telapsed: 0.03 mins\n",
      "Epoch 111: Train Loss: 0.0015\tVal Loss: 0.0050\tVal MAE: 168626.94\telapsed: 0.03 mins\n",
      "Epoch 112: Train Loss: 0.0014\tVal Loss: 0.0050\tVal MAE: 167914.70\telapsed: 0.03 mins\n",
      "Epoch 113: Train Loss: 0.0013\tVal Loss: 0.0049\tVal MAE: 167219.85\telapsed: 0.03 mins\n",
      "Epoch 114: Train Loss: 0.0012\tVal Loss: 0.0049\tVal MAE: 166566.73\telapsed: 0.03 mins\n",
      "Epoch 115: Train Loss: 0.0012\tVal Loss: 0.0049\tVal MAE: 165916.57\telapsed: 0.03 mins\n",
      "Epoch 116: Train Loss: 0.0011\tVal Loss: 0.0048\tVal MAE: 165345.96\telapsed: 0.03 mins\n",
      "Epoch 117: Train Loss: 0.0011\tVal Loss: 0.0048\tVal MAE: 164818.76\telapsed: 0.04 mins\n",
      "Epoch 118: Train Loss: 0.0010\tVal Loss: 0.0048\tVal MAE: 164402.64\telapsed: 0.04 mins\n",
      "Epoch 119: Train Loss: 0.0010\tVal Loss: 0.0047\tVal MAE: 164017.81\telapsed: 0.04 mins\n",
      "Epoch 120: Train Loss: 0.0009\tVal Loss: 0.0047\tVal MAE: 163602.92\telapsed: 0.04 mins\n",
      "Epoch 121: Train Loss: 0.0009\tVal Loss: 0.0047\tVal MAE: 163078.09\telapsed: 0.04 mins\n",
      "Epoch 122: Train Loss: 0.0009\tVal Loss: 0.0047\tVal MAE: 162521.29\telapsed: 0.04 mins\n",
      "Epoch 123: Train Loss: 0.0008\tVal Loss: 0.0047\tVal MAE: 162046.30\telapsed: 0.04 mins\n",
      "Epoch 124: Train Loss: 0.0008\tVal Loss: 0.0047\tVal MAE: 161691.93\telapsed: 0.04 mins\n",
      "Epoch 125: Train Loss: 0.0008\tVal Loss: 0.0046\tVal MAE: 161353.36\telapsed: 0.04 mins\n",
      "Epoch 126: Train Loss: 0.0007\tVal Loss: 0.0046\tVal MAE: 160948.37\telapsed: 0.04 mins\n",
      "Epoch 127: Train Loss: 0.0007\tVal Loss: 0.0046\tVal MAE: 160635.18\telapsed: 0.04 mins\n",
      "Epoch 128: Train Loss: 0.0007\tVal Loss: 0.0046\tVal MAE: 160441.40\telapsed: 0.04 mins\n",
      "Epoch 129: Train Loss: 0.0007\tVal Loss: 0.0046\tVal MAE: 160285.10\telapsed: 0.04 mins\n",
      "Epoch 130: Train Loss: 0.0006\tVal Loss: 0.0046\tVal MAE: 160139.74\telapsed: 0.04 mins\n",
      "Epoch 131: Train Loss: 0.0006\tVal Loss: 0.0046\tVal MAE: 159967.92\telapsed: 0.04 mins\n",
      "Epoch 132: Train Loss: 0.0006\tVal Loss: 0.0046\tVal MAE: 159713.89\telapsed: 0.04 mins\n",
      "Epoch 133: Train Loss: 0.0006\tVal Loss: 0.0045\tVal MAE: 159468.11\telapsed: 0.04 mins\n",
      "Epoch 134: Train Loss: 0.0006\tVal Loss: 0.0045\tVal MAE: 159221.34\telapsed: 0.04 mins\n",
      "Epoch 135: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 159131.73\telapsed: 0.04 mins\n",
      "Epoch 136: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 159093.76\telapsed: 0.04 mins\n",
      "Epoch 137: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 158982.41\telapsed: 0.04 mins\n",
      "Epoch 138: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 158816.58\telapsed: 0.04 mins\n",
      "Epoch 139: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 158628.32\telapsed: 0.04 mins\n",
      "Epoch 140: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 158522.43\telapsed: 0.04 mins\n",
      "Epoch 141: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 158541.04\telapsed: 0.04 mins\n",
      "Epoch 142: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 158508.88\telapsed: 0.04 mins\n",
      "Epoch 143: Train Loss: 0.0005\tVal Loss: 0.0045\tVal MAE: 158486.76\telapsed: 0.04 mins\n",
      "Epoch 144: Train Loss: 0.0004\tVal Loss: 0.0045\tVal MAE: 158472.50\telapsed: 0.04 mins\n",
      "Epoch 145: Train Loss: 0.0004\tVal Loss: 0.0045\tVal MAE: 158387.25\telapsed: 0.04 mins\n",
      "Epoch 146: Train Loss: 0.0004\tVal Loss: 0.0045\tVal MAE: 158334.90\telapsed: 0.04 mins\n",
      "Epoch 147: Train Loss: 0.0004\tVal Loss: 0.0045\tVal MAE: 158394.54\telapsed: 0.04 mins\n",
      "Epoch 148: Train Loss: 0.0004\tVal Loss: 0.0045\tVal MAE: 158476.04\telapsed: 0.04 mins\n",
      "Epoch 149: Train Loss: 0.0004\tVal Loss: 0.0045\tVal MAE: 158528.51\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 146\tVal loss: 0.0045\tVal MAE: 158334.90\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 2 from 1.0/2016.0 to 2.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.5644\tVal Loss: 0.2063\tVal MAE: 2374873.82\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.1077\tVal Loss: 0.1064\tVal MAE: 1264955.56\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.1050\tVal Loss: 0.1035\tVal MAE: 1232647.32\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.1018\tVal Loss: 0.1002\tVal MAE: 1196991.79\telapsed: 0.00 mins\n",
      "Epoch 5: Train Loss: 0.0985\tVal Loss: 0.0968\tVal MAE: 1159774.31\telapsed: 0.00 mins\n",
      "Epoch 6: Train Loss: 0.0950\tVal Loss: 0.0934\tVal MAE: 1122084.79\telapsed: 0.00 mins\n",
      "Epoch 7: Train Loss: 0.0915\tVal Loss: 0.0899\tVal MAE: 1084383.39\telapsed: 0.00 mins\n",
      "Epoch 8: Train Loss: 0.0881\tVal Loss: 0.0865\tVal MAE: 1046917.51\telapsed: 0.00 mins\n",
      "Epoch 9: Train Loss: 0.0847\tVal Loss: 0.0832\tVal MAE: 1009817.56\telapsed: 0.00 mins\n",
      "Epoch 10: Train Loss: 0.0813\tVal Loss: 0.0798\tVal MAE: 973051.65\telapsed: 0.00 mins\n",
      "Epoch 11: Train Loss: 0.0780\tVal Loss: 0.0765\tVal MAE: 936993.94\telapsed: 0.00 mins\n",
      "Epoch 12: Train Loss: 0.0748\tVal Loss: 0.0733\tVal MAE: 901993.15\telapsed: 0.00 mins\n",
      "Epoch 13: Train Loss: 0.0715\tVal Loss: 0.0701\tVal MAE: 867859.05\telapsed: 0.00 mins\n",
      "Epoch 14: Train Loss: 0.0684\tVal Loss: 0.0670\tVal MAE: 834192.79\telapsed: 0.00 mins\n",
      "Epoch 15: Train Loss: 0.0652\tVal Loss: 0.0639\tVal MAE: 801331.13\telapsed: 0.00 mins\n",
      "Epoch 16: Train Loss: 0.0622\tVal Loss: 0.0609\tVal MAE: 769037.67\telapsed: 0.00 mins\n",
      "Epoch 17: Train Loss: 0.0592\tVal Loss: 0.0580\tVal MAE: 737421.03\telapsed: 0.00 mins\n",
      "Epoch 18: Train Loss: 0.0562\tVal Loss: 0.0551\tVal MAE: 706674.20\telapsed: 0.01 mins\n",
      "Epoch 19: Train Loss: 0.0533\tVal Loss: 0.0522\tVal MAE: 676744.01\telapsed: 0.01 mins\n",
      "Epoch 20: Train Loss: 0.0505\tVal Loss: 0.0495\tVal MAE: 646910.56\telapsed: 0.01 mins\n",
      "Epoch 21: Train Loss: 0.0478\tVal Loss: 0.0468\tVal MAE: 617494.22\telapsed: 0.01 mins\n",
      "Epoch 22: Train Loss: 0.0451\tVal Loss: 0.0442\tVal MAE: 589126.44\telapsed: 0.01 mins\n",
      "Epoch 23: Train Loss: 0.0424\tVal Loss: 0.0416\tVal MAE: 561614.16\telapsed: 0.01 mins\n",
      "Epoch 24: Train Loss: 0.0399\tVal Loss: 0.0391\tVal MAE: 535264.23\telapsed: 0.01 mins\n",
      "Epoch 25: Train Loss: 0.0374\tVal Loss: 0.0367\tVal MAE: 510099.56\telapsed: 0.01 mins\n",
      "Epoch 26: Train Loss: 0.0350\tVal Loss: 0.0344\tVal MAE: 485669.96\telapsed: 0.01 mins\n",
      "Epoch 27: Train Loss: 0.0327\tVal Loss: 0.0322\tVal MAE: 462403.50\telapsed: 0.01 mins\n",
      "Epoch 28: Train Loss: 0.0305\tVal Loss: 0.0301\tVal MAE: 439919.87\telapsed: 0.01 mins\n",
      "Epoch 29: Train Loss: 0.0284\tVal Loss: 0.0280\tVal MAE: 418312.66\telapsed: 0.01 mins\n",
      "Epoch 30: Train Loss: 0.0264\tVal Loss: 0.0261\tVal MAE: 397576.88\telapsed: 0.01 mins\n",
      "Epoch 31: Train Loss: 0.0245\tVal Loss: 0.0243\tVal MAE: 378030.67\telapsed: 0.01 mins\n",
      "Epoch 32: Train Loss: 0.0227\tVal Loss: 0.0225\tVal MAE: 359509.66\telapsed: 0.01 mins\n",
      "Epoch 33: Train Loss: 0.0209\tVal Loss: 0.0209\tVal MAE: 342020.08\telapsed: 0.01 mins\n",
      "Epoch 34: Train Loss: 0.0193\tVal Loss: 0.0194\tVal MAE: 325139.42\telapsed: 0.01 mins\n",
      "Epoch 35: Train Loss: 0.0178\tVal Loss: 0.0179\tVal MAE: 309026.85\telapsed: 0.01 mins\n",
      "Epoch 36: Train Loss: 0.0164\tVal Loss: 0.0165\tVal MAE: 293889.60\telapsed: 0.01 mins\n",
      "Epoch 37: Train Loss: 0.0151\tVal Loss: 0.0153\tVal MAE: 279599.35\telapsed: 0.01 mins\n",
      "Epoch 38: Train Loss: 0.0139\tVal Loss: 0.0141\tVal MAE: 266679.61\telapsed: 0.01 mins\n",
      "Epoch 39: Train Loss: 0.0127\tVal Loss: 0.0130\tVal MAE: 254928.04\telapsed: 0.01 mins\n",
      "Epoch 40: Train Loss: 0.0117\tVal Loss: 0.0120\tVal MAE: 244002.06\telapsed: 0.01 mins\n",
      "Epoch 41: Train Loss: 0.0107\tVal Loss: 0.0111\tVal MAE: 234231.49\telapsed: 0.01 mins\n",
      "Epoch 42: Train Loss: 0.0098\tVal Loss: 0.0103\tVal MAE: 225132.54\telapsed: 0.01 mins\n",
      "Epoch 43: Train Loss: 0.0089\tVal Loss: 0.0095\tVal MAE: 216814.92\telapsed: 0.01 mins\n",
      "Epoch 44: Train Loss: 0.0082\tVal Loss: 0.0088\tVal MAE: 209280.30\telapsed: 0.01 mins\n",
      "Epoch 45: Train Loss: 0.0074\tVal Loss: 0.0081\tVal MAE: 202251.46\telapsed: 0.01 mins\n",
      "Epoch 46: Train Loss: 0.0068\tVal Loss: 0.0075\tVal MAE: 195737.75\telapsed: 0.01 mins\n",
      "Epoch 47: Train Loss: 0.0063\tVal Loss: 0.0071\tVal MAE: 189773.15\telapsed: 0.01 mins\n",
      "Epoch 48: Train Loss: 0.0058\tVal Loss: 0.0066\tVal MAE: 184335.66\telapsed: 0.01 mins\n",
      "Epoch 49: Train Loss: 0.0054\tVal Loss: 0.0062\tVal MAE: 179628.24\telapsed: 0.01 mins\n",
      "Epoch 50: Train Loss: 0.0050\tVal Loss: 0.0058\tVal MAE: 175281.65\telapsed: 0.01 mins\n",
      "Epoch 51: Train Loss: 0.0047\tVal Loss: 0.0055\tVal MAE: 171358.78\telapsed: 0.01 mins\n",
      "Epoch 52: Train Loss: 0.0044\tVal Loss: 0.0052\tVal MAE: 168092.15\telapsed: 0.01 mins\n",
      "Epoch 53: Train Loss: 0.0041\tVal Loss: 0.0050\tVal MAE: 165338.13\telapsed: 0.01 mins\n",
      "Epoch 54: Train Loss: 0.0038\tVal Loss: 0.0048\tVal MAE: 162833.39\telapsed: 0.01 mins\n",
      "Epoch 55: Train Loss: 0.0036\tVal Loss: 0.0046\tVal MAE: 160398.91\telapsed: 0.02 mins\n",
      "Epoch 56: Train Loss: 0.0034\tVal Loss: 0.0045\tVal MAE: 158341.12\telapsed: 0.02 mins\n",
      "Epoch 57: Train Loss: 0.0033\tVal Loss: 0.0043\tVal MAE: 156560.96\telapsed: 0.02 mins\n",
      "Epoch 58: Train Loss: 0.0032\tVal Loss: 0.0042\tVal MAE: 154789.14\telapsed: 0.02 mins\n",
      "Epoch 59: Train Loss: 0.0030\tVal Loss: 0.0041\tVal MAE: 153192.22\telapsed: 0.02 mins\n",
      "Epoch 60: Train Loss: 0.0029\tVal Loss: 0.0040\tVal MAE: 151859.02\telapsed: 0.02 mins\n",
      "Epoch 61: Train Loss: 0.0029\tVal Loss: 0.0039\tVal MAE: 150744.18\telapsed: 0.02 mins\n",
      "Epoch 62: Train Loss: 0.0028\tVal Loss: 0.0038\tVal MAE: 149758.42\telapsed: 0.02 mins\n",
      "Epoch 63: Train Loss: 0.0027\tVal Loss: 0.0038\tVal MAE: 148948.00\telapsed: 0.02 mins\n",
      "Epoch 64: Train Loss: 0.0027\tVal Loss: 0.0037\tVal MAE: 148275.66\telapsed: 0.02 mins\n",
      "Epoch 65: Train Loss: 0.0026\tVal Loss: 0.0037\tVal MAE: 147676.19\telapsed: 0.02 mins\n",
      "Epoch 66: Train Loss: 0.0026\tVal Loss: 0.0036\tVal MAE: 147165.73\telapsed: 0.02 mins\n",
      "Epoch 67: Train Loss: 0.0026\tVal Loss: 0.0036\tVal MAE: 146884.32\telapsed: 0.02 mins\n",
      "Epoch 68: Train Loss: 0.0025\tVal Loss: 0.0036\tVal MAE: 146466.89\telapsed: 0.02 mins\n",
      "Epoch 69: Train Loss: 0.0025\tVal Loss: 0.0036\tVal MAE: 146133.99\telapsed: 0.02 mins\n",
      "Epoch 70: Train Loss: 0.0025\tVal Loss: 0.0036\tVal MAE: 145884.37\telapsed: 0.02 mins\n",
      "Epoch 71: Train Loss: 0.0025\tVal Loss: 0.0036\tVal MAE: 145616.74\telapsed: 0.02 mins\n",
      "Epoch 72: Train Loss: 0.0025\tVal Loss: 0.0035\tVal MAE: 145503.82\telapsed: 0.02 mins\n",
      "Epoch 73: Train Loss: 0.0024\tVal Loss: 0.0035\tVal MAE: 145330.46\telapsed: 0.02 mins\n",
      "Epoch 74: Train Loss: 0.0024\tVal Loss: 0.0035\tVal MAE: 145187.50\telapsed: 0.02 mins\n",
      "Epoch 75: Train Loss: 0.0024\tVal Loss: 0.0035\tVal MAE: 145108.85\telapsed: 0.02 mins\n",
      "Epoch 76: Train Loss: 0.0024\tVal Loss: 0.0035\tVal MAE: 145096.61\telapsed: 0.02 mins\n",
      "Epoch 77: Train Loss: 0.0024\tVal Loss: 0.0035\tVal MAE: 145117.54\telapsed: 0.02 mins\n",
      "Epoch 78: Train Loss: 0.0024\tVal Loss: 0.0035\tVal MAE: 145180.91\telapsed: 0.02 mins\n",
      "Epoch 79: Train Loss: 0.0024\tVal Loss: 0.0035\tVal MAE: 145143.09\telapsed: 0.02 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 76\tVal loss: 0.0035\tVal MAE: 145096.61\tTotal time elapsed: 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 3 from 1.0/2016.0 to 3.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.6308\tVal Loss: 0.3807\tVal MAE: 4296192.92\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.1191\tVal Loss: 0.1067\tVal MAE: 1250821.99\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.1014\tVal Loss: 0.1001\tVal MAE: 1169144.82\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0980\tVal Loss: 0.0965\tVal MAE: 1128343.31\telapsed: 0.00 mins\n",
      "Epoch 5: Train Loss: 0.0940\tVal Loss: 0.0924\tVal MAE: 1082568.45\telapsed: 0.00 mins\n",
      "Epoch 6: Train Loss: 0.0898\tVal Loss: 0.0881\tVal MAE: 1034792.07\telapsed: 0.00 mins\n",
      "Epoch 7: Train Loss: 0.0854\tVal Loss: 0.0838\tVal MAE: 986631.11\telapsed: 0.00 mins\n",
      "Epoch 8: Train Loss: 0.0811\tVal Loss: 0.0796\tVal MAE: 938802.00\telapsed: 0.00 mins\n",
      "Epoch 9: Train Loss: 0.0768\tVal Loss: 0.0753\tVal MAE: 891598.47\telapsed: 0.00 mins\n",
      "Epoch 10: Train Loss: 0.0726\tVal Loss: 0.0711\tVal MAE: 844730.55\telapsed: 0.00 mins\n",
      "Epoch 11: Train Loss: 0.0684\tVal Loss: 0.0670\tVal MAE: 798545.67\telapsed: 0.00 mins\n",
      "Epoch 12: Train Loss: 0.0643\tVal Loss: 0.0630\tVal MAE: 753409.02\telapsed: 0.00 mins\n",
      "Epoch 13: Train Loss: 0.0603\tVal Loss: 0.0591\tVal MAE: 709212.68\telapsed: 0.01 mins\n",
      "Epoch 14: Train Loss: 0.0564\tVal Loss: 0.0552\tVal MAE: 665685.06\telapsed: 0.01 mins\n",
      "Epoch 15: Train Loss: 0.0525\tVal Loss: 0.0514\tVal MAE: 622863.73\telapsed: 0.01 mins\n",
      "Epoch 16: Train Loss: 0.0488\tVal Loss: 0.0478\tVal MAE: 581404.95\telapsed: 0.01 mins\n",
      "Epoch 17: Train Loss: 0.0451\tVal Loss: 0.0442\tVal MAE: 541377.19\telapsed: 0.01 mins\n",
      "Epoch 18: Train Loss: 0.0416\tVal Loss: 0.0408\tVal MAE: 503171.92\telapsed: 0.01 mins\n",
      "Epoch 19: Train Loss: 0.0382\tVal Loss: 0.0375\tVal MAE: 466599.42\telapsed: 0.01 mins\n",
      "Epoch 20: Train Loss: 0.0350\tVal Loss: 0.0344\tVal MAE: 431545.12\telapsed: 0.01 mins\n",
      "Epoch 21: Train Loss: 0.0320\tVal Loss: 0.0314\tVal MAE: 398094.57\telapsed: 0.01 mins\n",
      "Epoch 22: Train Loss: 0.0290\tVal Loss: 0.0286\tVal MAE: 366706.12\telapsed: 0.01 mins\n",
      "Epoch 23: Train Loss: 0.0263\tVal Loss: 0.0260\tVal MAE: 336985.50\telapsed: 0.01 mins\n",
      "Epoch 24: Train Loss: 0.0237\tVal Loss: 0.0235\tVal MAE: 309309.79\telapsed: 0.01 mins\n",
      "Epoch 25: Train Loss: 0.0213\tVal Loss: 0.0213\tVal MAE: 283701.12\telapsed: 0.01 mins\n",
      "Epoch 26: Train Loss: 0.0191\tVal Loss: 0.0191\tVal MAE: 259788.66\telapsed: 0.01 mins\n",
      "Epoch 27: Train Loss: 0.0171\tVal Loss: 0.0172\tVal MAE: 237498.35\telapsed: 0.01 mins\n",
      "Epoch 28: Train Loss: 0.0152\tVal Loss: 0.0155\tVal MAE: 217286.61\telapsed: 0.01 mins\n",
      "Epoch 29: Train Loss: 0.0135\tVal Loss: 0.0139\tVal MAE: 199328.30\telapsed: 0.01 mins\n",
      "Epoch 30: Train Loss: 0.0120\tVal Loss: 0.0125\tVal MAE: 183459.81\telapsed: 0.01 mins\n",
      "Epoch 31: Train Loss: 0.0106\tVal Loss: 0.0112\tVal MAE: 169373.36\telapsed: 0.01 mins\n",
      "Epoch 32: Train Loss: 0.0094\tVal Loss: 0.0102\tVal MAE: 156925.51\telapsed: 0.01 mins\n",
      "Epoch 33: Train Loss: 0.0084\tVal Loss: 0.0092\tVal MAE: 145962.49\telapsed: 0.01 mins\n",
      "Epoch 34: Train Loss: 0.0074\tVal Loss: 0.0084\tVal MAE: 135841.57\telapsed: 0.01 mins\n",
      "Epoch 35: Train Loss: 0.0066\tVal Loss: 0.0076\tVal MAE: 126857.06\telapsed: 0.01 mins\n",
      "Epoch 36: Train Loss: 0.0058\tVal Loss: 0.0069\tVal MAE: 119435.94\telapsed: 0.01 mins\n",
      "Epoch 37: Train Loss: 0.0052\tVal Loss: 0.0064\tVal MAE: 113237.11\telapsed: 0.01 mins\n",
      "Epoch 38: Train Loss: 0.0047\tVal Loss: 0.0059\tVal MAE: 107757.34\telapsed: 0.02 mins\n",
      "Epoch 39: Train Loss: 0.0043\tVal Loss: 0.0055\tVal MAE: 103072.76\telapsed: 0.02 mins\n",
      "Epoch 40: Train Loss: 0.0039\tVal Loss: 0.0052\tVal MAE: 99376.25\telapsed: 0.02 mins\n",
      "Epoch 41: Train Loss: 0.0035\tVal Loss: 0.0050\tVal MAE: 96252.70\telapsed: 0.02 mins\n",
      "Epoch 42: Train Loss: 0.0033\tVal Loss: 0.0047\tVal MAE: 93638.15\telapsed: 0.02 mins\n",
      "Epoch 43: Train Loss: 0.0031\tVal Loss: 0.0046\tVal MAE: 91550.05\telapsed: 0.02 mins\n",
      "Epoch 44: Train Loss: 0.0029\tVal Loss: 0.0044\tVal MAE: 89836.38\telapsed: 0.02 mins\n",
      "Epoch 45: Train Loss: 0.0027\tVal Loss: 0.0043\tVal MAE: 88590.58\telapsed: 0.02 mins\n",
      "Epoch 46: Train Loss: 0.0026\tVal Loss: 0.0042\tVal MAE: 87739.55\telapsed: 0.02 mins\n",
      "Epoch 47: Train Loss: 0.0025\tVal Loss: 0.0041\tVal MAE: 87105.13\telapsed: 0.02 mins\n",
      "Epoch 48: Train Loss: 0.0024\tVal Loss: 0.0041\tVal MAE: 86351.27\telapsed: 0.02 mins\n",
      "Epoch 49: Train Loss: 0.0023\tVal Loss: 0.0040\tVal MAE: 85515.88\telapsed: 0.02 mins\n",
      "Epoch 50: Train Loss: 0.0023\tVal Loss: 0.0040\tVal MAE: 85012.50\telapsed: 0.02 mins\n",
      "Epoch 51: Train Loss: 0.0022\tVal Loss: 0.0040\tVal MAE: 84690.00\telapsed: 0.02 mins\n",
      "Epoch 52: Train Loss: 0.0022\tVal Loss: 0.0039\tVal MAE: 84462.57\telapsed: 0.02 mins\n",
      "Epoch 53: Train Loss: 0.0021\tVal Loss: 0.0039\tVal MAE: 84334.59\telapsed: 0.02 mins\n",
      "Epoch 54: Train Loss: 0.0021\tVal Loss: 0.0039\tVal MAE: 84245.53\telapsed: 0.02 mins\n",
      "Epoch 55: Train Loss: 0.0021\tVal Loss: 0.0039\tVal MAE: 84105.02\telapsed: 0.02 mins\n",
      "Epoch 56: Train Loss: 0.0021\tVal Loss: 0.0039\tVal MAE: 83823.51\telapsed: 0.02 mins\n",
      "Epoch 57: Train Loss: 0.0021\tVal Loss: 0.0039\tVal MAE: 83548.95\telapsed: 0.02 mins\n",
      "Epoch 58: Train Loss: 0.0021\tVal Loss: 0.0039\tVal MAE: 83508.75\telapsed: 0.02 mins\n",
      "Epoch 59: Train Loss: 0.0021\tVal Loss: 0.0039\tVal MAE: 83293.73\telapsed: 0.02 mins\n",
      "Epoch 60: Train Loss: 0.0020\tVal Loss: 0.0039\tVal MAE: 83245.14\telapsed: 0.02 mins\n",
      "Epoch 61: Train Loss: 0.0020\tVal Loss: 0.0039\tVal MAE: 83187.19\telapsed: 0.02 mins\n",
      "Epoch 62: Train Loss: 0.0020\tVal Loss: 0.0039\tVal MAE: 83269.09\telapsed: 0.02 mins\n",
      "Epoch 63: Train Loss: 0.0020\tVal Loss: 0.0039\tVal MAE: 83260.62\telapsed: 0.03 mins\n",
      "Epoch 64: Train Loss: 0.0020\tVal Loss: 0.0039\tVal MAE: 83219.50\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 61\tVal loss: 0.0039\tVal MAE: 83187.19\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 4 from 1.0/2016.0 to 4.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.1084\tVal Loss: 0.1074\tVal MAE: 1292730.49\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.1013\tVal Loss: 0.1000\tVal MAE: 1209995.85\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0936\tVal Loss: 0.0924\tVal MAE: 1124387.33\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0861\tVal Loss: 0.0849\tVal MAE: 1040412.59\telapsed: 0.00 mins\n",
      "Epoch 5: Train Loss: 0.0787\tVal Loss: 0.0776\tVal MAE: 958872.57\telapsed: 0.00 mins\n",
      "Epoch 6: Train Loss: 0.0716\tVal Loss: 0.0705\tVal MAE: 880016.78\telapsed: 0.00 mins\n",
      "Epoch 7: Train Loss: 0.0647\tVal Loss: 0.0637\tVal MAE: 803661.18\telapsed: 0.00 mins\n",
      "Epoch 8: Train Loss: 0.0581\tVal Loss: 0.0572\tVal MAE: 730012.45\telapsed: 0.00 mins\n",
      "Epoch 9: Train Loss: 0.0518\tVal Loss: 0.0510\tVal MAE: 659968.00\telapsed: 0.00 mins\n",
      "Epoch 10: Train Loss: 0.0458\tVal Loss: 0.0452\tVal MAE: 593878.44\telapsed: 0.01 mins\n",
      "Epoch 11: Train Loss: 0.0402\tVal Loss: 0.0397\tVal MAE: 530936.39\telapsed: 0.01 mins\n",
      "Epoch 12: Train Loss: 0.0350\tVal Loss: 0.0346\tVal MAE: 473451.47\telapsed: 0.01 mins\n",
      "Epoch 13: Train Loss: 0.0303\tVal Loss: 0.0300\tVal MAE: 421377.73\telapsed: 0.01 mins\n",
      "Epoch 14: Train Loss: 0.0260\tVal Loss: 0.0259\tVal MAE: 375413.25\telapsed: 0.01 mins\n",
      "Epoch 15: Train Loss: 0.0221\tVal Loss: 0.0221\tVal MAE: 333175.08\telapsed: 0.01 mins\n",
      "Epoch 16: Train Loss: 0.0187\tVal Loss: 0.0188\tVal MAE: 294873.10\telapsed: 0.01 mins\n",
      "Epoch 17: Train Loss: 0.0157\tVal Loss: 0.0160\tVal MAE: 261554.12\telapsed: 0.01 mins\n",
      "Epoch 18: Train Loss: 0.0132\tVal Loss: 0.0135\tVal MAE: 232478.61\telapsed: 0.01 mins\n",
      "Epoch 19: Train Loss: 0.0110\tVal Loss: 0.0115\tVal MAE: 208407.22\telapsed: 0.01 mins\n",
      "Epoch 20: Train Loss: 0.0093\tVal Loss: 0.0098\tVal MAE: 189146.61\telapsed: 0.01 mins\n",
      "Epoch 21: Train Loss: 0.0079\tVal Loss: 0.0084\tVal MAE: 173087.43\telapsed: 0.01 mins\n",
      "Epoch 22: Train Loss: 0.0067\tVal Loss: 0.0074\tVal MAE: 160631.53\telapsed: 0.01 mins\n",
      "Epoch 23: Train Loss: 0.0058\tVal Loss: 0.0065\tVal MAE: 149807.79\telapsed: 0.01 mins\n",
      "Epoch 24: Train Loss: 0.0051\tVal Loss: 0.0059\tVal MAE: 141512.98\telapsed: 0.01 mins\n",
      "Epoch 25: Train Loss: 0.0046\tVal Loss: 0.0054\tVal MAE: 135125.98\telapsed: 0.01 mins\n",
      "Epoch 26: Train Loss: 0.0042\tVal Loss: 0.0050\tVal MAE: 129868.47\telapsed: 0.01 mins\n",
      "Epoch 27: Train Loss: 0.0038\tVal Loss: 0.0047\tVal MAE: 125692.52\telapsed: 0.01 mins\n",
      "Epoch 28: Train Loss: 0.0036\tVal Loss: 0.0045\tVal MAE: 122667.39\telapsed: 0.01 mins\n",
      "Epoch 29: Train Loss: 0.0034\tVal Loss: 0.0043\tVal MAE: 120543.47\telapsed: 0.02 mins\n",
      "Epoch 30: Train Loss: 0.0033\tVal Loss: 0.0042\tVal MAE: 118973.44\telapsed: 0.02 mins\n",
      "Epoch 31: Train Loss: 0.0032\tVal Loss: 0.0041\tVal MAE: 117641.12\telapsed: 0.02 mins\n",
      "Epoch 32: Train Loss: 0.0032\tVal Loss: 0.0040\tVal MAE: 116530.85\telapsed: 0.02 mins\n",
      "Epoch 33: Train Loss: 0.0031\tVal Loss: 0.0040\tVal MAE: 115907.67\telapsed: 0.02 mins\n",
      "Epoch 34: Train Loss: 0.0031\tVal Loss: 0.0040\tVal MAE: 115381.28\telapsed: 0.02 mins\n",
      "Epoch 35: Train Loss: 0.0031\tVal Loss: 0.0039\tVal MAE: 114918.81\telapsed: 0.02 mins\n",
      "Epoch 36: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 114556.74\telapsed: 0.02 mins\n",
      "Epoch 37: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 114395.61\telapsed: 0.02 mins\n",
      "Epoch 38: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 114163.11\telapsed: 0.02 mins\n",
      "Epoch 39: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 113662.66\telapsed: 0.02 mins\n",
      "Epoch 40: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 113446.97\telapsed: 0.02 mins\n",
      "Epoch 41: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 113391.18\telapsed: 0.02 mins\n",
      "Epoch 42: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 113331.71\telapsed: 0.02 mins\n",
      "Epoch 43: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 113263.07\telapsed: 0.02 mins\n",
      "Epoch 44: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 112913.70\telapsed: 0.02 mins\n",
      "Epoch 45: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 112970.44\telapsed: 0.02 mins\n",
      "Epoch 46: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 112925.36\telapsed: 0.02 mins\n",
      "Epoch 47: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 112699.83\telapsed: 0.02 mins\n",
      "Epoch 48: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 112699.13\telapsed: 0.03 mins\n",
      "Epoch 49: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 112738.34\telapsed: 0.03 mins\n",
      "Epoch 50: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 112727.67\telapsed: 0.03 mins\n",
      "Epoch 51: Train Loss: 0.0030\tVal Loss: 0.0039\tVal MAE: 112834.18\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 48\tVal loss: 0.0039\tVal MAE: 112699.13\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 5 from 1.0/2016.0 to 5.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.1144\tVal Loss: 0.1123\tVal MAE: 1336546.77\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.1029\tVal Loss: 0.1004\tVal MAE: 1204289.08\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0909\tVal Loss: 0.0886\tVal MAE: 1071646.40\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0797\tVal Loss: 0.0776\tVal MAE: 948213.55\telapsed: 0.00 mins\n",
      "Epoch 5: Train Loss: 0.0693\tVal Loss: 0.0674\tVal MAE: 834642.64\telapsed: 0.00 mins\n",
      "Epoch 6: Train Loss: 0.0598\tVal Loss: 0.0582\tVal MAE: 731139.54\telapsed: 0.00 mins\n",
      "Epoch 7: Train Loss: 0.0512\tVal Loss: 0.0497\tVal MAE: 636034.84\telapsed: 0.00 mins\n",
      "Epoch 8: Train Loss: 0.0433\tVal Loss: 0.0421\tVal MAE: 549558.38\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0363\tVal Loss: 0.0353\tVal MAE: 472625.92\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0301\tVal Loss: 0.0293\tVal MAE: 404633.75\telapsed: 0.01 mins\n",
      "Epoch 11: Train Loss: 0.0248\tVal Loss: 0.0242\tVal MAE: 346152.21\telapsed: 0.01 mins\n",
      "Epoch 12: Train Loss: 0.0202\tVal Loss: 0.0198\tVal MAE: 295989.54\telapsed: 0.01 mins\n",
      "Epoch 13: Train Loss: 0.0164\tVal Loss: 0.0162\tVal MAE: 254945.91\telapsed: 0.01 mins\n",
      "Epoch 14: Train Loss: 0.0133\tVal Loss: 0.0132\tVal MAE: 220812.79\telapsed: 0.01 mins\n",
      "Epoch 15: Train Loss: 0.0108\tVal Loss: 0.0109\tVal MAE: 194015.28\telapsed: 0.01 mins\n",
      "Epoch 16: Train Loss: 0.0088\tVal Loss: 0.0091\tVal MAE: 172938.36\telapsed: 0.01 mins\n",
      "Epoch 17: Train Loss: 0.0073\tVal Loss: 0.0077\tVal MAE: 156786.52\telapsed: 0.01 mins\n",
      "Epoch 18: Train Loss: 0.0062\tVal Loss: 0.0066\tVal MAE: 144004.72\telapsed: 0.01 mins\n",
      "Epoch 19: Train Loss: 0.0053\tVal Loss: 0.0059\tVal MAE: 134508.30\telapsed: 0.01 mins\n",
      "Epoch 20: Train Loss: 0.0047\tVal Loss: 0.0053\tVal MAE: 128097.15\telapsed: 0.01 mins\n",
      "Epoch 21: Train Loss: 0.0043\tVal Loss: 0.0049\tVal MAE: 123388.62\telapsed: 0.01 mins\n",
      "Epoch 22: Train Loss: 0.0040\tVal Loss: 0.0046\tVal MAE: 119473.82\telapsed: 0.01 mins\n",
      "Epoch 23: Train Loss: 0.0038\tVal Loss: 0.0044\tVal MAE: 116719.12\telapsed: 0.01 mins\n",
      "Epoch 24: Train Loss: 0.0036\tVal Loss: 0.0043\tVal MAE: 114715.89\telapsed: 0.02 mins\n",
      "Epoch 25: Train Loss: 0.0035\tVal Loss: 0.0042\tVal MAE: 113288.49\telapsed: 0.02 mins\n",
      "Epoch 26: Train Loss: 0.0034\tVal Loss: 0.0041\tVal MAE: 112135.33\telapsed: 0.02 mins\n",
      "Epoch 27: Train Loss: 0.0034\tVal Loss: 0.0041\tVal MAE: 111272.64\telapsed: 0.02 mins\n",
      "Epoch 28: Train Loss: 0.0034\tVal Loss: 0.0041\tVal MAE: 110785.33\telapsed: 0.02 mins\n",
      "Epoch 29: Train Loss: 0.0033\tVal Loss: 0.0040\tVal MAE: 110452.69\telapsed: 0.02 mins\n",
      "Epoch 30: Train Loss: 0.0033\tVal Loss: 0.0040\tVal MAE: 110240.04\telapsed: 0.02 mins\n",
      "Epoch 31: Train Loss: 0.0033\tVal Loss: 0.0040\tVal MAE: 110070.85\telapsed: 0.02 mins\n",
      "Epoch 32: Train Loss: 0.0033\tVal Loss: 0.0040\tVal MAE: 110022.28\telapsed: 0.02 mins\n",
      "Epoch 33: Train Loss: 0.0033\tVal Loss: 0.0040\tVal MAE: 109998.24\telapsed: 0.02 mins\n",
      "Epoch 34: Train Loss: 0.0033\tVal Loss: 0.0040\tVal MAE: 110220.63\telapsed: 0.02 mins\n",
      "Epoch 35: Train Loss: 0.0033\tVal Loss: 0.0040\tVal MAE: 110180.87\telapsed: 0.02 mins\n",
      "Epoch 36: Train Loss: 0.0033\tVal Loss: 0.0040\tVal MAE: 110310.25\telapsed: 0.02 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 33\tVal loss: 0.0040\tVal MAE: 109998.24\tTotal time elapsed: 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 6 from 1.0/2016.0 to 6.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.1094\tVal Loss: 0.1083\tVal MAE: 1318667.50\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0994\tVal Loss: 0.0981\tVal MAE: 1208084.80\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0890\tVal Loss: 0.0878\tVal MAE: 1095452.44\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0789\tVal Loss: 0.0778\tVal MAE: 987201.29\telapsed: 0.00 mins\n",
      "Epoch 5: Train Loss: 0.0693\tVal Loss: 0.0683\tVal MAE: 884029.61\telapsed: 0.00 mins\n",
      "Epoch 6: Train Loss: 0.0601\tVal Loss: 0.0592\tVal MAE: 787211.15\telapsed: 0.00 mins\n",
      "Epoch 7: Train Loss: 0.0515\tVal Loss: 0.0507\tVal MAE: 695727.33\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0435\tVal Loss: 0.0429\tVal MAE: 610950.28\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0362\tVal Loss: 0.0357\tVal MAE: 533662.11\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0298\tVal Loss: 0.0295\tVal MAE: 466568.79\telapsed: 0.01 mins\n",
      "Epoch 11: Train Loss: 0.0242\tVal Loss: 0.0240\tVal MAE: 408916.73\telapsed: 0.01 mins\n",
      "Epoch 12: Train Loss: 0.0194\tVal Loss: 0.0194\tVal MAE: 359135.33\telapsed: 0.01 mins\n",
      "Epoch 13: Train Loss: 0.0156\tVal Loss: 0.0157\tVal MAE: 318625.15\telapsed: 0.01 mins\n",
      "Epoch 14: Train Loss: 0.0124\tVal Loss: 0.0126\tVal MAE: 284349.31\telapsed: 0.01 mins\n",
      "Epoch 15: Train Loss: 0.0099\tVal Loss: 0.0103\tVal MAE: 257566.90\telapsed: 0.01 mins\n",
      "Epoch 16: Train Loss: 0.0080\tVal Loss: 0.0084\tVal MAE: 236849.65\telapsed: 0.01 mins\n",
      "Epoch 17: Train Loss: 0.0066\tVal Loss: 0.0071\tVal MAE: 220954.17\telapsed: 0.01 mins\n",
      "Epoch 18: Train Loss: 0.0056\tVal Loss: 0.0061\tVal MAE: 209664.78\telapsed: 0.01 mins\n",
      "Epoch 19: Train Loss: 0.0048\tVal Loss: 0.0054\tVal MAE: 200839.92\telapsed: 0.01 mins\n",
      "Epoch 20: Train Loss: 0.0043\tVal Loss: 0.0049\tVal MAE: 195008.62\telapsed: 0.02 mins\n",
      "Epoch 21: Train Loss: 0.0040\tVal Loss: 0.0046\tVal MAE: 191063.58\telapsed: 0.02 mins\n",
      "Epoch 22: Train Loss: 0.0038\tVal Loss: 0.0044\tVal MAE: 187705.68\telapsed: 0.02 mins\n",
      "Epoch 23: Train Loss: 0.0036\tVal Loss: 0.0043\tVal MAE: 185929.22\telapsed: 0.02 mins\n",
      "Epoch 24: Train Loss: 0.0036\tVal Loss: 0.0042\tVal MAE: 184385.76\telapsed: 0.02 mins\n",
      "Epoch 25: Train Loss: 0.0035\tVal Loss: 0.0041\tVal MAE: 182779.11\telapsed: 0.02 mins\n",
      "Epoch 26: Train Loss: 0.0035\tVal Loss: 0.0041\tVal MAE: 182138.74\telapsed: 0.02 mins\n",
      "Epoch 27: Train Loss: 0.0034\tVal Loss: 0.0041\tVal MAE: 181644.13\telapsed: 0.02 mins\n",
      "Epoch 28: Train Loss: 0.0034\tVal Loss: 0.0041\tVal MAE: 181130.89\telapsed: 0.02 mins\n",
      "Epoch 29: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 180960.26\telapsed: 0.02 mins\n",
      "Epoch 30: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 180855.39\telapsed: 0.02 mins\n",
      "Epoch 31: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 180274.91\telapsed: 0.02 mins\n",
      "Epoch 32: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179739.09\telapsed: 0.02 mins\n",
      "Epoch 33: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179795.70\telapsed: 0.03 mins\n",
      "Epoch 34: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179655.62\telapsed: 0.03 mins\n",
      "Epoch 35: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179533.13\telapsed: 0.03 mins\n",
      "Epoch 36: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179356.93\telapsed: 0.03 mins\n",
      "Epoch 37: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179238.31\telapsed: 0.03 mins\n",
      "Epoch 38: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179337.91\telapsed: 0.03 mins\n",
      "Epoch 39: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179528.19\telapsed: 0.03 mins\n",
      "Epoch 40: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 179343.68\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 37\tVal loss: 0.0040\tVal MAE: 179238.31\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 7 from 1.0/2016.0 to 7.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.1068\tVal Loss: 0.1048\tVal MAE: 1321408.23\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0897\tVal Loss: 0.0878\tVal MAE: 1139038.78\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0739\tVal Loss: 0.0722\tVal MAE: 968818.13\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0596\tVal Loss: 0.0583\tVal MAE: 817568.21\telapsed: 0.00 mins\n",
      "Epoch 5: Train Loss: 0.0472\tVal Loss: 0.0461\tVal MAE: 685946.92\telapsed: 0.00 mins\n",
      "Epoch 6: Train Loss: 0.0364\tVal Loss: 0.0357\tVal MAE: 572039.85\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0275\tVal Loss: 0.0271\tVal MAE: 476121.06\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0205\tVal Loss: 0.0204\tVal MAE: 399766.11\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0152\tVal Loss: 0.0153\tVal MAE: 341575.71\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0114\tVal Loss: 0.0117\tVal MAE: 299800.65\telapsed: 0.01 mins\n",
      "Epoch 11: Train Loss: 0.0087\tVal Loss: 0.0092\tVal MAE: 269035.17\telapsed: 0.01 mins\n",
      "Epoch 12: Train Loss: 0.0070\tVal Loss: 0.0075\tVal MAE: 249209.67\telapsed: 0.01 mins\n",
      "Epoch 13: Train Loss: 0.0058\tVal Loss: 0.0064\tVal MAE: 236077.62\telapsed: 0.01 mins\n",
      "Epoch 14: Train Loss: 0.0051\tVal Loss: 0.0057\tVal MAE: 228693.53\telapsed: 0.01 mins\n",
      "Epoch 15: Train Loss: 0.0046\tVal Loss: 0.0053\tVal MAE: 223067.52\telapsed: 0.01 mins\n",
      "Epoch 16: Train Loss: 0.0043\tVal Loss: 0.0051\tVal MAE: 219140.89\telapsed: 0.01 mins\n",
      "Epoch 17: Train Loss: 0.0042\tVal Loss: 0.0049\tVal MAE: 216818.47\telapsed: 0.02 mins\n",
      "Epoch 18: Train Loss: 0.0041\tVal Loss: 0.0048\tVal MAE: 215361.91\telapsed: 0.02 mins\n",
      "Epoch 19: Train Loss: 0.0040\tVal Loss: 0.0047\tVal MAE: 214109.16\telapsed: 0.02 mins\n",
      "Epoch 20: Train Loss: 0.0039\tVal Loss: 0.0047\tVal MAE: 213479.56\telapsed: 0.02 mins\n",
      "Epoch 21: Train Loss: 0.0039\tVal Loss: 0.0046\tVal MAE: 212930.53\telapsed: 0.02 mins\n",
      "Epoch 22: Train Loss: 0.0039\tVal Loss: 0.0046\tVal MAE: 212710.56\telapsed: 0.02 mins\n",
      "Epoch 23: Train Loss: 0.0038\tVal Loss: 0.0046\tVal MAE: 212472.20\telapsed: 0.02 mins\n",
      "Epoch 24: Train Loss: 0.0038\tVal Loss: 0.0045\tVal MAE: 211728.02\telapsed: 0.02 mins\n",
      "Epoch 25: Train Loss: 0.0038\tVal Loss: 0.0045\tVal MAE: 211149.10\telapsed: 0.02 mins\n",
      "Epoch 26: Train Loss: 0.0038\tVal Loss: 0.0045\tVal MAE: 211073.26\telapsed: 0.02 mins\n",
      "Epoch 27: Train Loss: 0.0037\tVal Loss: 0.0045\tVal MAE: 210426.41\telapsed: 0.03 mins\n",
      "Epoch 28: Train Loss: 0.0037\tVal Loss: 0.0045\tVal MAE: 210373.35\telapsed: 0.03 mins\n",
      "Epoch 29: Train Loss: 0.0037\tVal Loss: 0.0045\tVal MAE: 210427.07\telapsed: 0.03 mins\n",
      "Epoch 30: Train Loss: 0.0037\tVal Loss: 0.0045\tVal MAE: 210289.84\telapsed: 0.03 mins\n",
      "Epoch 31: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 210105.99\telapsed: 0.03 mins\n",
      "Epoch 32: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209801.14\telapsed: 0.03 mins\n",
      "Epoch 33: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209622.60\telapsed: 0.03 mins\n",
      "Epoch 34: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209739.34\telapsed: 0.03 mins\n",
      "Epoch 35: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209830.19\telapsed: 0.03 mins\n",
      "Epoch 36: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209220.52\telapsed: 0.04 mins\n",
      "Epoch 37: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209629.02\telapsed: 0.04 mins\n",
      "Epoch 38: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209529.93\telapsed: 0.04 mins\n",
      "Epoch 39: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209129.63\telapsed: 0.04 mins\n",
      "Epoch 40: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209403.19\telapsed: 0.04 mins\n",
      "Epoch 41: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209431.32\telapsed: 0.04 mins\n",
      "Epoch 42: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 208911.70\telapsed: 0.04 mins\n",
      "Epoch 43: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209235.68\telapsed: 0.04 mins\n",
      "Epoch 44: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 208882.41\telapsed: 0.04 mins\n",
      "Epoch 45: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209448.06\telapsed: 0.04 mins\n",
      "Epoch 46: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209335.26\telapsed: 0.04 mins\n",
      "Epoch 47: Train Loss: 0.0037\tVal Loss: 0.0044\tVal MAE: 209184.60\telapsed: 0.05 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 44\tVal loss: 0.0044\tVal MAE: 208882.41\tTotal time elapsed: 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 8 from 1.0/2016.0 to 8.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.1048\tVal Loss: 0.1024\tVal MAE: 1207884.34\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0881\tVal Loss: 0.0858\tVal MAE: 1023911.80\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0726\tVal Loss: 0.0706\tVal MAE: 855138.04\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0587\tVal Loss: 0.0569\tVal MAE: 703460.35\telapsed: 0.00 mins\n",
      "Epoch 5: Train Loss: 0.0464\tVal Loss: 0.0449\tVal MAE: 569311.95\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0357\tVal Loss: 0.0344\tVal MAE: 452923.26\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0268\tVal Loss: 0.0257\tVal MAE: 354875.66\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0197\tVal Loss: 0.0189\tVal MAE: 278562.29\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0145\tVal Loss: 0.0139\tVal MAE: 224154.75\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0108\tVal Loss: 0.0104\tVal MAE: 185786.54\telapsed: 0.01 mins\n",
      "Epoch 11: Train Loss: 0.0081\tVal Loss: 0.0080\tVal MAE: 159335.77\telapsed: 0.01 mins\n",
      "Epoch 12: Train Loss: 0.0065\tVal Loss: 0.0065\tVal MAE: 143024.82\telapsed: 0.01 mins\n",
      "Epoch 13: Train Loss: 0.0055\tVal Loss: 0.0056\tVal MAE: 133592.92\telapsed: 0.01 mins\n",
      "Epoch 14: Train Loss: 0.0049\tVal Loss: 0.0051\tVal MAE: 128308.49\telapsed: 0.02 mins\n",
      "Epoch 15: Train Loss: 0.0046\tVal Loss: 0.0048\tVal MAE: 125317.53\telapsed: 0.02 mins\n",
      "Epoch 16: Train Loss: 0.0044\tVal Loss: 0.0047\tVal MAE: 124153.73\telapsed: 0.02 mins\n",
      "Epoch 17: Train Loss: 0.0043\tVal Loss: 0.0046\tVal MAE: 123256.02\telapsed: 0.02 mins\n",
      "Epoch 18: Train Loss: 0.0043\tVal Loss: 0.0046\tVal MAE: 122607.59\telapsed: 0.02 mins\n",
      "Epoch 19: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122165.53\telapsed: 0.02 mins\n",
      "Epoch 20: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122121.26\telapsed: 0.02 mins\n",
      "Epoch 21: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122106.70\telapsed: 0.02 mins\n",
      "Epoch 22: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122082.24\telapsed: 0.02 mins\n",
      "Epoch 23: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122188.37\telapsed: 0.02 mins\n",
      "Epoch 24: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122126.54\telapsed: 0.03 mins\n",
      "Epoch 25: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122053.79\telapsed: 0.03 mins\n",
      "Epoch 26: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122041.87\telapsed: 0.03 mins\n",
      "Epoch 27: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122071.76\telapsed: 0.03 mins\n",
      "Epoch 28: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122027.42\telapsed: 0.03 mins\n",
      "Epoch 29: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122153.98\telapsed: 0.03 mins\n",
      "Epoch 30: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122254.45\telapsed: 0.03 mins\n",
      "Epoch 31: Train Loss: 0.0042\tVal Loss: 0.0045\tVal MAE: 122249.58\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 28\tVal loss: 0.0045\tVal MAE: 122027.42\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 9 from 1.0/2016.0 to 9.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.1047\tVal Loss: 0.1019\tVal MAE: 1205336.74\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0810\tVal Loss: 0.0784\tVal MAE: 948537.27\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0604\tVal Loss: 0.0583\tVal MAE: 727847.91\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0435\tVal Loss: 0.0419\tVal MAE: 550075.91\telapsed: 0.00 mins\n",
      "Epoch 5: Train Loss: 0.0302\tVal Loss: 0.0291\tVal MAE: 411232.42\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0204\tVal Loss: 0.0196\tVal MAE: 308155.59\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0137\tVal Loss: 0.0133\tVal MAE: 242261.70\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0094\tVal Loss: 0.0094\tVal MAE: 200298.55\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0070\tVal Loss: 0.0071\tVal MAE: 175831.69\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0056\tVal Loss: 0.0058\tVal MAE: 161672.93\telapsed: 0.01 mins\n",
      "Epoch 11: Train Loss: 0.0049\tVal Loss: 0.0052\tVal MAE: 154445.81\telapsed: 0.01 mins\n",
      "Epoch 12: Train Loss: 0.0046\tVal Loss: 0.0049\tVal MAE: 151447.60\telapsed: 0.01 mins\n",
      "Epoch 13: Train Loss: 0.0044\tVal Loss: 0.0048\tVal MAE: 150391.09\telapsed: 0.02 mins\n",
      "Epoch 14: Train Loss: 0.0043\tVal Loss: 0.0047\tVal MAE: 149727.82\telapsed: 0.02 mins\n",
      "Epoch 15: Train Loss: 0.0043\tVal Loss: 0.0047\tVal MAE: 149950.28\telapsed: 0.02 mins\n",
      "Epoch 16: Train Loss: 0.0043\tVal Loss: 0.0047\tVal MAE: 149844.23\telapsed: 0.02 mins\n",
      "Epoch 17: Train Loss: 0.0043\tVal Loss: 0.0047\tVal MAE: 149995.43\telapsed: 0.02 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 14\tVal loss: 0.0047\tVal MAE: 149727.82\tTotal time elapsed: 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 10 from 1.0/2016.0 to 10.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0979\tVal Loss: 0.0956\tVal MAE: 1145216.18\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0806\tVal Loss: 0.0783\tVal MAE: 956786.51\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0646\tVal Loss: 0.0625\tVal MAE: 783877.31\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0501\tVal Loss: 0.0481\tVal MAE: 625435.90\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0373\tVal Loss: 0.0356\tVal MAE: 487513.27\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0267\tVal Loss: 0.0253\tVal MAE: 376998.19\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0186\tVal Loss: 0.0174\tVal MAE: 292997.18\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0128\tVal Loss: 0.0119\tVal MAE: 234546.08\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0090\tVal Loss: 0.0083\tVal MAE: 197407.54\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0068\tVal Loss: 0.0063\tVal MAE: 176861.26\telapsed: 0.01 mins\n",
      "Epoch 11: Train Loss: 0.0055\tVal Loss: 0.0051\tVal MAE: 164687.06\telapsed: 0.01 mins\n",
      "Epoch 12: Train Loss: 0.0049\tVal Loss: 0.0045\tVal MAE: 158419.11\telapsed: 0.02 mins\n",
      "Epoch 13: Train Loss: 0.0045\tVal Loss: 0.0042\tVal MAE: 155709.51\telapsed: 0.02 mins\n",
      "Epoch 14: Train Loss: 0.0044\tVal Loss: 0.0041\tVal MAE: 154653.36\telapsed: 0.02 mins\n",
      "Epoch 15: Train Loss: 0.0043\tVal Loss: 0.0041\tVal MAE: 154547.69\telapsed: 0.02 mins\n",
      "Epoch 16: Train Loss: 0.0043\tVal Loss: 0.0040\tVal MAE: 155186.25\telapsed: 0.02 mins\n",
      "Epoch 17: Train Loss: 0.0042\tVal Loss: 0.0040\tVal MAE: 155133.41\telapsed: 0.02 mins\n",
      "Epoch 18: Train Loss: 0.0042\tVal Loss: 0.0040\tVal MAE: 155257.79\telapsed: 0.02 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 15\tVal loss: 0.0041\tVal MAE: 154547.69\tTotal time elapsed: 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 11 from 1.0/2016.0 to 11.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0971\tVal Loss: 0.0953\tVal MAE: 1150442.85\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0737\tVal Loss: 0.0716\tVal MAE: 897138.58\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0535\tVal Loss: 0.0518\tVal MAE: 686116.86\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0370\tVal Loss: 0.0357\tVal MAE: 515007.88\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0245\tVal Loss: 0.0237\tVal MAE: 387579.87\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0158\tVal Loss: 0.0153\tVal MAE: 298625.95\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0102\tVal Loss: 0.0100\tVal MAE: 243939.99\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0070\tVal Loss: 0.0070\tVal MAE: 212418.64\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0053\tVal Loss: 0.0055\tVal MAE: 195608.99\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0044\tVal Loss: 0.0047\tVal MAE: 188650.43\telapsed: 0.01 mins\n",
      "Epoch 11: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 186465.90\telapsed: 0.02 mins\n",
      "Epoch 12: Train Loss: 0.0039\tVal Loss: 0.0043\tVal MAE: 185604.45\telapsed: 0.02 mins\n",
      "Epoch 13: Train Loss: 0.0039\tVal Loss: 0.0043\tVal MAE: 185934.84\telapsed: 0.02 mins\n",
      "Epoch 14: Train Loss: 0.0038\tVal Loss: 0.0043\tVal MAE: 185971.55\telapsed: 0.02 mins\n",
      "Epoch 15: Train Loss: 0.0039\tVal Loss: 0.0043\tVal MAE: 186305.22\telapsed: 0.02 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 12\tVal loss: 0.0043\tVal MAE: 185604.45\tTotal time elapsed: 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 12 from 1.0/2016.0 to 12.0/2016.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0890\tVal Loss: 0.0872\tVal MAE: 1092336.21\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0678\tVal Loss: 0.0663\tVal MAE: 870475.34\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0496\tVal Loss: 0.0485\tVal MAE: 676560.50\telapsed: 0.00 mins\n",
      "Epoch 4: Train Loss: 0.0343\tVal Loss: 0.0334\tVal MAE: 514323.54\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0224\tVal Loss: 0.0219\tVal MAE: 387956.94\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0141\tVal Loss: 0.0140\tVal MAE: 303908.01\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0090\tVal Loss: 0.0092\tVal MAE: 255041.41\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0063\tVal Loss: 0.0066\tVal MAE: 227690.37\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 214201.59\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0043\tVal Loss: 0.0049\tVal MAE: 207232.01\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0041\tVal Loss: 0.0047\tVal MAE: 204223.06\telapsed: 0.02 mins\n",
      "Epoch 12: Train Loss: 0.0040\tVal Loss: 0.0047\tVal MAE: 203558.24\telapsed: 0.02 mins\n",
      "Epoch 13: Train Loss: 0.0040\tVal Loss: 0.0046\tVal MAE: 203021.49\telapsed: 0.02 mins\n",
      "Epoch 14: Train Loss: 0.0039\tVal Loss: 0.0046\tVal MAE: 202365.20\telapsed: 0.02 mins\n",
      "Epoch 15: Train Loss: 0.0039\tVal Loss: 0.0046\tVal MAE: 202378.99\telapsed: 0.02 mins\n",
      "Epoch 16: Train Loss: 0.0039\tVal Loss: 0.0046\tVal MAE: 202514.31\telapsed: 0.02 mins\n",
      "Epoch 17: Train Loss: 0.0040\tVal Loss: 0.0046\tVal MAE: 202664.31\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 14\tVal loss: 0.0046\tVal MAE: 202365.20\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 13 from 1.0/2016.0 to 1.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0862\tVal Loss: 0.0842\tVal MAE: 997954.75\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0615\tVal Loss: 0.0598\tVal MAE: 726791.33\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0412\tVal Loss: 0.0396\tVal MAE: 501582.15\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0255\tVal Loss: 0.0243\tVal MAE: 329519.86\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0149\tVal Loss: 0.0140\tVal MAE: 217341.72\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0090\tVal Loss: 0.0082\tVal MAE: 154407.62\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0063\tVal Loss: 0.0055\tVal MAE: 123935.60\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0052\tVal Loss: 0.0043\tVal MAE: 111489.82\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0049\tVal Loss: 0.0039\tVal MAE: 106652.01\telapsed: 0.01 mins\n",
      "Epoch 10: Train Loss: 0.0048\tVal Loss: 0.0037\tVal MAE: 103628.86\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0048\tVal Loss: 0.0037\tVal MAE: 102286.62\telapsed: 0.02 mins\n",
      "Epoch 12: Train Loss: 0.0047\tVal Loss: 0.0036\tVal MAE: 101161.68\telapsed: 0.02 mins\n",
      "Epoch 13: Train Loss: 0.0047\tVal Loss: 0.0036\tVal MAE: 100723.55\telapsed: 0.02 mins\n",
      "Epoch 14: Train Loss: 0.0047\tVal Loss: 0.0036\tVal MAE: 100215.26\telapsed: 0.02 mins\n",
      "Epoch 15: Train Loss: 0.0047\tVal Loss: 0.0036\tVal MAE: 100248.05\telapsed: 0.02 mins\n",
      "Epoch 16: Train Loss: 0.0047\tVal Loss: 0.0036\tVal MAE: 99864.80\telapsed: 0.03 mins\n",
      "Epoch 17: Train Loss: 0.0047\tVal Loss: 0.0036\tVal MAE: 99980.37\telapsed: 0.03 mins\n",
      "Epoch 18: Train Loss: 0.0047\tVal Loss: 0.0036\tVal MAE: 99897.78\telapsed: 0.03 mins\n",
      "Epoch 19: Train Loss: 0.0047\tVal Loss: 0.0036\tVal MAE: 100003.87\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 16\tVal loss: 0.0036\tVal MAE: 99864.80\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 14 from 1.0/2016.0 to 2.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0850\tVal Loss: 0.0828\tVal MAE: 1007642.63\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0585\tVal Loss: 0.0567\tVal MAE: 726936.19\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0371\tVal Loss: 0.0357\tVal MAE: 496368.37\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0214\tVal Loss: 0.0206\tVal MAE: 329599.13\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0116\tVal Loss: 0.0113\tVal MAE: 230382.26\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0067\tVal Loss: 0.0068\tVal MAE: 181955.29\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0046\tVal Loss: 0.0049\tVal MAE: 161642.70\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0039\tVal Loss: 0.0043\tVal MAE: 153288.12\telapsed: 0.01 mins\n",
      "Epoch 9: Train Loss: 0.0036\tVal Loss: 0.0041\tVal MAE: 150197.41\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0036\tVal Loss: 0.0041\tVal MAE: 149162.68\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 148825.94\telapsed: 0.02 mins\n",
      "Epoch 12: Train Loss: 0.0035\tVal Loss: 0.0041\tVal MAE: 148728.89\telapsed: 0.02 mins\n",
      "Epoch 13: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 148625.80\telapsed: 0.02 mins\n",
      "Epoch 14: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 148085.20\telapsed: 0.02 mins\n",
      "Epoch 15: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 148191.09\telapsed: 0.03 mins\n",
      "Epoch 16: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 148221.84\telapsed: 0.03 mins\n",
      "Epoch 17: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 147762.68\telapsed: 0.03 mins\n",
      "Epoch 18: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 148226.48\telapsed: 0.03 mins\n",
      "Epoch 19: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 147915.36\telapsed: 0.03 mins\n",
      "Epoch 20: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 147640.14\telapsed: 0.04 mins\n",
      "Epoch 21: Train Loss: 0.0035\tVal Loss: 0.0040\tVal MAE: 147717.59\telapsed: 0.04 mins\n",
      "Epoch 22: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147489.95\telapsed: 0.04 mins\n",
      "Epoch 23: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147497.32\telapsed: 0.04 mins\n",
      "Epoch 24: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147517.25\telapsed: 0.04 mins\n",
      "Epoch 25: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147218.38\telapsed: 0.04 mins\n",
      "Epoch 26: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147750.29\telapsed: 0.05 mins\n",
      "Epoch 27: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147084.90\telapsed: 0.05 mins\n",
      "Epoch 28: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147228.89\telapsed: 0.05 mins\n",
      "Epoch 29: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147419.74\telapsed: 0.05 mins\n",
      "Epoch 30: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147078.76\telapsed: 0.05 mins\n",
      "Epoch 31: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147370.59\telapsed: 0.06 mins\n",
      "Epoch 32: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147180.26\telapsed: 0.06 mins\n",
      "Epoch 33: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147043.89\telapsed: 0.06 mins\n",
      "Epoch 34: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147340.50\telapsed: 0.06 mins\n",
      "Epoch 35: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147105.80\telapsed: 0.06 mins\n",
      "Epoch 36: Train Loss: 0.0034\tVal Loss: 0.0040\tVal MAE: 147164.82\telapsed: 0.06 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 33\tVal loss: 0.0040\tVal MAE: 147043.89\tTotal time elapsed: 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 15 from 1.0/2016.0 to 3.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0881\tVal Loss: 0.0858\tVal MAE: 1031315.82\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0594\tVal Loss: 0.0575\tVal MAE: 726993.34\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0364\tVal Loss: 0.0351\tVal MAE: 488734.55\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0205\tVal Loss: 0.0197\tVal MAE: 325465.19\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0111\tVal Loss: 0.0107\tVal MAE: 231831.49\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0065\tVal Loss: 0.0065\tVal MAE: 187958.37\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0047\tVal Loss: 0.0049\tVal MAE: 171073.78\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0042\tVal Loss: 0.0044\tVal MAE: 166783.34\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 165670.57\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 165432.53\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 165834.68\telapsed: 0.02 mins\n",
      "Epoch 12: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 165453.63\telapsed: 0.02 mins\n",
      "Epoch 13: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 165329.46\telapsed: 0.02 mins\n",
      "Epoch 14: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 165654.00\telapsed: 0.03 mins\n",
      "Epoch 15: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 165228.50\telapsed: 0.03 mins\n",
      "Epoch 16: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 164801.69\telapsed: 0.03 mins\n",
      "Epoch 17: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 165416.78\telapsed: 0.03 mins\n",
      "Epoch 18: Train Loss: 0.0040\tVal Loss: 0.0044\tVal MAE: 165460.42\telapsed: 0.03 mins\n",
      "Epoch 19: Train Loss: 0.0040\tVal Loss: 0.0044\tVal MAE: 165236.12\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 16\tVal loss: 0.0044\tVal MAE: 164801.69\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 16 from 1.0/2016.0 to 4.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0852\tVal Loss: 0.0835\tVal MAE: 1018169.04\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0540\tVal Loss: 0.0529\tVal MAE: 703495.42\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0304\tVal Loss: 0.0298\tVal MAE: 465456.49\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0155\tVal Loss: 0.0154\tVal MAE: 322348.56\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0082\tVal Loss: 0.0085\tVal MAE: 254113.57\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0054\tVal Loss: 0.0059\tVal MAE: 228348.59\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0046\tVal Loss: 0.0052\tVal MAE: 220421.99\telapsed: 0.01 mins\n",
      "Epoch 8: Train Loss: 0.0045\tVal Loss: 0.0050\tVal MAE: 217521.35\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0045\tVal Loss: 0.0051\tVal MAE: 216139.03\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0045\tVal Loss: 0.0051\tVal MAE: 215258.68\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0045\tVal Loss: 0.0051\tVal MAE: 215415.91\telapsed: 0.02 mins\n",
      "Epoch 12: Train Loss: 0.0045\tVal Loss: 0.0051\tVal MAE: 215557.11\telapsed: 0.02 mins\n",
      "Epoch 13: Train Loss: 0.0045\tVal Loss: 0.0051\tVal MAE: 215585.51\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 10\tVal loss: 0.0051\tVal MAE: 215258.68\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 17 from 1.0/2016.0 to 5.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0748\tVal Loss: 0.0726\tVal MAE: 901799.03\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0414\tVal Loss: 0.0400\tVal MAE: 554670.54\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0205\tVal Loss: 0.0198\tVal MAE: 339945.91\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0100\tVal Loss: 0.0097\tVal MAE: 236513.17\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0062\tVal Loss: 0.0060\tVal MAE: 199673.41\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0052\tVal Loss: 0.0050\tVal MAE: 188528.10\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0050\tVal Loss: 0.0047\tVal MAE: 185023.04\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0051\tVal Loss: 0.0047\tVal MAE: 184993.62\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0051\tVal Loss: 0.0047\tVal MAE: 185635.14\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0051\tVal Loss: 0.0047\tVal MAE: 185487.89\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0052\tVal Loss: 0.0047\tVal MAE: 185665.04\telapsed: 0.02 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 8\tVal loss: 0.0047\tVal MAE: 184993.62\tTotal time elapsed: 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 18 from 1.0/2016.0 to 6.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0899\tVal Loss: 0.0889\tVal MAE: 1128098.12\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0633\tVal Loss: 0.0624\tVal MAE: 850073.16\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0401\tVal Loss: 0.0396\tVal MAE: 607564.93\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0227\tVal Loss: 0.0226\tVal MAE: 428514.88\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0121\tVal Loss: 0.0124\tVal MAE: 322898.55\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0069\tVal Loss: 0.0075\tVal MAE: 271567.82\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0050\tVal Loss: 0.0057\tVal MAE: 252696.82\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0045\tVal Loss: 0.0052\tVal MAE: 245501.46\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0044\tVal Loss: 0.0052\tVal MAE: 244440.29\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0044\tVal Loss: 0.0052\tVal MAE: 244141.67\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0044\tVal Loss: 0.0052\tVal MAE: 243727.76\telapsed: 0.03 mins\n",
      "Epoch 12: Train Loss: 0.0044\tVal Loss: 0.0052\tVal MAE: 243246.30\telapsed: 0.03 mins\n",
      "Epoch 13: Train Loss: 0.0044\tVal Loss: 0.0052\tVal MAE: 243614.58\telapsed: 0.03 mins\n",
      "Epoch 14: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 242915.31\telapsed: 0.03 mins\n",
      "Epoch 15: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 243113.05\telapsed: 0.03 mins\n",
      "Epoch 16: Train Loss: 0.0044\tVal Loss: 0.0052\tVal MAE: 243235.87\telapsed: 0.04 mins\n",
      "Epoch 17: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 242628.43\telapsed: 0.04 mins\n",
      "Epoch 18: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 242853.55\telapsed: 0.04 mins\n",
      "Epoch 19: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 242879.46\telapsed: 0.04 mins\n",
      "Epoch 20: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 242358.26\telapsed: 0.05 mins\n",
      "Epoch 21: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 242561.09\telapsed: 0.05 mins\n",
      "Epoch 22: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 242609.96\telapsed: 0.05 mins\n",
      "Epoch 23: Train Loss: 0.0043\tVal Loss: 0.0052\tVal MAE: 242703.89\telapsed: 0.05 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 20\tVal loss: 0.0052\tVal MAE: 242358.26\tTotal time elapsed: 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 19 from 1.0/2016.0 to 7.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0732\tVal Loss: 0.0713\tVal MAE: 915595.03\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0392\tVal Loss: 0.0381\tVal MAE: 558648.96\telapsed: 0.00 mins\n",
      "Epoch 3: Train Loss: 0.0183\tVal Loss: 0.0180\tVal MAE: 343741.80\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0089\tVal Loss: 0.0090\tVal MAE: 249470.32\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0058\tVal Loss: 0.0063\tVal MAE: 218748.20\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0051\tVal Loss: 0.0057\tVal MAE: 210410.39\telapsed: 0.01 mins\n",
      "Epoch 7: Train Loss: 0.0049\tVal Loss: 0.0055\tVal MAE: 207273.70\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0049\tVal Loss: 0.0055\tVal MAE: 206275.61\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0049\tVal Loss: 0.0055\tVal MAE: 205566.93\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 204436.52\telapsed: 0.02 mins\n",
      "Epoch 11: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 204541.97\telapsed: 0.03 mins\n",
      "Epoch 12: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 204261.31\telapsed: 0.03 mins\n",
      "Epoch 13: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 203850.54\telapsed: 0.03 mins\n",
      "Epoch 14: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 203613.61\telapsed: 0.03 mins\n",
      "Epoch 15: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 204033.88\telapsed: 0.04 mins\n",
      "Epoch 16: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 203998.88\telapsed: 0.04 mins\n",
      "Epoch 17: Train Loss: 0.0049\tVal Loss: 0.0054\tVal MAE: 203791.66\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 14\tVal loss: 0.0054\tVal MAE: 203613.61\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 20 from 1.0/2016.0 to 8.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0719\tVal Loss: 0.0713\tVal MAE: 970746.19\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0380\tVal Loss: 0.0402\tVal MAE: 640532.53\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0174\tVal Loss: 0.0225\tVal MAE: 446135.56\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0086\tVal Loss: 0.0159\tVal MAE: 368781.43\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0061\tVal Loss: 0.0143\tVal MAE: 348776.05\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0056\tVal Loss: 0.0139\tVal MAE: 343690.67\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0055\tVal Loss: 0.0139\tVal MAE: 341181.24\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0055\tVal Loss: 0.0139\tVal MAE: 341087.25\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0055\tVal Loss: 0.0139\tVal MAE: 340748.79\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0055\tVal Loss: 0.0139\tVal MAE: 340893.13\telapsed: 0.03 mins\n",
      "Epoch 11: Train Loss: 0.0055\tVal Loss: 0.0139\tVal MAE: 340981.99\telapsed: 0.03 mins\n",
      "Epoch 12: Train Loss: 0.0055\tVal Loss: 0.0139\tVal MAE: 341108.91\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 9\tVal loss: 0.0139\tVal MAE: 340748.79\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 21 from 1.0/2016.0 to 9.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0773\tVal Loss: 0.0741\tVal MAE: 968943.57\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0475\tVal Loss: 0.0429\tVal MAE: 639813.60\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0270\tVal Loss: 0.0204\tVal MAE: 411995.98\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0174\tVal Loss: 0.0095\tVal MAE: 303838.24\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0146\tVal Loss: 0.0060\tVal MAE: 269112.91\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0141\tVal Loss: 0.0052\tVal MAE: 259751.39\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0139\tVal Loss: 0.0051\tVal MAE: 257978.60\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0139\tVal Loss: 0.0051\tVal MAE: 257951.38\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0140\tVal Loss: 0.0051\tVal MAE: 258633.64\telapsed: 0.02 mins\n",
      "Epoch 10: Train Loss: 0.0140\tVal Loss: 0.0051\tVal MAE: 258156.49\telapsed: 0.03 mins\n",
      "Epoch 11: Train Loss: 0.0140\tVal Loss: 0.0052\tVal MAE: 258980.12\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 8\tVal loss: 0.0051\tVal MAE: 257951.38\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 22 from 1.0/2016.0 to 10.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0771\tVal Loss: 0.0748\tVal MAE: 924352.39\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0426\tVal Loss: 0.0408\tVal MAE: 557776.37\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0198\tVal Loss: 0.0186\tVal MAE: 318890.85\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0092\tVal Loss: 0.0086\tVal MAE: 207973.10\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0058\tVal Loss: 0.0058\tVal MAE: 176664.50\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0051\tVal Loss: 0.0054\tVal MAE: 170115.00\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0050\tVal Loss: 0.0054\tVal MAE: 171045.39\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0050\tVal Loss: 0.0054\tVal MAE: 171931.35\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0050\tVal Loss: 0.0054\tVal MAE: 173022.39\telapsed: 0.02 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 6\tVal loss: 0.0054\tVal MAE: 170115.00\tTotal time elapsed: 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 23 from 1.0/2016.0 to 11.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0664\tVal Loss: 0.0643\tVal MAE: 826559.74\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0318\tVal Loss: 0.0302\tVal MAE: 475045.53\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0129\tVal Loss: 0.0119\tVal MAE: 290410.69\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0065\tVal Loss: 0.0057\tVal MAE: 231525.58\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0053\tVal Loss: 0.0045\tVal MAE: 223313.43\telapsed: 0.01 mins\n",
      "Epoch 6: Train Loss: 0.0051\tVal Loss: 0.0043\tVal MAE: 224811.27\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0051\tVal Loss: 0.0043\tVal MAE: 225762.85\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0051\tVal Loss: 0.0043\tVal MAE: 226500.61\telapsed: 0.02 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 5\tVal loss: 0.0045\tVal MAE: 223313.43\tTotal time elapsed: 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 24 from 1.0/2016.0 to 12.0/2017.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0723\tVal Loss: 0.0706\tVal MAE: 881391.89\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0373\tVal Loss: 0.0361\tVal MAE: 514345.45\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0162\tVal Loss: 0.0157\tVal MAE: 298463.22\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0071\tVal Loss: 0.0072\tVal MAE: 211472.15\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0046\tVal Loss: 0.0049\tVal MAE: 186511.47\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 183502.29\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0040\tVal Loss: 0.0044\tVal MAE: 185505.91\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 186730.83\telapsed: 0.02 mins\n",
      "Epoch 9: Train Loss: 0.0041\tVal Loss: 0.0044\tVal MAE: 188430.85\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 6\tVal loss: 0.0044\tVal MAE: 183502.29\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 25 from 1.0/2016.0 to 1.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0670\tVal Loss: 0.0650\tVal MAE: 817311.67\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0293\tVal Loss: 0.0279\tVal MAE: 426299.59\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0110\tVal Loss: 0.0102\tVal MAE: 247502.32\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0053\tVal Loss: 0.0047\tVal MAE: 194251.11\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0043\tVal Loss: 0.0037\tVal MAE: 189726.59\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0042\tVal Loss: 0.0035\tVal MAE: 189072.17\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0042\tVal Loss: 0.0036\tVal MAE: 190549.31\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0042\tVal Loss: 0.0036\tVal MAE: 190464.50\telapsed: 0.03 mins\n",
      "Epoch 9: Train Loss: 0.0042\tVal Loss: 0.0035\tVal MAE: 191516.16\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 6\tVal loss: 0.0035\tVal MAE: 189072.17\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 26 from 1.0/2016.0 to 2.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0559\tVal Loss: 0.0540\tVal MAE: 684413.46\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0195\tVal Loss: 0.0187\tVal MAE: 313524.63\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0064\tVal Loss: 0.0064\tVal MAE: 192028.34\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0039\tVal Loss: 0.0040\tVal MAE: 174293.36\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0035\tVal Loss: 0.0037\tVal MAE: 172582.49\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0035\tVal Loss: 0.0037\tVal MAE: 174610.93\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0035\tVal Loss: 0.0037\tVal MAE: 174771.59\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0035\tVal Loss: 0.0037\tVal MAE: 174926.86\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 5\tVal loss: 0.0037\tVal MAE: 172582.49\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 27 from 1.0/2016.0 to 3.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0701\tVal Loss: 0.0683\tVal MAE: 837381.28\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0312\tVal Loss: 0.0299\tVal MAE: 439119.22\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0104\tVal Loss: 0.0097\tVal MAE: 229289.04\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0046\tVal Loss: 0.0043\tVal MAE: 175015.39\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0036\tVal Loss: 0.0034\tVal MAE: 167389.81\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0035\tVal Loss: 0.0033\tVal MAE: 168646.88\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0035\tVal Loss: 0.0034\tVal MAE: 171043.56\telapsed: 0.02 mins\n",
      "Epoch 8: Train Loss: 0.0035\tVal Loss: 0.0033\tVal MAE: 170032.67\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 5\tVal loss: 0.0034\tVal MAE: 167389.81\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 28 from 1.0/2016.0 to 4.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0634\tVal Loss: 0.0619\tVal MAE: 773719.25\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0240\tVal Loss: 0.0232\tVal MAE: 363850.16\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0074\tVal Loss: 0.0072\tVal MAE: 203265.03\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0038\tVal Loss: 0.0039\tVal MAE: 173845.95\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0034\tVal Loss: 0.0035\tVal MAE: 171329.96\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0034\tVal Loss: 0.0035\tVal MAE: 171144.12\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 171206.21\telapsed: 0.03 mins\n",
      "Epoch 8: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 171672.22\telapsed: 0.03 mins\n",
      "Epoch 9: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 171234.37\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 6\tVal loss: 0.0035\tVal MAE: 171144.12\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 29 from 1.0/2016.0 to 5.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0621\tVal Loss: 0.0603\tVal MAE: 758787.93\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0239\tVal Loss: 0.0233\tVal MAE: 359154.73\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0073\tVal Loss: 0.0074\tVal MAE: 199746.74\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0038\tVal Loss: 0.0042\tVal MAE: 169927.05\telapsed: 0.01 mins\n",
      "Epoch 5: Train Loss: 0.0034\tVal Loss: 0.0038\tVal MAE: 167945.98\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0034\tVal Loss: 0.0038\tVal MAE: 168107.28\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0034\tVal Loss: 0.0038\tVal MAE: 168674.16\telapsed: 0.03 mins\n",
      "Epoch 8: Train Loss: 0.0034\tVal Loss: 0.0038\tVal MAE: 168886.75\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 5\tVal loss: 0.0038\tVal MAE: 167945.98\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 30 from 1.0/2016.0 to 6.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0577\tVal Loss: 0.0562\tVal MAE: 740748.83\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0187\tVal Loss: 0.0180\tVal MAE: 336703.06\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0059\tVal Loss: 0.0059\tVal MAE: 213340.97\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0040\tVal Loss: 0.0041\tVal MAE: 195215.73\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0038\tVal Loss: 0.0040\tVal MAE: 195245.80\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0038\tVal Loss: 0.0040\tVal MAE: 193854.30\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0038\tVal Loss: 0.0040\tVal MAE: 195161.45\telapsed: 0.03 mins\n",
      "Epoch 8: Train Loss: 0.0038\tVal Loss: 0.0040\tVal MAE: 194453.31\telapsed: 0.03 mins\n",
      "Epoch 9: Train Loss: 0.0038\tVal Loss: 0.0040\tVal MAE: 194885.41\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 6\tVal loss: 0.0040\tVal MAE: 193854.30\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 31 from 1.0/2016.0 to 7.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0636\tVal Loss: 0.0623\tVal MAE: 844644.29\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0238\tVal Loss: 0.0231\tVal MAE: 424833.61\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0074\tVal Loss: 0.0073\tVal MAE: 257333.61\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0042\tVal Loss: 0.0043\tVal MAE: 222282.59\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0039\tVal Loss: 0.0040\tVal MAE: 215988.98\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0039\tVal Loss: 0.0040\tVal MAE: 216246.54\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0039\tVal Loss: 0.0040\tVal MAE: 215084.99\telapsed: 0.03 mins\n",
      "Epoch 8: Train Loss: 0.0039\tVal Loss: 0.0040\tVal MAE: 215697.51\telapsed: 0.03 mins\n",
      "Epoch 9: Train Loss: 0.0039\tVal Loss: 0.0040\tVal MAE: 215113.93\telapsed: 0.04 mins\n",
      "Epoch 10: Train Loss: 0.0039\tVal Loss: 0.0040\tVal MAE: 215844.69\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 7\tVal loss: 0.0040\tVal MAE: 215084.99\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 32 from 1.0/2016.0 to 8.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0547\tVal Loss: 0.0530\tVal MAE: 710574.31\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0158\tVal Loss: 0.0152\tVal MAE: 317617.56\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0052\tVal Loss: 0.0052\tVal MAE: 220022.63\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0041\tVal Loss: 0.0042\tVal MAE: 211545.65\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0040\tVal Loss: 0.0041\tVal MAE: 210663.08\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0040\tVal Loss: 0.0041\tVal MAE: 211213.65\telapsed: 0.02 mins\n",
      "Epoch 7: Train Loss: 0.0040\tVal Loss: 0.0041\tVal MAE: 211776.50\telapsed: 0.03 mins\n",
      "Epoch 8: Train Loss: 0.0040\tVal Loss: 0.0041\tVal MAE: 211547.66\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 5\tVal loss: 0.0041\tVal MAE: 210663.08\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 33 from 1.0/2016.0 to 9.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0563\tVal Loss: 0.0547\tVal MAE: 749161.52\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0181\tVal Loss: 0.0174\tVal MAE: 359064.71\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0057\tVal Loss: 0.0061\tVal MAE: 244664.83\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0042\tVal Loss: 0.0049\tVal MAE: 233392.08\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0041\tVal Loss: 0.0048\tVal MAE: 233420.08\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0041\tVal Loss: 0.0048\tVal MAE: 234340.60\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0041\tVal Loss: 0.0048\tVal MAE: 234237.68\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0049\tVal MAE: 233392.08\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 34 from 1.0/2016.0 to 10.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0523\tVal Loss: 0.0504\tVal MAE: 660738.69\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0151\tVal Loss: 0.0140\tVal MAE: 279114.63\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0058\tVal Loss: 0.0051\tVal MAE: 187716.69\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0049\tVal Loss: 0.0042\tVal MAE: 179302.05\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0048\tVal Loss: 0.0042\tVal MAE: 180156.34\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0049\tVal Loss: 0.0042\tVal MAE: 180400.90\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0049\tVal Loss: 0.0042\tVal MAE: 179425.30\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0042\tVal MAE: 179302.05\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 35 from 1.0/2016.0 to 11.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0535\tVal Loss: 0.0516\tVal MAE: 662367.79\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0153\tVal Loss: 0.0145\tVal MAE: 272361.20\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0051\tVal Loss: 0.0049\tVal MAE: 177255.95\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0041\tVal Loss: 0.0040\tVal MAE: 172053.80\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0041\tVal Loss: 0.0040\tVal MAE: 173108.73\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0041\tVal Loss: 0.0040\tVal MAE: 174536.13\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0041\tVal Loss: 0.0040\tVal MAE: 174418.51\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0040\tVal MAE: 172053.80\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 36 from 1.0/2016.0 to 12.0/2018.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0497\tVal Loss: 0.0482\tVal MAE: 625318.51\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0129\tVal Loss: 0.0123\tVal MAE: 256115.39\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0045\tVal Loss: 0.0043\tVal MAE: 182700.06\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0039\tVal Loss: 0.0038\tVal MAE: 181394.28\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0039\tVal Loss: 0.0038\tVal MAE: 182838.87\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0039\tVal Loss: 0.0038\tVal MAE: 183252.82\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0039\tVal Loss: 0.0038\tVal MAE: 183630.69\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0038\tVal MAE: 181394.28\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 37 from 1.0/2016.0 to 1.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0422\tVal Loss: 0.0407\tVal MAE: 563176.35\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0091\tVal Loss: 0.0089\tVal MAE: 229335.29\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0040\tVal Loss: 0.0042\tVal MAE: 186366.76\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0038\tVal Loss: 0.0041\tVal MAE: 187013.47\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0038\tVal Loss: 0.0041\tVal MAE: 188560.49\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0038\tVal Loss: 0.0041\tVal MAE: 188515.35\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0042\tVal MAE: 186366.76\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 38 from 1.0/2016.0 to 2.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0488\tVal Loss: 0.0472\tVal MAE: 584301.40\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0118\tVal Loss: 0.0110\tVal MAE: 206587.10\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0045\tVal Loss: 0.0039\tVal MAE: 144263.49\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0041\tVal Loss: 0.0034\tVal MAE: 142613.24\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0041\tVal Loss: 0.0034\tVal MAE: 143824.17\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0042\tVal Loss: 0.0034\tVal MAE: 143721.90\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0042\tVal Loss: 0.0034\tVal MAE: 144317.04\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0034\tVal MAE: 142613.24\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 39 from 1.0/2016.0 to 3.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0500\tVal Loss: 0.0486\tVal MAE: 622486.10\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0132\tVal Loss: 0.0127\tVal MAE: 251879.60\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0041\tVal Loss: 0.0039\tVal MAE: 165657.47\telapsed: 0.01 mins\n",
      "Epoch 4: Train Loss: 0.0033\tVal Loss: 0.0032\tVal MAE: 160542.00\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0033\tVal Loss: 0.0032\tVal MAE: 163593.44\telapsed: 0.02 mins\n",
      "Epoch 6: Train Loss: 0.0033\tVal Loss: 0.0032\tVal MAE: 165017.65\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0033\tVal Loss: 0.0032\tVal MAE: 164912.64\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0032\tVal MAE: 160542.00\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 40 from 1.0/2016.0 to 4.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0496\tVal Loss: 0.0481\tVal MAE: 622660.77\telapsed: 0.00 mins\n",
      "Epoch 2: Train Loss: 0.0114\tVal Loss: 0.0110\tVal MAE: 233577.41\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0037\tVal Loss: 0.0037\tVal MAE: 153170.46\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0032\tVal Loss: 0.0033\tVal MAE: 149834.47\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0032\tVal Loss: 0.0033\tVal MAE: 151573.81\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0032\tVal Loss: 0.0033\tVal MAE: 151678.15\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0032\tVal Loss: 0.0033\tVal MAE: 152304.61\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0033\tVal MAE: 149834.47\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 41 from 1.0/2016.0 to 5.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0404\tVal Loss: 0.0392\tVal MAE: 530799.08\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0082\tVal Loss: 0.0080\tVal MAE: 201256.52\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0035\tVal Loss: 0.0036\tVal MAE: 158087.43\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0032\tVal Loss: 0.0034\tVal MAE: 156349.14\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0033\tVal Loss: 0.0034\tVal MAE: 157322.05\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0033\tVal Loss: 0.0034\tVal MAE: 157713.85\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0033\tVal Loss: 0.0034\tVal MAE: 158005.46\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0034\tVal MAE: 156349.14\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 42 from 1.0/2016.0 to 6.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0387\tVal Loss: 0.0374\tVal MAE: 519285.36\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0069\tVal Loss: 0.0067\tVal MAE: 200736.25\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0034\tVal Loss: 0.0034\tVal MAE: 168379.48\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 167144.66\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 167419.33\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 167692.62\telapsed: 0.03 mins\n",
      "Epoch 7: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 167631.05\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0033\tVal MAE: 167144.66\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 43 from 1.0/2016.0 to 7.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0324\tVal Loss: 0.0312\tVal MAE: 460936.88\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0054\tVal Loss: 0.0054\tVal MAE: 186112.20\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0034\tVal Loss: 0.0034\tVal MAE: 166928.41\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0033\tVal Loss: 0.0034\tVal MAE: 165154.32\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 164909.52\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 164560.50\telapsed: 0.04 mins\n",
      "Epoch 7: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 164568.77\telapsed: 0.04 mins\n",
      "Epoch 8: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 164740.50\telapsed: 0.05 mins\n",
      "Epoch 9: Train Loss: 0.0033\tVal Loss: 0.0033\tVal MAE: 164850.80\telapsed: 0.05 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 6\tVal loss: 0.0033\tVal MAE: 164560.50\tTotal time elapsed: 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 44 from 1.0/2016.0 to 8.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0366\tVal Loss: 0.0351\tVal MAE: 480900.11\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0060\tVal Loss: 0.0059\tVal MAE: 172835.03\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0034\tVal Loss: 0.0036\tVal MAE: 151664.77\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 150692.06\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 150373.25\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 150390.76\telapsed: 0.04 mins\n",
      "Epoch 7: Train Loss: 0.0033\tVal Loss: 0.0034\tVal MAE: 149633.09\telapsed: 0.04 mins\n",
      "Epoch 8: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 149477.29\telapsed: 0.05 mins\n",
      "Epoch 9: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 149557.79\telapsed: 0.06 mins\n",
      "Epoch 10: Train Loss: 0.0033\tVal Loss: 0.0034\tVal MAE: 149500.65\telapsed: 0.06 mins\n",
      "Epoch 11: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 149644.94\telapsed: 0.07 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 8\tVal loss: 0.0035\tVal MAE: 149477.29\tTotal time elapsed: 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 45 from 1.0/2016.0 to 9.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0370\tVal Loss: 0.0356\tVal MAE: 484161.32\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0065\tVal Loss: 0.0060\tVal MAE: 179470.07\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0036\tVal Loss: 0.0032\tVal MAE: 154514.29\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0035\tVal Loss: 0.0031\tVal MAE: 152900.45\telapsed: 0.03 mins\n",
      "Epoch 5: Train Loss: 0.0035\tVal Loss: 0.0031\tVal MAE: 153445.26\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0034\tVal Loss: 0.0031\tVal MAE: 153049.07\telapsed: 0.04 mins\n",
      "Epoch 7: Train Loss: 0.0035\tVal Loss: 0.0031\tVal MAE: 153334.36\telapsed: 0.05 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0031\tVal MAE: 152900.45\tTotal time elapsed: 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 46 from 1.0/2016.0 to 10.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0413\tVal Loss: 0.0397\tVal MAE: 503563.83\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0071\tVal Loss: 0.0070\tVal MAE: 147895.14\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0031\tVal Loss: 0.0037\tVal MAE: 116483.93\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0031\tVal Loss: 0.0037\tVal MAE: 116766.15\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0030\tVal Loss: 0.0037\tVal MAE: 117641.46\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0030\tVal Loss: 0.0037\tVal MAE: 117739.01\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0037\tVal MAE: 116483.93\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 47 from 1.0/2016.0 to 11.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0435\tVal Loss: 0.0422\tVal MAE: 536808.69\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0077\tVal Loss: 0.0072\tVal MAE: 163940.76\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0037\tVal Loss: 0.0033\tVal MAE: 119569.14\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0037\tVal Loss: 0.0033\tVal MAE: 121908.91\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0037\tVal Loss: 0.0033\tVal MAE: 122505.65\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0037\tVal Loss: 0.0033\tVal MAE: 122652.47\telapsed: 0.03 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0033\tVal MAE: 119569.14\tTotal time elapsed: 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 48 from 1.0/2016.0 to 12.0/2019.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0379\tVal Loss: 0.0369\tVal MAE: 496333.73\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0059\tVal Loss: 0.0060\tVal MAE: 189737.03\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0033\tVal Loss: 0.0036\tVal MAE: 170056.51\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 171045.81\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 173235.32\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0033\tVal Loss: 0.0035\tVal MAE: 172432.69\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0036\tVal MAE: 170056.51\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 49 from 1.0/2016.0 to 1.0/2021.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0425\tVal Loss: 0.0413\tVal MAE: 566521.31\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0078\tVal Loss: 0.0077\tVal MAE: 204250.60\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0035\tVal Loss: 0.0037\tVal MAE: 165986.36\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0034\tVal Loss: 0.0036\tVal MAE: 167212.66\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0034\tVal Loss: 0.0036\tVal MAE: 168686.17\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0034\tVal Loss: 0.0036\tVal MAE: 169173.19\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0037\tVal MAE: 165986.36\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 50 from 1.0/2016.0 to 2.0/2021.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0346\tVal Loss: 0.0333\tVal MAE: 456834.36\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0055\tVal Loss: 0.0050\tVal MAE: 164651.68\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0037\tVal Loss: 0.0032\tVal MAE: 145784.24\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0037\tVal Loss: 0.0032\tVal MAE: 146628.52\telapsed: 0.03 mins\n",
      "Epoch 5: Train Loss: 0.0037\tVal Loss: 0.0032\tVal MAE: 147967.62\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0037\tVal Loss: 0.0032\tVal MAE: 147863.80\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0032\tVal MAE: 145784.24\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 51 from 1.0/2016.0 to 3.0/2021.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0387\tVal Loss: 0.0376\tVal MAE: 510301.42\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0061\tVal Loss: 0.0060\tVal MAE: 184657.80\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0033\tVal Loss: 0.0034\tVal MAE: 163214.47\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0032\tVal Loss: 0.0034\tVal MAE: 163972.56\telapsed: 0.02 mins\n",
      "Epoch 5: Train Loss: 0.0032\tVal Loss: 0.0034\tVal MAE: 165245.00\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0032\tVal Loss: 0.0034\tVal MAE: 165557.81\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0034\tVal MAE: 163214.47\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 52 from 1.0/2016.0 to 4.0/2021.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0312\tVal Loss: 0.0305\tVal MAE: 456533.55\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0044\tVal Loss: 0.0049\tVal MAE: 198236.82\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0034\tVal Loss: 0.0041\tVal MAE: 194145.92\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0035\tVal Loss: 0.0041\tVal MAE: 194960.18\telapsed: 0.03 mins\n",
      "Epoch 5: Train Loss: 0.0035\tVal Loss: 0.0042\tVal MAE: 195340.36\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0035\tVal Loss: 0.0042\tVal MAE: 196817.07\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0041\tVal MAE: 194145.92\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 53 from 1.0/2016.0 to 5.0/2021.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0314\tVal Loss: 0.0301\tVal MAE: 438671.97\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0052\tVal Loss: 0.0046\tVal MAE: 170362.69\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0042\tVal Loss: 0.0036\tVal MAE: 159939.44\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0043\tVal Loss: 0.0036\tVal MAE: 160019.84\telapsed: 0.03 mins\n",
      "Epoch 5: Train Loss: 0.0043\tVal Loss: 0.0036\tVal MAE: 160228.11\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0043\tVal Loss: 0.0036\tVal MAE: 160423.03\telapsed: 0.04 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 3\tVal loss: 0.0036\tVal MAE: 159939.44\tTotal time elapsed: 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 54 from 1.0/2016.0 to 6.0/2021.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0263\tVal Loss: 0.0253\tVal MAE: 365544.93\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0041\tVal Loss: 0.0043\tVal MAE: 141859.19\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0036\tVal Loss: 0.0038\tVal MAE: 136547.35\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0036\tVal Loss: 0.0038\tVal MAE: 136113.56\telapsed: 0.03 mins\n",
      "Epoch 5: Train Loss: 0.0037\tVal Loss: 0.0039\tVal MAE: 136757.38\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0037\tVal Loss: 0.0039\tVal MAE: 136720.43\telapsed: 0.04 mins\n",
      "Epoch 7: Train Loss: 0.0036\tVal Loss: 0.0039\tVal MAE: 137042.54\telapsed: 0.05 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0038\tVal MAE: 136113.56\tTotal time elapsed: 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 55 from 1.0/2016.0 to 7.0/2021.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0248\tVal Loss: 0.0247\tVal MAE: 360919.24\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0041\tVal Loss: 0.0056\tVal MAE: 147437.26\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0036\tVal Loss: 0.0051\tVal MAE: 141286.61\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0036\tVal Loss: 0.0052\tVal MAE: 140906.98\telapsed: 0.03 mins\n",
      "Epoch 5: Train Loss: 0.0037\tVal Loss: 0.0052\tVal MAE: 141412.02\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0037\tVal Loss: 0.0052\tVal MAE: 140957.97\telapsed: 0.04 mins\n",
      "Epoch 7: Train Loss: 0.0037\tVal Loss: 0.0052\tVal MAE: 141091.21\telapsed: 0.05 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 4\tVal loss: 0.0052\tVal MAE: 140906.98\tTotal time elapsed: 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training step 56 from 1.0/2016.0 to 8.0/2021.0:\n",
      "\n",
      "\n",
      "Epoch 1: Train Loss: 0.0241\tVal Loss: 0.0224\tVal MAE: 300080.22\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0055\tVal Loss: 0.0041\tVal MAE: 92686.76\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0051\tVal Loss: 0.0036\tVal MAE: 88942.43\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0051\tVal Loss: 0.0036\tVal MAE: 89065.81\telapsed: 0.03 mins\n",
      "Epoch 5: Train Loss: 0.0051\tVal Loss: 0.0036\tVal MAE: 88251.50\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0052\tVal Loss: 0.0037\tVal MAE: 89387.30\telapsed: 0.04 mins\n",
      "Epoch 7: Train Loss: 0.0052\tVal Loss: 0.0037\tVal MAE: 90007.83\telapsed: 0.05 mins\n",
      "Epoch 8: Train Loss: 0.0052\tVal Loss: 0.0038\tVal MAE: 89217.54\telapsed: 0.06 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 5\tVal loss: 0.0036\tVal MAE: 88251.50\tTotal time elapsed: 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Average Val loss: 0.0042\tAverage Val MAE: 170167.7595\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from fossil.preprocessing import FossilDataset, collate_fn\n",
    "from fossil.models.blender import FossilBlender\n",
    "from fossil.utils.pipeline import FossilPipeline\n",
    "\n",
    "expanding_window = True\n",
    "models, metrics_list, loss_list,  = [], [], []\n",
    "train_set, val_set = [], []\n",
    "\n",
    "for ix in range(len(meta_dates[:-1])):\n",
    "    if expanding_window:\n",
    "        print('Training step {} from {}/{} to {}/{}:'.format(ix+1, meta_dates[0][0], meta_dates[0][1], meta_dates[ix][0], meta_dates[ix][1]))\n",
    "        print('\\n')\n",
    "        train_set += [meta_train[ix]]    \n",
    "        val_set += [meta_val[ix]]\n",
    "\n",
    "    # else:\n",
    "    #     print('Training step {} from {}/{} to {}/{}:'.format(ix+1, dates[ix-window][0], dates[ix-window][1], dates[ix][0], dates[ix][1]))\n",
    "    #     print('\\n')\n",
    "    #     train_set = [train_norm[i] for i in range(ix-window,ix)] if ix>window else train_norm[:ix+1]\n",
    "    #     val_set = [val_norm[i] for i in range(ix-window,ix)] if ix>window else val_norm[:ix+1]\n",
    "       \n",
    "    meta_train_set = FossilDataset(train_set)\n",
    "    meta_val_set = FossilDataset(val_set)\n",
    "\n",
    "    meta_train_loader = DataLoader(meta_train_set, collate_fn=lambda x: collate_fn(x, len(sku_encoder)), shuffle=False)\n",
    "    meta_val_loader = DataLoader(meta_val_set, collate_fn=lambda x: collate_fn(x, len(sku_encoder)), shuffle=False)\n",
    "    # model = pipe.model if ix>0 else FossilModel(len(features), 4, len(sku_encoder)+1, N_STEPS).double()\n",
    "    \n",
    "    model = FossilBlender(len(meta_features), 4, len(sku_encoder)+1, ModelsConfig.N_STEPS).double()\n",
    "    pipe = FossilPipeline(meta_train_loader, meta_val_loader, model, y_scaler)\n",
    "    \n",
    "    torch.manual_seed(ModelsConfig.SEED)\n",
    "    pipe.train_model(3, 1)\n",
    "    best_model, val_loss, metrics = pipe.model_checkpoints[-1]\n",
    "    \n",
    "    models.append(best_model)\n",
    "    loss_list.append(val_loss)\n",
    "    metrics_list.append(metrics)\n",
    "print('Average Val loss: {:.4f}\\tAverage Val MAE: {:.4f}'.format(np.mean(loss_list), np.mean(metrics_list)))\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fb6a6a5-7e6a-4f70-b36d-8808fab72cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil.preprocessing import FossilDataset, collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "meta_train_set = FossilDataset(meta_train)\n",
    "meta_val_set = FossilDataset(meta_val)\n",
    "\n",
    "meta_train_loader = DataLoader(meta_train_set, collate_fn=lambda x: collate_fn(x, len(sku_encoder)), shuffle=False)\n",
    "meta_val_loader = DataLoader(meta_val_set, collate_fn=lambda x: collate_fn(x, len(sku_encoder)), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "648480cf-3df3-4241-9c99-604a04b92724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fossil.models.blender import FossilBlender\n",
    "from fossil.utils.pipeline import FossilPipeline\n",
    "\n",
    "model = FossilBlender(len(meta_features), 4, len(sku_encoder)+1, ModelsConfig.N_STEPS).double()\n",
    "pipe = FossilPipeline(meta_train_loader, meta_val_loader, model, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf731de3-6d4e-4268-9d0c-f6f2acdec205",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0271\tVal Loss: 0.0254\tVal MAE: 337114.90\telapsed: 0.01 mins\n",
      "Epoch 2: Train Loss: 0.0058\tVal Loss: 0.0045\tVal MAE: 100048.10\telapsed: 0.01 mins\n",
      "Epoch 3: Train Loss: 0.0053\tVal Loss: 0.0039\tVal MAE: 90469.68\telapsed: 0.02 mins\n",
      "Epoch 4: Train Loss: 0.0053\tVal Loss: 0.0039\tVal MAE: 89237.33\telapsed: 0.03 mins\n",
      "Epoch 5: Train Loss: 0.0054\tVal Loss: 0.0040\tVal MAE: 89337.09\telapsed: 0.03 mins\n",
      "Epoch 6: Train Loss: 0.0054\tVal Loss: 0.0040\tVal MAE: 89189.73\telapsed: 0.04 mins\n",
      "Epoch 7: Train Loss: 0.0055\tVal Loss: 0.0041\tVal MAE: 89448.32\telapsed: 0.05 mins\n",
      "Epoch 8: Train Loss: 0.0055\tVal Loss: 0.0041\tVal MAE: 89061.62\telapsed: 0.06 mins\n",
      "Epoch 9: Train Loss: 0.0055\tVal Loss: 0.0041\tVal MAE: 89004.81\telapsed: 0.06 mins\n",
      "Epoch 10: Train Loss: 0.0055\tVal Loss: 0.0041\tVal MAE: 88362.44\telapsed: 0.07 mins\n",
      "Epoch 11: Train Loss: 0.0055\tVal Loss: 0.0042\tVal MAE: 89442.07\telapsed: 0.08 mins\n",
      "Epoch 12: Train Loss: 0.0056\tVal Loss: 0.0043\tVal MAE: 89163.07\telapsed: 0.08 mins\n",
      "Epoch 13: Train Loss: 0.0055\tVal Loss: 0.0042\tVal MAE: 88935.50\telapsed: 0.09 mins\n",
      "\n",
      "\n",
      "Early stopping: Best Epoch: 10\tVal loss: 0.0041\tVal MAE: 88362.44\tTotal time elapsed: 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(ModelsConfig.SEED)\n",
    "pipe.train_model(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32408f5b-5582-4621-833d-f020dd06fb50",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# primary_preds = primary_preds[primary_preds.sku_name.isin(test.sku_name.unique())]\n",
    "\n",
    "for i, preds in enumerate([primary_preds[target_cols].values, secondary_preds['Target'].values]):\n",
    "    meta_base = test_data.copy()\n",
    "    meta_base[pred_cols] = preds.reshape(-1, ModelsConfig.N_STEPS)\n",
    "    meta_padded = meta_base.groupby(['month','year']).apply(fossil_preproc.pad_sku_sequence, pad_value=np.nan)\n",
    "    meta_padded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    meta_primary = meta_padded.drop(columns=pred_cols)\n",
    "    meta_oof = meta_padded[pred_cols].values\n",
    "    meta_expanded = fossil_preproc.expand_primary_data(meta_primary, meta_oof, target_cols, pred_cols)\n",
    "\n",
    "    if i==0:\n",
    "        meta_data = meta_expanded.drop(columns=['preds']).copy()\n",
    "\n",
    "    meta_data[f'preds_{i}'] = meta_expanded['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d9b539a-5d35-4c14-aa9c-d05f8091feed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "meta_data['target'] = meta_data.groupby('sku_name')['target'].progress_transform(lambda x: x.fillna(x.median()))\n",
    "meta_data['target'] = meta_data.groupby(['month','year'])['target'].progress_transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982d3b7-a8bf-4dd6-ba84-d0fffcee13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data.fillna(0, inplace=True)\n",
    "\n",
    "meta_dates = sorted([(m, y) for y,m in meta_data.groupby(['year', 'month']).groups.keys()], key=lambda d: (d[1], d[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9018e553-135a-4e76-9d0d-c0b129e9dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta_features = [c for c in meta_data.columns if 'preds' in c]\n",
    "meta_targets = 'target'\n",
    "\n",
    "meta_data[meta_features] = x_scaler.transform(meta_data[meta_features])\n",
    "meta_data[meta_targets] = y_scaler.transform(meta_data[meta_targets].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "109dc8d8-4f62-4180-8b16-ebc25a8fb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['time_step'] = meta_data.groupby(['sku_name','sku_coded','month','year']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af7e41f4-c903-4b2c-8480-8526cc95fd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_test = get_data(meta_data, test_dates, meta_features, meta_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee1273a2-13a1-4262-99da-f7f73cb8846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(features, targets), y_test = meta_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5a170c4-fef8-4633-b670-7a8e19c7954b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMcvIW1lUAtw",
    "outputId": "63587449-77d0-4130-c358-3f069c0a9ac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.load_state_dict(pipe.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20b4f9a3-00f9-4782-94d8-d0d1899cd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_preds = model(torch.as_tensor(features).transpose(0,2).unsqueeze(0).to(ModelsConfig.device))\n",
    "pred_arr = meta_preds.detach().numpy().reshape(-1, ModelsConfig.N_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd70ba4b-b62e-440a-8ba4-39c8a3195678",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = meta_data[meta_data['sku_name']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d994e8f7-788b-4b63-97e7-3e104d7baa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28561/3396961515.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df['Target'] = pred_arr[sub_df['sku_coded'].astype(int).values, sub_df['time_step'].values]\n",
      "/tmp/ipykernel_28561/3396961515.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df['Target'] = y_scaler.inverse_transform(sub_df['Target'].values.reshape(-1, 1))\n"
     ]
    }
   ],
   "source": [
    "sub_df['Target'] = pred_arr[sub_df['sku_coded'].astype(int).values, sub_df['time_step'].values]\n",
    "sub_df['Target'] = y_scaler.inverse_transform(sub_df['Target'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c107a1ba-79ca-4c40-9467-513d10757957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28561/4129148662.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df['month'], sub_df['year'] = meta_secondary['month'], meta_secondary['year']\n"
     ]
    }
   ],
   "source": [
    "meta_secondary = fossil_preproc.prepare_secondary_data(meta_primary, meta_oof, target_cols, pred_cols)\n",
    "sub_df['month'], sub_df['year'] = meta_secondary['month'], meta_secondary['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53ab602b-506f-4405-8d40-2bae21058d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28561/2410078269.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df['target'] = y_scaler.inverse_transform(sub_df['target'].values.reshape(-1, 1));sub_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>target</th>\n",
       "      <th>time_step</th>\n",
       "      <th>preds_0</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>Target</th>\n",
       "      <th>Item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69536.362080</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>0.015553</td>\n",
       "      <td>12447.405347</td>\n",
       "      <td>ABEAHAMASHL_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>123358.571244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019387</td>\n",
       "      <td>0.027411</td>\n",
       "      <td>31869.806485</td>\n",
       "      <td>ABEAHAMASHL_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>100678.584110</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.017177</td>\n",
       "      <td>32274.814645</td>\n",
       "      <td>ABEAHAMASHL_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>109051.794236</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>18126.535988</td>\n",
       "      <td>ABEAHAMASHL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEANNAONEIZZ</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>168158.0</td>\n",
       "      <td>76988.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9117.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>61056.682074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>-6948.350256</td>\n",
       "      <td>ABEANNAONEIZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>1527604.0</td>\n",
       "      <td>288705.0</td>\n",
       "      <td>199561.0</td>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>289041.621090</td>\n",
       "      <td>3</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>0.064525</td>\n",
       "      <td>189049.415290</td>\n",
       "      <td>YOSHRENECARL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>283174.838744</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043466</td>\n",
       "      <td>0.072075</td>\n",
       "      <td>95887.859734</td>\n",
       "      <td>YOSHTLYNYOSHZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>302929.766945</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046443</td>\n",
       "      <td>0.079573</td>\n",
       "      <td>41056.740146</td>\n",
       "      <td>YOSHTLYNYOSHZZ_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>246794.438821</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.047513</td>\n",
       "      <td>53121.115963</td>\n",
       "      <td>YOSHTLYNYOSHZZ_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>222611.474320</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034341</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>98900.548081</td>\n",
       "      <td>YOSHTLYNYOSHZZ_2_2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2564 rows  85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month    year  starting_inventory    sellin  \\\n",
       "0        ABEAHAMASHL   11.0  2021.0            410265.0   18234.0   \n",
       "1        ABEAHAMASHL   12.0  2021.0            410265.0   18234.0   \n",
       "2        ABEAHAMASHL    1.0  2022.0            410265.0   18234.0   \n",
       "3        ABEAHAMASHL    2.0  2022.0            410265.0   18234.0   \n",
       "4      ABEANNAONEIZZ   11.0  2021.0            168158.0   76988.0   \n",
       "...              ...    ...     ...                 ...       ...   \n",
       "2559    YOSHRENECARL    2.0  2022.0           1527604.0  288705.0   \n",
       "2560  YOSHTLYNYOSHZZ   11.0  2021.0            156002.0  163093.0   \n",
       "2561  YOSHTLYNYOSHZZ   12.0  2021.0            156002.0  163093.0   \n",
       "2562  YOSHTLYNYOSHZZ    1.0  2022.0            156002.0  163093.0   \n",
       "2563  YOSHTLYNYOSHZZ    2.0  2022.0            156002.0  163093.0   \n",
       "\n",
       "      sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "0                  0.0               0.0               0.0            1013.0   \n",
       "1                  0.0               0.0               0.0            1013.0   \n",
       "2                  0.0               0.0               0.0            1013.0   \n",
       "3                  0.0               0.0               0.0            1013.0   \n",
       "4                  0.0           10130.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "2559          199561.0           79014.0               0.0               0.0   \n",
       "2560          122573.0           30390.0               0.0               0.0   \n",
       "2561          122573.0           30390.0               0.0               0.0   \n",
       "2562          122573.0           30390.0               0.0               0.0   \n",
       "2563          122573.0           30390.0               0.0               0.0   \n",
       "\n",
       "      sellin_channel_5  ...  leftover_inventory_9month_MM  price_6month_MM  \\\n",
       "0                  0.0  ...                      -16208.0            149.0   \n",
       "1                  0.0  ...                      -16208.0            149.0   \n",
       "2                  0.0  ...                      -16208.0            149.0   \n",
       "3                  0.0  ...                      -16208.0            149.0   \n",
       "4                  0.0  ...                       -9117.0            129.0   \n",
       "...                ...  ...                           ...              ...   \n",
       "2559               0.0  ...                      214756.0            129.0   \n",
       "2560               0.0  ...                      200574.0            149.0   \n",
       "2561               0.0  ...                      200574.0            149.0   \n",
       "2562               0.0  ...                      200574.0            149.0   \n",
       "2563               0.0  ...                      200574.0            149.0   \n",
       "\n",
       "      price_9month_MM  sku_coded         target  time_step   preds_0  \\\n",
       "0               149.0       74.0   69536.362080          0  0.011278   \n",
       "1               149.0       74.0  123358.571244          1  0.019387   \n",
       "2               149.0       74.0  100678.584110          2  0.015970   \n",
       "3               149.0       74.0  109051.794236          3  0.017231   \n",
       "4               129.0     2241.0   61056.682074          0  0.010000   \n",
       "...               ...        ...            ...        ...       ...   \n",
       "2559            129.0      248.0  289041.621090          3  0.044350   \n",
       "2560            149.0     1852.0  283174.838744          0  0.043466   \n",
       "2561            149.0     1852.0  302929.766945          1  0.046443   \n",
       "2562            149.0     1852.0  246794.438821          2  0.037985   \n",
       "2563            149.0     1852.0  222611.474320          3  0.034341   \n",
       "\n",
       "       preds_1         Target                 Item_ID  \n",
       "0     0.015553   12447.405347     ABEAHAMASHL_11_2021  \n",
       "1     0.027411   31869.806485     ABEAHAMASHL_12_2021  \n",
       "2     0.017177   32274.814645      ABEAHAMASHL_1_2022  \n",
       "3     0.019645   18126.535988      ABEAHAMASHL_2_2022  \n",
       "4     0.012935   -6948.350256   ABEANNAONEIZZ_11_2021  \n",
       "...        ...            ...                     ...  \n",
       "2559  0.064525  189049.415290     YOSHRENECARL_2_2022  \n",
       "2560  0.072075   95887.859734  YOSHTLYNYOSHZZ_11_2021  \n",
       "2561  0.079573   41056.740146  YOSHTLYNYOSHZZ_12_2021  \n",
       "2562  0.047513   53121.115963   YOSHTLYNYOSHZZ_1_2022  \n",
       "2563  0.046823   98900.548081   YOSHTLYNYOSHZZ_2_2022  \n",
       "\n",
       "[2564 rows x 85 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df['target'] = y_scaler.inverse_transform(sub_df['target'].values.reshape(-1, 1));sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2772c327-9043-4e10-81cf-6b6ca4c382b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_6month_MM</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229444.5</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69536.362080</td>\n",
       "      <td>43735.480111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229444.5</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>123358.571244</td>\n",
       "      <td>77079.006822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229444.5</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>100678.584110</td>\n",
       "      <td>48301.075780</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229444.5</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>109051.794236</td>\n",
       "      <td>55242.775411</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEANNAONEIZZ</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>168158.0</td>\n",
       "      <td>76988.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75468.5</td>\n",
       "      <td>176262.0</td>\n",
       "      <td>-8104.0</td>\n",
       "      <td>-9117.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>61056.682074</td>\n",
       "      <td>36373.702684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15363</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3839.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15364</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15367</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15368 rows  82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month    year  starting_inventory   sellin  \\\n",
       "0        ABEAHAMASHL   10.0  2021.0            410265.0  18234.0   \n",
       "1        ABEAHAMASHL   10.0  2021.0            410265.0  18234.0   \n",
       "2        ABEAHAMASHL   10.0  2021.0            410265.0  18234.0   \n",
       "3        ABEAHAMASHL   10.0  2021.0            410265.0  18234.0   \n",
       "4      ABEANNAONEIZZ   10.0  2021.0            168158.0  76988.0   \n",
       "...              ...    ...     ...                 ...      ...   \n",
       "15363            NaN   10.0  2021.0                 NaN      NaN   \n",
       "15364            NaN   10.0  2021.0                 NaN      NaN   \n",
       "15365            NaN   10.0  2021.0                 NaN      NaN   \n",
       "15366            NaN   10.0  2021.0                 NaN      NaN   \n",
       "15367            NaN   10.0  2021.0                 NaN      NaN   \n",
       "\n",
       "       sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "0                   0.0               0.0               0.0            1013.0   \n",
       "1                   0.0               0.0               0.0            1013.0   \n",
       "2                   0.0               0.0               0.0            1013.0   \n",
       "3                   0.0               0.0               0.0            1013.0   \n",
       "4                   0.0           10130.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "15363               NaN               NaN               NaN               NaN   \n",
       "15364               NaN               NaN               NaN               NaN   \n",
       "15365               NaN               NaN               NaN               NaN   \n",
       "15366               NaN               NaN               NaN               NaN   \n",
       "15367               NaN               NaN               NaN               NaN   \n",
       "\n",
       "       sellin_channel_5  ...  onhand_inventory_6month_MM  \\\n",
       "0                   0.0  ...                    229444.5   \n",
       "1                   0.0  ...                    229444.5   \n",
       "2                   0.0  ...                    229444.5   \n",
       "3                   0.0  ...                    229444.5   \n",
       "4                   0.0  ...                     75468.5   \n",
       "...                 ...  ...                         ...   \n",
       "15363               NaN  ...                         NaN   \n",
       "15364               NaN  ...                         NaN   \n",
       "15365               NaN  ...                         NaN   \n",
       "15366               NaN  ...                         NaN   \n",
       "15367               NaN  ...                         NaN   \n",
       "\n",
       "       onhand_inventory_9month_MM  leftover_inventory_6month_MM  \\\n",
       "0                        291744.0                      -13675.5   \n",
       "1                        291744.0                      -13675.5   \n",
       "2                        291744.0                      -13675.5   \n",
       "3                        291744.0                      -13675.5   \n",
       "4                        176262.0                       -8104.0   \n",
       "...                           ...                           ...   \n",
       "15363                         NaN                           NaN   \n",
       "15364                         NaN                           NaN   \n",
       "15365                         NaN                           NaN   \n",
       "15366                         NaN                           NaN   \n",
       "15367                         NaN                           NaN   \n",
       "\n",
       "       leftover_inventory_9month_MM  price_6month_MM  price_9month_MM  \\\n",
       "0                          -16208.0            149.0            149.0   \n",
       "1                          -16208.0            149.0            149.0   \n",
       "2                          -16208.0            149.0            149.0   \n",
       "3                          -16208.0            149.0            149.0   \n",
       "4                           -9117.0            129.0            129.0   \n",
       "...                             ...              ...              ...   \n",
       "15363                           NaN              NaN              NaN   \n",
       "15364                           NaN              NaN              NaN   \n",
       "15365                           NaN              NaN              NaN   \n",
       "15366                           NaN              NaN              NaN   \n",
       "15367                           NaN              NaN              NaN   \n",
       "\n",
       "       sku_coded         target         preds  time_step  \n",
       "0           74.0   69536.362080  43735.480111          0  \n",
       "1           74.0  123358.571244  77079.006822          1  \n",
       "2           74.0  100678.584110  48301.075780          2  \n",
       "3           74.0  109051.794236  55242.775411          3  \n",
       "4         2241.0   61056.682074  36373.702684          0  \n",
       "...          ...            ...           ...        ...  \n",
       "15363     3839.0            NaN           NaN      12799  \n",
       "15364     3840.0            NaN           NaN      12800  \n",
       "15365     3840.0            NaN           NaN      12801  \n",
       "15366     3840.0            NaN           NaN      12802  \n",
       "15367     3840.0            NaN           NaN      12803  \n",
       "\n",
       "[15368 rows x 82 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_secondary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
