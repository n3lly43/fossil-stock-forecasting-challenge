{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85bd596",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8376677b",
   "metadata": {
    "id": "6cdpG2ZoV1ig"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "\n",
    "TRAIN_DIR = f'{DATA_DIR}/train'\n",
    "TEST_DIR = f'{DATA_DIR}/test'\n",
    "\n",
    "PLOTS_DIR = f'{DATA_DIR}/plots'\n",
    "\n",
    "OUTPUT_DIR = f'{DATA_DIR}/output'\n",
    "MODEL_CHECKPOINT_DIR = f'{DATA_DIR}/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38cc4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "for pth in [TRAIN_DIR, TEST_DIR, OUTPUT_DIR, MODEL_CHECKPOINT_DIR]:\n",
    "    if path.exists(pth) == False:\n",
    "        os.mkdir(pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25be99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = pd.read_csv(f'{TRAIN_DIR}/Train.csv')\n",
    "desc = pd.read_csv(f'{DATA_DIR}/DataDictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6b72e-e5a5-4aa3-874d-0b28adaa55b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e136fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CAT = desc[36:]['Column Name'].tolist()\n",
    "train_df = train.drop(columns=CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99a56fbb-e73b-456f-bad5-a9e6c9711eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "timespan = train_df.groupby('sku_name').size()\n",
    "max_len = timespan.max()\n",
    "sample = list(set(timespan[timespan>=(max_len*.6)].index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4919736c-251b-49f7-84fa-19fe32ee6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train = train_df.copy()\n",
    "exp_train['date'] = exp_train['month'].astype(str)+'/'+exp_train['year'].astype(str)\n",
    "exp_train = exp_train.set_index(exp_train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b73d4e6c-6813-4e1a-9d3c-659aec5fc102",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>sellin_channel_6</th>\n",
       "      <th>sellin_channel_7</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_channel_4</th>\n",
       "      <th>onhand_inventory_channel_5</th>\n",
       "      <th>onhand_inventory_channel_6</th>\n",
       "      <th>onhand_inventory_channel_7</th>\n",
       "      <th>onhand_inventory_channel_8</th>\n",
       "      <th>onhand_inventory_channel_9</th>\n",
       "      <th>onhand_inventory_channel_10</th>\n",
       "      <th>price</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21401</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>864089</td>\n",
       "      <td>462941</td>\n",
       "      <td>232990</td>\n",
       "      <td>28364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9117</td>\n",
       "      <td>15195</td>\n",
       "      <td>...</td>\n",
       "      <td>3039</td>\n",
       "      <td>375823</td>\n",
       "      <td>0</td>\n",
       "      <td>124599</td>\n",
       "      <td>1013</td>\n",
       "      <td>398109</td>\n",
       "      <td>151950</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21402</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>530812</td>\n",
       "      <td>258315</td>\n",
       "      <td>22286</td>\n",
       "      <td>24312</td>\n",
       "      <td>0</td>\n",
       "      <td>20260</td>\n",
       "      <td>19247</td>\n",
       "      <td>71923</td>\n",
       "      <td>...</td>\n",
       "      <td>3039</td>\n",
       "      <td>206652</td>\n",
       "      <td>0</td>\n",
       "      <td>123586</td>\n",
       "      <td>0</td>\n",
       "      <td>397096</td>\n",
       "      <td>150937</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21403</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>939051</td>\n",
       "      <td>270471</td>\n",
       "      <td>228938</td>\n",
       "      <td>18234</td>\n",
       "      <td>0</td>\n",
       "      <td>60780</td>\n",
       "      <td>13169</td>\n",
       "      <td>304913</td>\n",
       "      <td>...</td>\n",
       "      <td>2026</td>\n",
       "      <td>333277</td>\n",
       "      <td>0</td>\n",
       "      <td>132703</td>\n",
       "      <td>0</td>\n",
       "      <td>434577</td>\n",
       "      <td>143846</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21404</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>605774</td>\n",
       "      <td>249198</td>\n",
       "      <td>259328</td>\n",
       "      <td>20260</td>\n",
       "      <td>3039</td>\n",
       "      <td>6078</td>\n",
       "      <td>15195</td>\n",
       "      <td>4052</td>\n",
       "      <td>...</td>\n",
       "      <td>2026</td>\n",
       "      <td>298835</td>\n",
       "      <td>0</td>\n",
       "      <td>114469</td>\n",
       "      <td>0</td>\n",
       "      <td>210704</td>\n",
       "      <td>143846</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21405</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>488266</td>\n",
       "      <td>285666</td>\n",
       "      <td>25325</td>\n",
       "      <td>25325</td>\n",
       "      <td>2026</td>\n",
       "      <td>60780</td>\n",
       "      <td>8104</td>\n",
       "      <td>12156</td>\n",
       "      <td>...</td>\n",
       "      <td>2026</td>\n",
       "      <td>278575</td>\n",
       "      <td>0</td>\n",
       "      <td>119534</td>\n",
       "      <td>0</td>\n",
       "      <td>148911</td>\n",
       "      <td>135742</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21406</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>889414</td>\n",
       "      <td>535877</td>\n",
       "      <td>75975</td>\n",
       "      <td>44572</td>\n",
       "      <td>0</td>\n",
       "      <td>79014</td>\n",
       "      <td>13169</td>\n",
       "      <td>42546</td>\n",
       "      <td>...</td>\n",
       "      <td>2026</td>\n",
       "      <td>303900</td>\n",
       "      <td>0</td>\n",
       "      <td>117508</td>\n",
       "      <td>2026</td>\n",
       "      <td>166132</td>\n",
       "      <td>130677</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21407</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>658450</td>\n",
       "      <td>378862</td>\n",
       "      <td>7091</td>\n",
       "      <td>31403</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>11143</td>\n",
       "      <td>78001</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>315043</td>\n",
       "      <td>0</td>\n",
       "      <td>131690</td>\n",
       "      <td>1013</td>\n",
       "      <td>99274</td>\n",
       "      <td>144859</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21408</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>546007</td>\n",
       "      <td>301874</td>\n",
       "      <td>22286</td>\n",
       "      <td>49637</td>\n",
       "      <td>1013</td>\n",
       "      <td>81040</td>\n",
       "      <td>12156</td>\n",
       "      <td>15195</td>\n",
       "      <td>...</td>\n",
       "      <td>7091</td>\n",
       "      <td>192470</td>\n",
       "      <td>0</td>\n",
       "      <td>108391</td>\n",
       "      <td>0</td>\n",
       "      <td>94209</td>\n",
       "      <td>157015</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21409</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>1007935</td>\n",
       "      <td>612865</td>\n",
       "      <td>52676</td>\n",
       "      <td>69897</td>\n",
       "      <td>4052</td>\n",
       "      <td>131690</td>\n",
       "      <td>20260</td>\n",
       "      <td>20260</td>\n",
       "      <td>...</td>\n",
       "      <td>5065</td>\n",
       "      <td>308965</td>\n",
       "      <td>0</td>\n",
       "      <td>96235</td>\n",
       "      <td>0</td>\n",
       "      <td>100287</td>\n",
       "      <td>177275</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21410</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>911700</td>\n",
       "      <td>707074</td>\n",
       "      <td>43559</td>\n",
       "      <td>39507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16208</td>\n",
       "      <td>3039</td>\n",
       "      <td>...</td>\n",
       "      <td>4052</td>\n",
       "      <td>346446</td>\n",
       "      <td>0</td>\n",
       "      <td>93196</td>\n",
       "      <td>0</td>\n",
       "      <td>89144</td>\n",
       "      <td>170184</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21411</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>1524565</td>\n",
       "      <td>688840</td>\n",
       "      <td>142833</td>\n",
       "      <td>419382</td>\n",
       "      <td>14182</td>\n",
       "      <td>22286</td>\n",
       "      <td>35455</td>\n",
       "      <td>35455</td>\n",
       "      <td>...</td>\n",
       "      <td>17221</td>\n",
       "      <td>364680</td>\n",
       "      <td>0</td>\n",
       "      <td>91170</td>\n",
       "      <td>0</td>\n",
       "      <td>40520</td>\n",
       "      <td>385953</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>2005740</td>\n",
       "      <td>1060611</td>\n",
       "      <td>141820</td>\n",
       "      <td>286679</td>\n",
       "      <td>0</td>\n",
       "      <td>75975</td>\n",
       "      <td>134729</td>\n",
       "      <td>25325</td>\n",
       "      <td>...</td>\n",
       "      <td>11143</td>\n",
       "      <td>335303</td>\n",
       "      <td>0</td>\n",
       "      <td>75975</td>\n",
       "      <td>0</td>\n",
       "      <td>50650</td>\n",
       "      <td>312004</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>424447</td>\n",
       "      <td>270471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55715</td>\n",
       "      <td>9117</td>\n",
       "      <td>3039</td>\n",
       "      <td>...</td>\n",
       "      <td>8104</td>\n",
       "      <td>330238</td>\n",
       "      <td>0</td>\n",
       "      <td>71923</td>\n",
       "      <td>0</td>\n",
       "      <td>33429</td>\n",
       "      <td>303900</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>163093</td>\n",
       "      <td>73949</td>\n",
       "      <td>30390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23299</td>\n",
       "      <td>0</td>\n",
       "      <td>7091</td>\n",
       "      <td>...</td>\n",
       "      <td>8104</td>\n",
       "      <td>316056</td>\n",
       "      <td>0</td>\n",
       "      <td>57741</td>\n",
       "      <td>0</td>\n",
       "      <td>69897</td>\n",
       "      <td>279588</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>60780</td>\n",
       "      <td>32416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2026</td>\n",
       "      <td>...</td>\n",
       "      <td>7091</td>\n",
       "      <td>304913</td>\n",
       "      <td>0</td>\n",
       "      <td>54702</td>\n",
       "      <td>0</td>\n",
       "      <td>63819</td>\n",
       "      <td>232990</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>50650</td>\n",
       "      <td>28364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9117</td>\n",
       "      <td>281614</td>\n",
       "      <td>0</td>\n",
       "      <td>41533</td>\n",
       "      <td>1013</td>\n",
       "      <td>29377</td>\n",
       "      <td>226912</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21417</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>1304744</td>\n",
       "      <td>652372</td>\n",
       "      <td>205639</td>\n",
       "      <td>56728</td>\n",
       "      <td>2026</td>\n",
       "      <td>207665</td>\n",
       "      <td>12156</td>\n",
       "      <td>56728</td>\n",
       "      <td>...</td>\n",
       "      <td>6078</td>\n",
       "      <td>249198</td>\n",
       "      <td>0</td>\n",
       "      <td>46598</td>\n",
       "      <td>2026</td>\n",
       "      <td>20260</td>\n",
       "      <td>220834</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21418</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>215769</td>\n",
       "      <td>57741</td>\n",
       "      <td>122573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6078</td>\n",
       "      <td>3039</td>\n",
       "      <td>...</td>\n",
       "      <td>6078</td>\n",
       "      <td>264393</td>\n",
       "      <td>0</td>\n",
       "      <td>44572</td>\n",
       "      <td>1013</td>\n",
       "      <td>52676</td>\n",
       "      <td>200574</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21419</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>47611</td>\n",
       "      <td>25325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6078</td>\n",
       "      <td>281614</td>\n",
       "      <td>0</td>\n",
       "      <td>31403</td>\n",
       "      <td>1013</td>\n",
       "      <td>32416</td>\n",
       "      <td>181327</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21420</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>246159</td>\n",
       "      <td>201587</td>\n",
       "      <td>0</td>\n",
       "      <td>9117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4052</td>\n",
       "      <td>285666</td>\n",
       "      <td>0</td>\n",
       "      <td>24312</td>\n",
       "      <td>1013</td>\n",
       "      <td>25325</td>\n",
       "      <td>162080</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21421</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>1552929</td>\n",
       "      <td>747594</td>\n",
       "      <td>247172</td>\n",
       "      <td>123586</td>\n",
       "      <td>45585</td>\n",
       "      <td>224886</td>\n",
       "      <td>18234</td>\n",
       "      <td>38494</td>\n",
       "      <td>...</td>\n",
       "      <td>37481</td>\n",
       "      <td>293770</td>\n",
       "      <td>0</td>\n",
       "      <td>40520</td>\n",
       "      <td>1013</td>\n",
       "      <td>32416</td>\n",
       "      <td>177275</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21422</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>937025</td>\n",
       "      <td>425460</td>\n",
       "      <td>10130</td>\n",
       "      <td>42546</td>\n",
       "      <td>392031</td>\n",
       "      <td>0</td>\n",
       "      <td>10130</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>380888</td>\n",
       "      <td>257302</td>\n",
       "      <td>0</td>\n",
       "      <td>30390</td>\n",
       "      <td>3039</td>\n",
       "      <td>23299</td>\n",
       "      <td>176262</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21423</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>811413</td>\n",
       "      <td>424447</td>\n",
       "      <td>26338</td>\n",
       "      <td>48624</td>\n",
       "      <td>70910</td>\n",
       "      <td>6078</td>\n",
       "      <td>22286</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>285666</td>\n",
       "      <td>268445</td>\n",
       "      <td>0</td>\n",
       "      <td>21273</td>\n",
       "      <td>3039</td>\n",
       "      <td>8104</td>\n",
       "      <td>201587</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21424</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>989701</td>\n",
       "      <td>528786</td>\n",
       "      <td>70910</td>\n",
       "      <td>207665</td>\n",
       "      <td>5065</td>\n",
       "      <td>0</td>\n",
       "      <td>116495</td>\n",
       "      <td>2026</td>\n",
       "      <td>...</td>\n",
       "      <td>101300</td>\n",
       "      <td>266419</td>\n",
       "      <td>0</td>\n",
       "      <td>22286</td>\n",
       "      <td>1013</td>\n",
       "      <td>17221</td>\n",
       "      <td>167145</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21425</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>412291</td>\n",
       "      <td>76988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>238055</td>\n",
       "      <td>0</td>\n",
       "      <td>44572</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>521695</td>\n",
       "      <td>257302</td>\n",
       "      <td>0</td>\n",
       "      <td>16208</td>\n",
       "      <td>1013</td>\n",
       "      <td>22286</td>\n",
       "      <td>123586</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21426</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>137768</td>\n",
       "      <td>25325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8104</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>540942</td>\n",
       "      <td>170184</td>\n",
       "      <td>0</td>\n",
       "      <td>17221</td>\n",
       "      <td>1013</td>\n",
       "      <td>15195</td>\n",
       "      <td>96235</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21427</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>48624</td>\n",
       "      <td>21273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>464967</td>\n",
       "      <td>130677</td>\n",
       "      <td>0</td>\n",
       "      <td>14182</td>\n",
       "      <td>1013</td>\n",
       "      <td>13169</td>\n",
       "      <td>85092</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21428</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>33429</td>\n",
       "      <td>29377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2026</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>396083</td>\n",
       "      <td>78001</td>\n",
       "      <td>0</td>\n",
       "      <td>13169</td>\n",
       "      <td>1013</td>\n",
       "      <td>17221</td>\n",
       "      <td>72936</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21429</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>19247</td>\n",
       "      <td>14182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>353537</td>\n",
       "      <td>112443</td>\n",
       "      <td>0</td>\n",
       "      <td>11143</td>\n",
       "      <td>1013</td>\n",
       "      <td>13169</td>\n",
       "      <td>47611</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21430</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>82053</td>\n",
       "      <td>52676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11143</td>\n",
       "      <td>10130</td>\n",
       "      <td>...</td>\n",
       "      <td>250211</td>\n",
       "      <td>58754</td>\n",
       "      <td>0</td>\n",
       "      <td>9117</td>\n",
       "      <td>1013</td>\n",
       "      <td>4052</td>\n",
       "      <td>27351</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21431</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>120547</td>\n",
       "      <td>73949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36468</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154989</td>\n",
       "      <td>64832</td>\n",
       "      <td>0</td>\n",
       "      <td>7091</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>11143</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21432</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>59767</td>\n",
       "      <td>33429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24312</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>90157</td>\n",
       "      <td>58754</td>\n",
       "      <td>0</td>\n",
       "      <td>3039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9117</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21433</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>24312</td>\n",
       "      <td>9117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13169</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3039</td>\n",
       "      <td>57741</td>\n",
       "      <td>0</td>\n",
       "      <td>3039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7091</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21434</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>51663</td>\n",
       "      <td>45585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6078</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>53689</td>\n",
       "      <td>0</td>\n",
       "      <td>3039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5065</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21435</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>222860</td>\n",
       "      <td>217795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5065</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41533</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8104</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21436</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>170184</td>\n",
       "      <td>167145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>39507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9117</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21437</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>101300</td>\n",
       "      <td>93196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>33429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>4052</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21438</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>45585</td>\n",
       "      <td>44572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>20260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3039</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21439</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>8104</td>\n",
       "      <td>7091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>31403</td>\n",
       "      <td>0</td>\n",
       "      <td>2026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21440</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>26338</td>\n",
       "      <td>26338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>31403</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21441</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>28364</td>\n",
       "      <td>28364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>28364</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>141820</td>\n",
       "      <td>141820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>32416</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21443</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>6078</td>\n",
       "      <td>6078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>29377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21444</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>19247</td>\n",
       "      <td>19247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>29377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21445</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>43559</td>\n",
       "      <td>43559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>24312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21446</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>334290</td>\n",
       "      <td>300861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21447</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>334290</td>\n",
       "      <td>300861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>22286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21448</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>560189</td>\n",
       "      <td>526760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21449</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>0</td>\n",
       "      <td>560189</td>\n",
       "      <td>526760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>22286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21450</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>419382</td>\n",
       "      <td>15195</td>\n",
       "      <td>15195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>20260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21451</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>842816</td>\n",
       "      <td>83066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75975</td>\n",
       "      <td>11143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21452</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>665541</td>\n",
       "      <td>182340</td>\n",
       "      <td>138781</td>\n",
       "      <td>12156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37481</td>\n",
       "      <td>9117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21453</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>529799</td>\n",
       "      <td>140807</td>\n",
       "      <td>49637</td>\n",
       "      <td>30390</td>\n",
       "      <td>56728</td>\n",
       "      <td>4052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33429</td>\n",
       "      <td>4052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21454</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>481175</td>\n",
       "      <td>49637</td>\n",
       "      <td>49637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36468</td>\n",
       "      <td>9117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>420395</td>\n",
       "      <td>60780</td>\n",
       "      <td>55715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80027</td>\n",
       "      <td>2026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21456</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>419382</td>\n",
       "      <td>2026</td>\n",
       "      <td>2026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44572</td>\n",
       "      <td>3039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21457</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>417356</td>\n",
       "      <td>2026</td>\n",
       "      <td>2026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37481</td>\n",
       "      <td>3039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>1292588</td>\n",
       "      <td>151950</td>\n",
       "      <td>151950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32416</td>\n",
       "      <td>2026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>KEVAROBRIGO</td>\n",
       "      <td>1372615</td>\n",
       "      <td>1035286</td>\n",
       "      <td>1035286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26338</td>\n",
       "      <td>4052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sku_name  starting_inventory   sellin  sellin_channel_1  \\\n",
       "21401  KEVAROBRIGO                   0   864089            462941   \n",
       "21402  KEVAROBRIGO                   0   530812            258315   \n",
       "21403  KEVAROBRIGO                   0   939051            270471   \n",
       "21404  KEVAROBRIGO                   0   605774            249198   \n",
       "21405  KEVAROBRIGO                   0   488266            285666   \n",
       "21406  KEVAROBRIGO                   0   889414            535877   \n",
       "21407  KEVAROBRIGO                   0   658450            378862   \n",
       "21408  KEVAROBRIGO                   0   546007            301874   \n",
       "21409  KEVAROBRIGO                   0  1007935            612865   \n",
       "21410  KEVAROBRIGO                   0   911700            707074   \n",
       "21411  KEVAROBRIGO                   0  1524565            688840   \n",
       "21412  KEVAROBRIGO                   0  2005740           1060611   \n",
       "21413  KEVAROBRIGO                   0   424447            270471   \n",
       "21414  KEVAROBRIGO                   0   163093             73949   \n",
       "21415  KEVAROBRIGO                   0    60780             32416   \n",
       "21416  KEVAROBRIGO                   0    50650             28364   \n",
       "21417  KEVAROBRIGO                   0  1304744            652372   \n",
       "21418  KEVAROBRIGO                   0   215769             57741   \n",
       "21419  KEVAROBRIGO                   0    47611             25325   \n",
       "21420  KEVAROBRIGO                   0   246159            201587   \n",
       "21421  KEVAROBRIGO                   0  1552929            747594   \n",
       "21422  KEVAROBRIGO                   0   937025            425460   \n",
       "21423  KEVAROBRIGO                   0   811413            424447   \n",
       "21424  KEVAROBRIGO                   0   989701            528786   \n",
       "21425  KEVAROBRIGO                   0   412291             76988   \n",
       "21426  KEVAROBRIGO                   0   137768             25325   \n",
       "21427  KEVAROBRIGO                   0    48624             21273   \n",
       "21428  KEVAROBRIGO                   0    33429             29377   \n",
       "21429  KEVAROBRIGO                   0    19247             14182   \n",
       "21430  KEVAROBRIGO                   0    82053             52676   \n",
       "21431  KEVAROBRIGO                   0   120547             73949   \n",
       "21432  KEVAROBRIGO                   0    59767             33429   \n",
       "21433  KEVAROBRIGO                   0    24312              9117   \n",
       "21434  KEVAROBRIGO                   0    51663             45585   \n",
       "21435  KEVAROBRIGO                   0   222860            217795   \n",
       "21436  KEVAROBRIGO                   0   170184            167145   \n",
       "21437  KEVAROBRIGO                   0   101300             93196   \n",
       "21438  KEVAROBRIGO                   0    45585             44572   \n",
       "21439  KEVAROBRIGO                   0     8104              7091   \n",
       "21440  KEVAROBRIGO                   0    26338             26338   \n",
       "21441  KEVAROBRIGO                   0    28364             28364   \n",
       "21442  KEVAROBRIGO                   0   141820            141820   \n",
       "21443  KEVAROBRIGO                   0     6078              6078   \n",
       "21444  KEVAROBRIGO                   0    19247             19247   \n",
       "21445  KEVAROBRIGO                   0    43559             43559   \n",
       "21446  KEVAROBRIGO                   0   334290            300861   \n",
       "21447  KEVAROBRIGO                   0   334290            300861   \n",
       "21448  KEVAROBRIGO                   0   560189            526760   \n",
       "21449  KEVAROBRIGO                   0   560189            526760   \n",
       "21450  KEVAROBRIGO              419382    15195             15195   \n",
       "21451  KEVAROBRIGO              842816    83066                 0   \n",
       "21452  KEVAROBRIGO              665541   182340            138781   \n",
       "21453  KEVAROBRIGO              529799   140807             49637   \n",
       "21454  KEVAROBRIGO              481175    49637             49637   \n",
       "21455  KEVAROBRIGO              420395    60780             55715   \n",
       "21456  KEVAROBRIGO              419382     2026              2026   \n",
       "21457  KEVAROBRIGO              417356     2026              2026   \n",
       "21458  KEVAROBRIGO             1292588   151950            151950   \n",
       "21459  KEVAROBRIGO             1372615  1035286           1035286   \n",
       "\n",
       "       sellin_channel_2  sellin_channel_3  sellin_channel_4  sellin_channel_5  \\\n",
       "21401            232990             28364                 0                 0   \n",
       "21402             22286             24312                 0             20260   \n",
       "21403            228938             18234                 0             60780   \n",
       "21404            259328             20260              3039              6078   \n",
       "21405             25325             25325              2026             60780   \n",
       "21406             75975             44572                 0             79014   \n",
       "21407              7091             31403              1013                 0   \n",
       "21408             22286             49637              1013             81040   \n",
       "21409             52676             69897              4052            131690   \n",
       "21410             43559             39507                 0                 0   \n",
       "21411            142833            419382             14182             22286   \n",
       "21412            141820            286679                 0             75975   \n",
       "21413                 0                 0                 0             55715   \n",
       "21414             30390                 0                 0             23299   \n",
       "21415                 0                 0                 0                 0   \n",
       "21416                 0                 0                 0                 0   \n",
       "21417            205639             56728              2026            207665   \n",
       "21418            122573                 0                 0                 0   \n",
       "21419                 0                 0                 0                 0   \n",
       "21420                 0              9117                 0                 0   \n",
       "21421            247172            123586             45585            224886   \n",
       "21422             10130             42546            392031                 0   \n",
       "21423             26338             48624             70910              6078   \n",
       "21424             70910            207665              5065                 0   \n",
       "21425                 0                 0            238055                 0   \n",
       "21426                 0                 0                 0                 0   \n",
       "21427                 0                 0                 0                 0   \n",
       "21428                 0                 0                 0                 0   \n",
       "21429                 0                 0                 0                 0   \n",
       "21430                 0                 0                 0                 0   \n",
       "21431                 0                 0                 0                 0   \n",
       "21432                 0                 0                 0                 0   \n",
       "21433                 0                 0                 0                 0   \n",
       "21434                 0                 0                 0                 0   \n",
       "21435                 0                 0                 0                 0   \n",
       "21436                 0                 0                 0                 0   \n",
       "21437                 0                 0                 0                 0   \n",
       "21438                 0                 0                 0                 0   \n",
       "21439                 0                 0                 0                 0   \n",
       "21440                 0                 0                 0                 0   \n",
       "21441                 0                 0                 0                 0   \n",
       "21442                 0                 0                 0                 0   \n",
       "21443                 0                 0                 0                 0   \n",
       "21444                 0                 0                 0                 0   \n",
       "21445                 0                 0                 0                 0   \n",
       "21446                 0                 0                 0                 0   \n",
       "21447                 0                 0                 0                 0   \n",
       "21448                 0                 0                 0                 0   \n",
       "21449                 0                 0                 0                 0   \n",
       "21450                 0                 0                 0                 0   \n",
       "21451                 0                 0             81040                 0   \n",
       "21452             12156                 0                 0                 0   \n",
       "21453             30390             56728              4052                 0   \n",
       "21454                 0                 0                 0                 0   \n",
       "21455                 0                 0                 0              5065   \n",
       "21456                 0                 0                 0                 0   \n",
       "21457                 0                 0                 0                 0   \n",
       "21458                 0                 0                 0                 0   \n",
       "21459                 0                 0                 0                 0   \n",
       "\n",
       "       sellin_channel_6  sellin_channel_7  ...  onhand_inventory_channel_4  \\\n",
       "21401              9117             15195  ...                        3039   \n",
       "21402             19247             71923  ...                        3039   \n",
       "21403             13169            304913  ...                        2026   \n",
       "21404             15195              4052  ...                        2026   \n",
       "21405              8104             12156  ...                        2026   \n",
       "21406             13169             42546  ...                        2026   \n",
       "21407             11143             78001  ...                        1013   \n",
       "21408             12156             15195  ...                        7091   \n",
       "21409             20260             20260  ...                        5065   \n",
       "21410             16208              3039  ...                        4052   \n",
       "21411             35455             35455  ...                       17221   \n",
       "21412            134729             25325  ...                       11143   \n",
       "21413              9117              3039  ...                        8104   \n",
       "21414                 0              7091  ...                        8104   \n",
       "21415                 0              2026  ...                        7091   \n",
       "21416                 0                 0  ...                        9117   \n",
       "21417             12156             56728  ...                        6078   \n",
       "21418              6078              3039  ...                        6078   \n",
       "21419                 0                 0  ...                        6078   \n",
       "21420                 0                 0  ...                        4052   \n",
       "21421             18234             38494  ...                       37481   \n",
       "21422             10130                 0  ...                      380888   \n",
       "21423             22286                 0  ...                      285666   \n",
       "21424            116495              2026  ...                      101300   \n",
       "21425             44572                 0  ...                      521695   \n",
       "21426              8104                 0  ...                      540942   \n",
       "21427             11143                 0  ...                      464967   \n",
       "21428              2026                 0  ...                      396083   \n",
       "21429                 0                 0  ...                      353537   \n",
       "21430             11143             10130  ...                      250211   \n",
       "21431             36468                 0  ...                      154989   \n",
       "21432             24312                 0  ...                       90157   \n",
       "21433             13169                 0  ...                        3039   \n",
       "21434              6078                 0  ...                           0   \n",
       "21435              5065                 0  ...                           0   \n",
       "21436                 0                 0  ...                        1013   \n",
       "21437                 0                 0  ...                        1013   \n",
       "21438                 0                 0  ...                        1013   \n",
       "21439                 0                 0  ...                        1013   \n",
       "21440                 0                 0  ...                        1013   \n",
       "21441                 0                 0  ...                        1013   \n",
       "21442                 0                 0  ...                        1013   \n",
       "21443                 0                 0  ...                        1013   \n",
       "21444                 0                 0  ...                        1013   \n",
       "21445                 0                 0  ...                        1013   \n",
       "21446                 0                 0  ...                        1013   \n",
       "21447                 0                 0  ...                        1013   \n",
       "21448                 0                 0  ...                        1013   \n",
       "21449                 0                 0  ...                        1013   \n",
       "21450                 0                 0  ...                        1013   \n",
       "21451                 0                 0  ...                       75975   \n",
       "21452              1013                 0  ...                       37481   \n",
       "21453                 0                 0  ...                       33429   \n",
       "21454                 0                 0  ...                       36468   \n",
       "21455                 0                 0  ...                       80027   \n",
       "21456                 0                 0  ...                       44572   \n",
       "21457                 0                 0  ...                       37481   \n",
       "21458                 0                 0  ...                       32416   \n",
       "21459                 0                 0  ...                       26338   \n",
       "\n",
       "       onhand_inventory_channel_5  onhand_inventory_channel_6  \\\n",
       "21401                      375823                           0   \n",
       "21402                      206652                           0   \n",
       "21403                      333277                           0   \n",
       "21404                      298835                           0   \n",
       "21405                      278575                           0   \n",
       "21406                      303900                           0   \n",
       "21407                      315043                           0   \n",
       "21408                      192470                           0   \n",
       "21409                      308965                           0   \n",
       "21410                      346446                           0   \n",
       "21411                      364680                           0   \n",
       "21412                      335303                           0   \n",
       "21413                      330238                           0   \n",
       "21414                      316056                           0   \n",
       "21415                      304913                           0   \n",
       "21416                      281614                           0   \n",
       "21417                      249198                           0   \n",
       "21418                      264393                           0   \n",
       "21419                      281614                           0   \n",
       "21420                      285666                           0   \n",
       "21421                      293770                           0   \n",
       "21422                      257302                           0   \n",
       "21423                      268445                           0   \n",
       "21424                      266419                           0   \n",
       "21425                      257302                           0   \n",
       "21426                      170184                           0   \n",
       "21427                      130677                           0   \n",
       "21428                       78001                           0   \n",
       "21429                      112443                           0   \n",
       "21430                       58754                           0   \n",
       "21431                       64832                           0   \n",
       "21432                       58754                           0   \n",
       "21433                       57741                           0   \n",
       "21434                       53689                           0   \n",
       "21435                       41533                           0   \n",
       "21436                       39507                           0   \n",
       "21437                       33429                           0   \n",
       "21438                       20260                           0   \n",
       "21439                       31403                           0   \n",
       "21440                       31403                           0   \n",
       "21441                       28364                           0   \n",
       "21442                       32416                           0   \n",
       "21443                       29377                           0   \n",
       "21444                       29377                           0   \n",
       "21445                       24312                           0   \n",
       "21446                        1013                           0   \n",
       "21447                       22286                           0   \n",
       "21448                        1013                           0   \n",
       "21449                       22286                           0   \n",
       "21450                       20260                           0   \n",
       "21451                       11143                           0   \n",
       "21452                        9117                           0   \n",
       "21453                        4052                           0   \n",
       "21454                        9117                           0   \n",
       "21455                        2026                           0   \n",
       "21456                        3039                           0   \n",
       "21457                        3039                           0   \n",
       "21458                        2026                           0   \n",
       "21459                        4052                           0   \n",
       "\n",
       "       onhand_inventory_channel_7  onhand_inventory_channel_8  \\\n",
       "21401                      124599                        1013   \n",
       "21402                      123586                           0   \n",
       "21403                      132703                           0   \n",
       "21404                      114469                           0   \n",
       "21405                      119534                           0   \n",
       "21406                      117508                        2026   \n",
       "21407                      131690                        1013   \n",
       "21408                      108391                           0   \n",
       "21409                       96235                           0   \n",
       "21410                       93196                           0   \n",
       "21411                       91170                           0   \n",
       "21412                       75975                           0   \n",
       "21413                       71923                           0   \n",
       "21414                       57741                           0   \n",
       "21415                       54702                           0   \n",
       "21416                       41533                        1013   \n",
       "21417                       46598                        2026   \n",
       "21418                       44572                        1013   \n",
       "21419                       31403                        1013   \n",
       "21420                       24312                        1013   \n",
       "21421                       40520                        1013   \n",
       "21422                       30390                        3039   \n",
       "21423                       21273                        3039   \n",
       "21424                       22286                        1013   \n",
       "21425                       16208                        1013   \n",
       "21426                       17221                        1013   \n",
       "21427                       14182                        1013   \n",
       "21428                       13169                        1013   \n",
       "21429                       11143                        1013   \n",
       "21430                        9117                        1013   \n",
       "21431                        7091                           0   \n",
       "21432                        3039                           0   \n",
       "21433                        3039                           0   \n",
       "21434                        3039                           0   \n",
       "21435                        1013                           0   \n",
       "21436                           0                           0   \n",
       "21437                           0                           0   \n",
       "21438                           0                           0   \n",
       "21439                        2026                           0   \n",
       "21440                        1013                           0   \n",
       "21441                        1013                           0   \n",
       "21442                        1013                           0   \n",
       "21443                           0                           0   \n",
       "21444                           0                           0   \n",
       "21445                           0                           0   \n",
       "21446                           0                           0   \n",
       "21447                           0                           0   \n",
       "21448                           0                           0   \n",
       "21449                           0                           0   \n",
       "21450                           0                           0   \n",
       "21451                           0                           0   \n",
       "21452                           0                           0   \n",
       "21453                           0                           0   \n",
       "21454                           0                           0   \n",
       "21455                           0                           0   \n",
       "21456                           0                           0   \n",
       "21457                           0                           0   \n",
       "21458                           0                           0   \n",
       "21459                           0                           0   \n",
       "\n",
       "       onhand_inventory_channel_9  onhand_inventory_channel_10  price  month  \\\n",
       "21401                      398109                       151950    155      1   \n",
       "21402                      397096                       150937    155      2   \n",
       "21403                      434577                       143846    155      3   \n",
       "21404                      210704                       143846    155      4   \n",
       "21405                      148911                       135742    155      5   \n",
       "21406                      166132                       130677    155      6   \n",
       "21407                       99274                       144859    155      7   \n",
       "21408                       94209                       157015    155      8   \n",
       "21409                      100287                       177275    155      9   \n",
       "21410                       89144                       170184    155     10   \n",
       "21411                       40520                       385953    155     11   \n",
       "21412                       50650                       312004    155     12   \n",
       "21413                       33429                       303900    155      1   \n",
       "21414                       69897                       279588    155      2   \n",
       "21415                       63819                       232990    155      3   \n",
       "21416                       29377                       226912    155      4   \n",
       "21417                       20260                       220834    155      5   \n",
       "21418                       52676                       200574    155      6   \n",
       "21419                       32416                       181327    155      7   \n",
       "21420                       25325                       162080    155      8   \n",
       "21421                       32416                       177275    155      9   \n",
       "21422                       23299                       176262    155     10   \n",
       "21423                        8104                       201587    155     11   \n",
       "21424                       17221                       167145    155     12   \n",
       "21425                       22286                       123586    155      1   \n",
       "21426                       15195                        96235    155      2   \n",
       "21427                       13169                        85092    155      3   \n",
       "21428                       17221                        72936    155      4   \n",
       "21429                       13169                        47611    155      5   \n",
       "21430                        4052                        27351    155      6   \n",
       "21431                        1013                        11143    155      7   \n",
       "21432                           0                         9117    155      8   \n",
       "21433                           0                         7091    155      9   \n",
       "21434                           0                         5065    155     10   \n",
       "21435                           0                         8104    155     11   \n",
       "21436                           0                         9117    155     12   \n",
       "21437                        1013                         4052    155      1   \n",
       "21438                           0                         3039    155      2   \n",
       "21439                           0                         1013    155      3   \n",
       "21440                           0                         1013    155      4   \n",
       "21441                           0                         1013    155      5   \n",
       "21442                           0                            0    155      6   \n",
       "21443                           0                            0    155      7   \n",
       "21444                           0                            0    155      8   \n",
       "21445                           0                            0    155      9   \n",
       "21446                           0                            0    155     10   \n",
       "21447                           0                            0    155     10   \n",
       "21448                           0                            0    159     10   \n",
       "21449                           0                            0    159     10   \n",
       "21450                           0                            0    159     11   \n",
       "21451                           0                            0    159      1   \n",
       "21452                           0                            0    159      2   \n",
       "21453                           0                            0    159      3   \n",
       "21454                           0                            0    159      4   \n",
       "21455                           0                            0    159      5   \n",
       "21456                           0                            0    159      6   \n",
       "21457                           0                            0    159      7   \n",
       "21458                           0                            0    159      9   \n",
       "21459                           0                            0    159     10   \n",
       "\n",
       "       year  \n",
       "21401  2016  \n",
       "21402  2016  \n",
       "21403  2016  \n",
       "21404  2016  \n",
       "21405  2016  \n",
       "21406  2016  \n",
       "21407  2016  \n",
       "21408  2016  \n",
       "21409  2016  \n",
       "21410  2016  \n",
       "21411  2016  \n",
       "21412  2016  \n",
       "21413  2017  \n",
       "21414  2017  \n",
       "21415  2017  \n",
       "21416  2017  \n",
       "21417  2017  \n",
       "21418  2017  \n",
       "21419  2017  \n",
       "21420  2017  \n",
       "21421  2017  \n",
       "21422  2017  \n",
       "21423  2017  \n",
       "21424  2017  \n",
       "21425  2018  \n",
       "21426  2018  \n",
       "21427  2018  \n",
       "21428  2018  \n",
       "21429  2018  \n",
       "21430  2018  \n",
       "21431  2018  \n",
       "21432  2018  \n",
       "21433  2018  \n",
       "21434  2018  \n",
       "21435  2018  \n",
       "21436  2018  \n",
       "21437  2019  \n",
       "21438  2019  \n",
       "21439  2019  \n",
       "21440  2019  \n",
       "21441  2019  \n",
       "21442  2019  \n",
       "21443  2019  \n",
       "21444  2019  \n",
       "21445  2019  \n",
       "21446  2019  \n",
       "21447  2019  \n",
       "21448  2019  \n",
       "21449  2019  \n",
       "21450  2019  \n",
       "21451  2021  \n",
       "21452  2021  \n",
       "21453  2021  \n",
       "21454  2021  \n",
       "21455  2021  \n",
       "21456  2021  \n",
       "21457  2021  \n",
       "21458  2021  \n",
       "21459  2021  \n",
       "\n",
       "[59 rows x 37 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['sku_name']==sample[15]].sort_values(['year','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a12b9926-3733-4144-ac29-dc6be987ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'sellin'\n",
    "factors = [c for c in train_df.columns if 'channel' not in c and c not in ['sku_name','month','year','sellin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e23c2920-2488-41b9-af31-3bc7ec0ae269",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellout</th>\n",
       "      <th>onhand_inventory</th>\n",
       "      <th>leftover_inventory</th>\n",
       "      <th>price</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21401</th>\n",
       "      <td>0</td>\n",
       "      <td>534864</td>\n",
       "      <td>3319601</td>\n",
       "      <td>329225</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21402</th>\n",
       "      <td>0</td>\n",
       "      <td>501435</td>\n",
       "      <td>3145365</td>\n",
       "      <td>29377</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21403</th>\n",
       "      <td>0</td>\n",
       "      <td>462941</td>\n",
       "      <td>3167651</td>\n",
       "      <td>476110</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21404</th>\n",
       "      <td>0</td>\n",
       "      <td>416343</td>\n",
       "      <td>2822218</td>\n",
       "      <td>189431</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21405</th>\n",
       "      <td>0</td>\n",
       "      <td>459902</td>\n",
       "      <td>2740165</td>\n",
       "      <td>28364</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21406</th>\n",
       "      <td>0</td>\n",
       "      <td>492318</td>\n",
       "      <td>2646969</td>\n",
       "      <td>397096</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21407</th>\n",
       "      <td>0</td>\n",
       "      <td>400135</td>\n",
       "      <td>2562890</td>\n",
       "      <td>258315</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21408</th>\n",
       "      <td>0</td>\n",
       "      <td>396083</td>\n",
       "      <td>2532500</td>\n",
       "      <td>149924</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21409</th>\n",
       "      <td>0</td>\n",
       "      <td>530812</td>\n",
       "      <td>2460577</td>\n",
       "      <td>477123</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21410</th>\n",
       "      <td>0</td>\n",
       "      <td>378862</td>\n",
       "      <td>2546682</td>\n",
       "      <td>532838</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21411</th>\n",
       "      <td>0</td>\n",
       "      <td>489279</td>\n",
       "      <td>3261860</td>\n",
       "      <td>1035286</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>0</td>\n",
       "      <td>1445551</td>\n",
       "      <td>2861725</td>\n",
       "      <td>560189</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>0</td>\n",
       "      <td>310991</td>\n",
       "      <td>2754347</td>\n",
       "      <td>113456</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>0</td>\n",
       "      <td>354550</td>\n",
       "      <td>2717879</td>\n",
       "      <td>-191457</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>0</td>\n",
       "      <td>297822</td>\n",
       "      <td>2568968</td>\n",
       "      <td>-237042</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>0</td>\n",
       "      <td>216782</td>\n",
       "      <td>2115144</td>\n",
       "      <td>-166132</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21417</th>\n",
       "      <td>0</td>\n",
       "      <td>243120</td>\n",
       "      <td>2071585</td>\n",
       "      <td>1061624</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21418</th>\n",
       "      <td>0</td>\n",
       "      <td>285666</td>\n",
       "      <td>2152625</td>\n",
       "      <td>-69897</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21419</th>\n",
       "      <td>0</td>\n",
       "      <td>254263</td>\n",
       "      <td>1930778</td>\n",
       "      <td>-206652</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21420</th>\n",
       "      <td>0</td>\n",
       "      <td>282627</td>\n",
       "      <td>1711970</td>\n",
       "      <td>-36468</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21421</th>\n",
       "      <td>0</td>\n",
       "      <td>298835</td>\n",
       "      <td>2021948</td>\n",
       "      <td>1254094</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21422</th>\n",
       "      <td>0</td>\n",
       "      <td>296809</td>\n",
       "      <td>2393719</td>\n",
       "      <td>640216</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21423</th>\n",
       "      <td>0</td>\n",
       "      <td>568293</td>\n",
       "      <td>2437278</td>\n",
       "      <td>243120</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21424</th>\n",
       "      <td>0</td>\n",
       "      <td>1351342</td>\n",
       "      <td>2067533</td>\n",
       "      <td>-361641</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21425</th>\n",
       "      <td>0</td>\n",
       "      <td>537903</td>\n",
       "      <td>2077663</td>\n",
       "      <td>-125612</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21426</th>\n",
       "      <td>0</td>\n",
       "      <td>330238</td>\n",
       "      <td>1601553</td>\n",
       "      <td>-192470</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21427</th>\n",
       "      <td>0</td>\n",
       "      <td>295796</td>\n",
       "      <td>1376667</td>\n",
       "      <td>-247172</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21428</th>\n",
       "      <td>0</td>\n",
       "      <td>205639</td>\n",
       "      <td>1183184</td>\n",
       "      <td>-172210</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21429</th>\n",
       "      <td>0</td>\n",
       "      <td>151950</td>\n",
       "      <td>1108222</td>\n",
       "      <td>-132703</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21430</th>\n",
       "      <td>0</td>\n",
       "      <td>246159</td>\n",
       "      <td>816478</td>\n",
       "      <td>-164106</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21431</th>\n",
       "      <td>0</td>\n",
       "      <td>232990</td>\n",
       "      <td>601722</td>\n",
       "      <td>-112443</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21432</th>\n",
       "      <td>0</td>\n",
       "      <td>169171</td>\n",
       "      <td>445720</td>\n",
       "      <td>-109404</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21433</th>\n",
       "      <td>0</td>\n",
       "      <td>61793</td>\n",
       "      <td>285666</td>\n",
       "      <td>-37481</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21434</th>\n",
       "      <td>0</td>\n",
       "      <td>24312</td>\n",
       "      <td>285666</td>\n",
       "      <td>27351</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21435</th>\n",
       "      <td>0</td>\n",
       "      <td>60780</td>\n",
       "      <td>344420</td>\n",
       "      <td>162080</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21436</th>\n",
       "      <td>0</td>\n",
       "      <td>388992</td>\n",
       "      <td>156002</td>\n",
       "      <td>-218808</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21437</th>\n",
       "      <td>0</td>\n",
       "      <td>75975</td>\n",
       "      <td>236029</td>\n",
       "      <td>25325</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21438</th>\n",
       "      <td>0</td>\n",
       "      <td>49637</td>\n",
       "      <td>222860</td>\n",
       "      <td>-4052</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21439</th>\n",
       "      <td>0</td>\n",
       "      <td>39507</td>\n",
       "      <td>209691</td>\n",
       "      <td>-31403</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21440</th>\n",
       "      <td>0</td>\n",
       "      <td>30390</td>\n",
       "      <td>174236</td>\n",
       "      <td>-4052</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21441</th>\n",
       "      <td>0</td>\n",
       "      <td>44572</td>\n",
       "      <td>148911</td>\n",
       "      <td>-16208</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>0</td>\n",
       "      <td>38494</td>\n",
       "      <td>429512</td>\n",
       "      <td>103326</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21443</th>\n",
       "      <td>0</td>\n",
       "      <td>68884</td>\n",
       "      <td>192470</td>\n",
       "      <td>-62806</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21444</th>\n",
       "      <td>0</td>\n",
       "      <td>35455</td>\n",
       "      <td>165119</td>\n",
       "      <td>-16208</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21445</th>\n",
       "      <td>0</td>\n",
       "      <td>67871</td>\n",
       "      <td>98261</td>\n",
       "      <td>-24312</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21446</th>\n",
       "      <td>0</td>\n",
       "      <td>51663</td>\n",
       "      <td>82053</td>\n",
       "      <td>282627</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21447</th>\n",
       "      <td>0</td>\n",
       "      <td>108391</td>\n",
       "      <td>533851</td>\n",
       "      <td>225899</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21448</th>\n",
       "      <td>0</td>\n",
       "      <td>51663</td>\n",
       "      <td>82053</td>\n",
       "      <td>508526</td>\n",
       "      <td>159</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21449</th>\n",
       "      <td>0</td>\n",
       "      <td>108391</td>\n",
       "      <td>533851</td>\n",
       "      <td>451798</td>\n",
       "      <td>159</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21450</th>\n",
       "      <td>419382</td>\n",
       "      <td>123586</td>\n",
       "      <td>439642</td>\n",
       "      <td>-108391</td>\n",
       "      <td>159</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21451</th>\n",
       "      <td>842816</td>\n",
       "      <td>17221</td>\n",
       "      <td>99274</td>\n",
       "      <td>65845</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21452</th>\n",
       "      <td>665541</td>\n",
       "      <td>68884</td>\n",
       "      <td>149924</td>\n",
       "      <td>113456</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21453</th>\n",
       "      <td>529799</td>\n",
       "      <td>29377</td>\n",
       "      <td>321121</td>\n",
       "      <td>111430</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21454</th>\n",
       "      <td>481175</td>\n",
       "      <td>30390</td>\n",
       "      <td>352524</td>\n",
       "      <td>19247</td>\n",
       "      <td>159</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>420395</td>\n",
       "      <td>40520</td>\n",
       "      <td>342394</td>\n",
       "      <td>20260</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21456</th>\n",
       "      <td>419382</td>\n",
       "      <td>201587</td>\n",
       "      <td>63819</td>\n",
       "      <td>-199561</td>\n",
       "      <td>159</td>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21457</th>\n",
       "      <td>417356</td>\n",
       "      <td>21273</td>\n",
       "      <td>61793</td>\n",
       "      <td>-19247</td>\n",
       "      <td>159</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>1292588</td>\n",
       "      <td>7091</td>\n",
       "      <td>43559</td>\n",
       "      <td>144859</td>\n",
       "      <td>159</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>1372615</td>\n",
       "      <td>11143</td>\n",
       "      <td>1131521</td>\n",
       "      <td>1024143</td>\n",
       "      <td>159</td>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_inventory  sellout  onhand_inventory  leftover_inventory  \\\n",
       "21401                   0   534864           3319601              329225   \n",
       "21402                   0   501435           3145365               29377   \n",
       "21403                   0   462941           3167651              476110   \n",
       "21404                   0   416343           2822218              189431   \n",
       "21405                   0   459902           2740165               28364   \n",
       "21406                   0   492318           2646969              397096   \n",
       "21407                   0   400135           2562890              258315   \n",
       "21408                   0   396083           2532500              149924   \n",
       "21409                   0   530812           2460577              477123   \n",
       "21410                   0   378862           2546682              532838   \n",
       "21411                   0   489279           3261860             1035286   \n",
       "21412                   0  1445551           2861725              560189   \n",
       "21413                   0   310991           2754347              113456   \n",
       "21414                   0   354550           2717879             -191457   \n",
       "21415                   0   297822           2568968             -237042   \n",
       "21416                   0   216782           2115144             -166132   \n",
       "21417                   0   243120           2071585             1061624   \n",
       "21418                   0   285666           2152625              -69897   \n",
       "21419                   0   254263           1930778             -206652   \n",
       "21420                   0   282627           1711970              -36468   \n",
       "21421                   0   298835           2021948             1254094   \n",
       "21422                   0   296809           2393719              640216   \n",
       "21423                   0   568293           2437278              243120   \n",
       "21424                   0  1351342           2067533             -361641   \n",
       "21425                   0   537903           2077663             -125612   \n",
       "21426                   0   330238           1601553             -192470   \n",
       "21427                   0   295796           1376667             -247172   \n",
       "21428                   0   205639           1183184             -172210   \n",
       "21429                   0   151950           1108222             -132703   \n",
       "21430                   0   246159            816478             -164106   \n",
       "21431                   0   232990            601722             -112443   \n",
       "21432                   0   169171            445720             -109404   \n",
       "21433                   0    61793            285666              -37481   \n",
       "21434                   0    24312            285666               27351   \n",
       "21435                   0    60780            344420              162080   \n",
       "21436                   0   388992            156002             -218808   \n",
       "21437                   0    75975            236029               25325   \n",
       "21438                   0    49637            222860               -4052   \n",
       "21439                   0    39507            209691              -31403   \n",
       "21440                   0    30390            174236               -4052   \n",
       "21441                   0    44572            148911              -16208   \n",
       "21442                   0    38494            429512              103326   \n",
       "21443                   0    68884            192470              -62806   \n",
       "21444                   0    35455            165119              -16208   \n",
       "21445                   0    67871             98261              -24312   \n",
       "21446                   0    51663             82053              282627   \n",
       "21447                   0   108391            533851              225899   \n",
       "21448                   0    51663             82053              508526   \n",
       "21449                   0   108391            533851              451798   \n",
       "21450              419382   123586            439642             -108391   \n",
       "21451              842816    17221             99274               65845   \n",
       "21452              665541    68884            149924              113456   \n",
       "21453              529799    29377            321121              111430   \n",
       "21454              481175    30390            352524               19247   \n",
       "21455              420395    40520            342394               20260   \n",
       "21456              419382   201587             63819             -199561   \n",
       "21457              417356    21273             61793              -19247   \n",
       "21458             1292588     7091             43559              144859   \n",
       "21459             1372615    11143           1131521             1024143   \n",
       "\n",
       "       price  month  year  \n",
       "21401    155      1  2016  \n",
       "21402    155      2  2016  \n",
       "21403    155      3  2016  \n",
       "21404    155      4  2016  \n",
       "21405    155      5  2016  \n",
       "21406    155      6  2016  \n",
       "21407    155      7  2016  \n",
       "21408    155      8  2016  \n",
       "21409    155      9  2016  \n",
       "21410    155     10  2016  \n",
       "21411    155     11  2016  \n",
       "21412    155     12  2016  \n",
       "21413    155      1  2017  \n",
       "21414    155      2  2017  \n",
       "21415    155      3  2017  \n",
       "21416    155      4  2017  \n",
       "21417    155      5  2017  \n",
       "21418    155      6  2017  \n",
       "21419    155      7  2017  \n",
       "21420    155      8  2017  \n",
       "21421    155      9  2017  \n",
       "21422    155     10  2017  \n",
       "21423    155     11  2017  \n",
       "21424    155     12  2017  \n",
       "21425    155      1  2018  \n",
       "21426    155      2  2018  \n",
       "21427    155      3  2018  \n",
       "21428    155      4  2018  \n",
       "21429    155      5  2018  \n",
       "21430    155      6  2018  \n",
       "21431    155      7  2018  \n",
       "21432    155      8  2018  \n",
       "21433    155      9  2018  \n",
       "21434    155     10  2018  \n",
       "21435    155     11  2018  \n",
       "21436    155     12  2018  \n",
       "21437    155      1  2019  \n",
       "21438    155      2  2019  \n",
       "21439    155      3  2019  \n",
       "21440    155      4  2019  \n",
       "21441    155      5  2019  \n",
       "21442    155      6  2019  \n",
       "21443    155      7  2019  \n",
       "21444    155      8  2019  \n",
       "21445    155      9  2019  \n",
       "21446    155     10  2019  \n",
       "21447    155     10  2019  \n",
       "21448    159     10  2019  \n",
       "21449    159     10  2019  \n",
       "21450    159     11  2019  \n",
       "21451    159      1  2021  \n",
       "21452    159      2  2021  \n",
       "21453    159      3  2021  \n",
       "21454    159      4  2021  \n",
       "21455    159      5  2021  \n",
       "21456    159      6  2021  \n",
       "21457    159      7  2021  \n",
       "21458    159      9  2021  \n",
       "21459    159     10  2021  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['sku_name']==sample[15]].sort_values(['year','month'])[factors+['month','year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c6979df-640d-4b44-aec4-ce469c595329",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[train_df['sku_name']==sample[15]].sort_values(['year','month'])[factors+['month','year','sellin']]['sellin'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d92b9b8a-44fe-4df9-ae05-7d923788b441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:xlabel='date'>, <AxesSubplot:xlabel='date'>,\n",
       "       <AxesSubplot:xlabel='date'>, <AxesSubplot:xlabel='date'>,\n",
       "       <AxesSubplot:xlabel='date'>, <AxesSubplot:xlabel='date'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_train[exp_train['sku_name']==sample[89]].sort_values(['year','month'])[factors+['sellin']].plot(subplots=True, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b628bc1",
   "metadata": {},
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590bb26",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8dd4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CAT = desc[36:]['Column Name'].tolist()\n",
    "train_df = train.drop(columns=CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88816319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil.preprocessing import FossilPreprocessor, LabelEncoder\n",
    "from fossil.config import ModelsConfig\n",
    "\n",
    "np.random.seed(ModelsConfig.SEED)\n",
    "sku_encoder = LabelEncoder(train.sku_name.sample(frac=0.95, random_state=ModelsConfig.SEED).unique())\n",
    "\n",
    "#save dictionary of items for use during inference\n",
    "sku_encoder.save_items(f'{OUTPUT_DIR}/sku_dict.pkl')\n",
    "\n",
    "fossil_preproc = FossilPreprocessor(sku_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10b5851",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates = fossil_preproc.sort_dates(train_df)\n",
    "train_df = fossil_preproc.extract_relative_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088ba6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f623e0b8a0c54043a8b650930a531dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3327df8dce0948e4b880c21c0f283908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d7a7bc909248e78ac104515260fbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436b3d9f80684a9f82566152bc386895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd19c1a65cd49cfae6a747cffdeb35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546479457de44b6595b95e81c323b88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5d808f0aad4ec09a6d7dc8ed2987bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c193af7010d44d109dbe74f55b1a044f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "primary_data = fossil_preproc.prepare_primary_data(train_df, dates, False, OUTPUT_DIR)\n",
    "base_data = fossil_preproc.impute_missing(primary_data, False, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02497776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#store features from latest date for use as context during inference\n",
    "context = primary_data[['month','year']].apply(tuple, axis=1).isin(dates[-ModelsConfig.LOOKBACK:])\n",
    "primary_data[context].to_csv(f'{OUTPUT_DIR}/context.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca46940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fossil_preproc.pca_feature_selection(base_data, eda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07804c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_features = fossil_preproc.pca_feature_selection(base_data, 50)\n",
    "\n",
    "#save features for inference\n",
    "fossil_preproc.save_items(f'{OUTPUT_DIR}/principal_features.pkl', principal_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e6eff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be057c21",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's l1: 108778\tvalid_1's l1: 153917\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 88193.6\tvalid_1's l1: 118949\n",
      "Early stopping, best iteration is:\n",
      "[663]\ttraining's l1: 80184.4\tvalid_1's l1: 117452\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 86116.1\tvalid_1's l1: 129129\n",
      "Early stopping, best iteration is:\n",
      "[590]\ttraining's l1: 81433\tvalid_1's l1: 128136\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[415]\ttraining's l1: 89253.5\tvalid_1's l1: 152350\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 85220.1\tvalid_1's l1: 134436\n",
      "Early stopping, best iteration is:\n",
      "[582]\ttraining's l1: 81151.1\tvalid_1's l1: 133769\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 91432.2\tvalid_1's l1: 125830\n",
      "Early stopping, best iteration is:\n",
      "[501]\ttraining's l1: 91365.6\tvalid_1's l1: 125817\n",
      "Elapsed 0.22 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[410]\ttraining's l1: 88070.9\tvalid_1's l1: 147806\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 85173.6\tvalid_1's l1: 117585\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's l1: 81267.1\tvalid_1's l1: 117092\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 82101.1\tvalid_1's l1: 130283\n",
      "Early stopping, best iteration is:\n",
      "[612]\ttraining's l1: 76809.3\tvalid_1's l1: 129588\n",
      "Elapsed 0.35 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 82750.9\tvalid_1's l1: 130416\n",
      "Early stopping, best iteration is:\n",
      "[556]\ttraining's l1: 79661.9\tvalid_1's l1: 129900\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 78561.8\tvalid_1's l1: 125282\n",
      "Early stopping, best iteration is:\n",
      "[707]\ttraining's l1: 69900.1\tvalid_1's l1: 123879\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 77676\tvalid_1's l1: 125544\n",
      "Early stopping, best iteration is:\n",
      "[637]\ttraining's l1: 71400.4\tvalid_1's l1: 124515\n",
      "Elapsed 0.50 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 133327.43375634175\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 137423.6515245171\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 131621.4255554171\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 126127.07988322784\n",
      "\n",
      "\n",
      "Average Val MAE: 132124.89767987368\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:207436.70876\tvalidation_1-mae:225621.76881\n",
      "[117]\tvalidation_0-mae:115989.72504\tvalidation_1-mae:135788.58510\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:211659.09755\tvalidation_1-mae:217264.99048\n",
      "[101]\tvalidation_0-mae:121303.89941\tvalidation_1-mae:122053.75170\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:221395.62413\tvalidation_1-mae:197471.75260\n",
      "[88]\tvalidation_0-mae:124844.95769\tvalidation_1-mae:117067.92223\n",
      "Elapsed 0.23 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 135734.9587139662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 121833.62489310734\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 116865.10533744318\n",
      "\n",
      "\n",
      "Average Val MAE: 124892.5181730519\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 204237.7583625\ttest: 204237.7583625\ttest1: 222888.0780851\tbest: 222888.0780851 (0)\ttotal: 154ms\tremaining: 25m 41s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129479.5046\n",
      "bestIteration = 384\n",
      "\n",
      "Shrink model to first 385 iterations.\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 208648.0555209\ttest: 208648.0555209\ttest1: 213429.4316487\tbest: 213429.4316487 (0)\ttotal: 11.8ms\tremaining: 1m 58s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117641.699\n",
      "bestIteration = 340\n",
      "\n",
      "Shrink model to first 341 iterations.\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 217960.4751623\ttest: 217960.4751623\ttest1: 194672.1233600\tbest: 194672.1233600 (0)\ttotal: 12.8ms\tremaining: 2m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 111963.7248\n",
      "bestIteration = 272\n",
      "\n",
      "Shrink model to first 273 iterations.\n",
      "Elapsed 0.21 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 129479.50464775\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 117641.6990042723\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 111963.72478919323\n",
      "\n",
      "\n",
      "Average Val MAE: 119767.48921147245\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:226722.86759\tvalidation_1-mae:242414.33359\n",
      "[115]\tvalidation_0-mae:104186.45949\tvalidation_1-mae:134813.91163\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:233102.56838\tvalidation_1-mae:229895.56934\n",
      "[143]\tvalidation_0-mae:106595.67835\tvalidation_1-mae:121929.41130\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:236219.94678\tvalidation_1-mae:223693.21574\n",
      "[130]\tvalidation_0-mae:105205.15040\tvalidation_1-mae:130906.87130\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:212349.15299\tvalidation_1-mae:231927.56350\n",
      "[116]\tvalidation_0-mae:103470.70467\tvalidation_1-mae:142894.46535\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:204857.27246\tvalidation_1-mae:247621.49507\n",
      "[176]\tvalidation_0-mae:102677.70883\tvalidation_1-mae:138282.28488\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:239011.13853\tvalidation_1-mae:176871.25405\n",
      "[63]\tvalidation_0-mae:127166.91046\tvalidation_1-mae:109420.85330\n",
      "Elapsed 0.22 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:207141.34849\tvalidation_1-mae:203042.18216\n",
      "[99]\tvalidation_0-mae:103629.79290\tvalidation_1-mae:126800.15293\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:212280.82757\tvalidation_1-mae:191201.39192\n",
      "[75]\tvalidation_0-mae:113049.44352\tvalidation_1-mae:115948.91062\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:197499.28079\tvalidation_1-mae:222866.16638\n",
      "[171]\tvalidation_0-mae:97267.72551\tvalidation_1-mae:132504.86448\n",
      "Elapsed 0.34 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:210992.35660\tvalidation_1-mae:171533.67072\n",
      "[78]\tvalidation_0-mae:110373.47224\tvalidation_1-mae:110112.17821\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:189761.79391\tvalidation_1-mae:214111.76247\n",
      "[137]\tvalidation_0-mae:95193.54683\tvalidation_1-mae:128037.49588\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:192598.98986\tvalidation_1-mae:208334.92391\n",
      "[121]\tvalidation_0-mae:96390.07625\tvalidation_1-mae:120641.72156\n",
      "Elapsed 0.47 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 129077.45229295448\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 129424.05056602039\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 124236.86073255153\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 119287.44099464316\n",
      "\n",
      "\n",
      "Average Val MAE: 125506.45114654239\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 124473\tvalid_1's l1: 144464\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's l1: 122878\tvalid_1's l1: 143135\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 129070\tvalid_1's l1: 137933\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 133662\tvalid_1's l1: 128279\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 143135.2571589804\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 137933.39519580285\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 128279.29297748688\n",
      "\n",
      "\n",
      "Average Val MAE: 136497.46221733955\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 204226.2591926\ttest: 204226.2591926\ttest1: 222620.6433903\tbest: 222620.6433903 (0)\ttotal: 11.8ms\tremaining: 1m 57s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130188.0728\n",
      "bestIteration = 305\n",
      "\n",
      "Shrink model to first 306 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 208753.8668896\ttest: 208753.8668896\ttest1: 213663.5461358\tbest: 213663.5461358 (0)\ttotal: 11.9ms\tremaining: 1m 58s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119662.0423\n",
      "bestIteration = 421\n",
      "\n",
      "Shrink model to first 422 iterations.\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 218081.2043321\ttest: 218081.2043321\ttest1: 194787.1260703\tbest: 194787.1260703 (0)\ttotal: 11.2ms\tremaining: 1m 51s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 111640.4999\n",
      "bestIteration = 254\n",
      "\n",
      "Shrink model to first 255 iterations.\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 130188.07280342262\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 119662.04234720021\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 111640.499859355\n",
      "\n",
      "\n",
      "Average Val MAE: 120568.11076362079\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 222103.7619990\ttest: 222103.7619990\ttest1: 237162.3004707\tbest: 237162.3004707 (0)\ttotal: 6.62ms\tremaining: 1m 6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129036.914\n",
      "bestIteration = 235\n",
      "\n",
      "Shrink model to first 236 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 228202.2135119\ttest: 228202.2135119\ttest1: 225369.9556292\tbest: 225369.9556292 (0)\ttotal: 7.77ms\tremaining: 1m 17s\n",
      "500:\tlearn: 108923.0588116\ttest: 108923.0588116\ttest1: 113561.9348974\tbest: 113561.9348974 (500)\ttotal: 3.26s\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 110198.7341\n",
      "bestIteration = 933\n",
      "\n",
      "Shrink model to first 934 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 231268.6198495\ttest: 231268.6198495\ttest1: 218997.0452563\tbest: 218997.0452563 (0)\ttotal: 8.57ms\tremaining: 1m 25s\n",
      "500:\tlearn: 105420.1101967\ttest: 105420.1101967\ttest1: 121458.2991171\tbest: 121458.2991171 (500)\ttotal: 2.96s\tremaining: 56.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120816.3025\n",
      "bestIteration = 611\n",
      "\n",
      "Shrink model to first 612 iterations.\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 208403.5409685\ttest: 208403.5409685\ttest1: 227987.4391788\tbest: 227987.4391788 (0)\ttotal: 6.36ms\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 132274.2039\n",
      "bestIteration = 232\n",
      "\n",
      "Shrink model to first 233 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 201460.8223513\ttest: 201460.8223513\ttest1: 243408.1380132\tbest: 243408.1380132 (0)\ttotal: 7.61ms\tremaining: 1m 16s\n",
      "500:\tlearn: 105597.6907567\ttest: 105597.6907567\ttest1: 133111.5858067\tbest: 133111.3157231 (499)\ttotal: 3.14s\tremaining: 59.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 131771.4274\n",
      "bestIteration = 708\n",
      "\n",
      "Shrink model to first 709 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 235205.2984068\ttest: 235205.2984068\ttest1: 173910.7076456\tbest: 173910.7076456 (0)\ttotal: 7.28ms\tremaining: 1m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 107512.1381\n",
      "bestIteration = 153\n",
      "\n",
      "Shrink model to first 154 iterations.\n",
      "Elapsed 0.32 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 204425.3537980\ttest: 204425.3537980\ttest1: 199783.0851771\tbest: 199783.0851771 (0)\ttotal: 7.09ms\tremaining: 1m 10s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117640.8172\n",
      "bestIteration = 307\n",
      "\n",
      "Shrink model to first 308 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 209325.9108802\ttest: 209325.9108802\ttest1: 189476.0605407\tbest: 189476.0605407 (0)\ttotal: 7.79ms\tremaining: 1m 17s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 107387.4151\n",
      "bestIteration = 381\n",
      "\n",
      "Shrink model to first 382 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 194528.5834015\ttest: 194528.5834015\ttest1: 218847.9545595\tbest: 218847.9545595 (0)\ttotal: 7.48ms\tremaining: 1m 14s\n",
      "500:\tlearn: 101733.7421523\ttest: 101733.7421523\ttest1: 126745.9356862\tbest: 126745.9356862 (500)\ttotal: 3.31s\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124500.7054\n",
      "bestIteration = 832\n",
      "\n",
      "Shrink model to first 833 iterations.\n",
      "Elapsed 0.50 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 208872.5394298\ttest: 208872.5394298\ttest1: 168491.3029448\tbest: 168491.3029448 (0)\ttotal: 6.26ms\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 101001.662\n",
      "bestIteration = 268\n",
      "\n",
      "Shrink model to first 269 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 187148.8624542\ttest: 187148.8624542\ttest1: 212807.6846344\tbest: 212807.6846344 (0)\ttotal: 7.79ms\tremaining: 1m 17s\n",
      "500:\tlearn: 98061.3180518\ttest: 98061.3180518\ttest1: 118523.9918609\tbest: 118521.2717692 (498)\ttotal: 3.23s\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116448.7322\n",
      "bestIteration = 961\n",
      "\n",
      "Shrink model to first 962 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 190298.3985874\ttest: 190298.3985874\ttest1: 205807.6507768\tbest: 205807.6507768 (0)\ttotal: 7.16ms\tremaining: 1m 11s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115173.7946\n",
      "bestIteration = 407\n",
      "\n",
      "Shrink model to first 408 iterations.\n",
      "Elapsed 0.68 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 120088.01083702063\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 123910.29751040271\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 116522.34464167005\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 110799.85927457496\n",
      "\n",
      "\n",
      "Average Val MAE: 117830.12806591656\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 124121\tvalid_1's l1: 143013\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 128847\tvalid_1's l1: 137558\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 133735\tvalid_1's l1: 127617\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 143013.10244641814\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 137557.84453293047\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 127616.72872828945\n",
      "\n",
      "\n",
      "Average Val MAE: 136112.63422401156\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:207417.49377\tvalidation_1-mae:225530.34636\n",
      "[100]\tvalidation_0-mae:115788.19243\tvalidation_1-mae:130673.45239\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:211625.98442\tvalidation_1-mae:217286.64635\n",
      "[93]\tvalidation_0-mae:119600.45436\tvalidation_1-mae:122639.07465\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:221369.67319\tvalidation_1-mae:197384.57427\n",
      "[83]\tvalidation_0-mae:123881.00882\tvalidation_1-mae:114416.12335\n",
      "Elapsed 0.24 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 130544.3735071858\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 122465.63721160077\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 114161.4442897976\n",
      "\n",
      "\n",
      "Average Val MAE: 122450.04577843114\n",
      "Blended MAE: 120189.45808653416\n"
     ]
    }
   ],
   "source": [
    "from fossil.models.gbdt import FossilGBDT\n",
    "gbdt_models = FossilGBDT()\n",
    "\n",
    "oof_preds, cv_models, blended_mae = gbdt_models.blend_cv_models(principal_features, base_data, fossil_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d937baa1-c07d-4432-9a64-b7831aaee511",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[380]\ttraining's l1: 92357.4\tvalid_1's l1: 147278\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 88103.2\tvalid_1's l1: 119682\n",
      "Early stopping, best iteration is:\n",
      "[717]\ttraining's l1: 78049.8\tvalid_1's l1: 118029\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 86603.1\tvalid_1's l1: 127915\n",
      "Early stopping, best iteration is:\n",
      "[752]\ttraining's l1: 75779.7\tvalid_1's l1: 125971\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's l1: 89652.5\tvalid_1's l1: 146899\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 85407.6\tvalid_1's l1: 136556\n",
      "Early stopping, best iteration is:\n",
      "[598]\ttraining's l1: 80574.4\tvalid_1's l1: 135549\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 91568.4\tvalid_1's l1: 123515\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's l1: 90738.3\tvalid_1's l1: 123420\n",
      "Elapsed 0.25 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[459]\ttraining's l1: 85196.4\tvalid_1's l1: 137383\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 85460.4\tvalid_1's l1: 117764\n",
      "Early stopping, best iteration is:\n",
      "[617]\ttraining's l1: 79489.7\tvalid_1's l1: 116949\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 82150.3\tvalid_1's l1: 130227\n",
      "Early stopping, best iteration is:\n",
      "[581]\ttraining's l1: 78129\tvalid_1's l1: 129552\n",
      "Elapsed 0.40 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 84054\tvalid_1's l1: 123150\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's l1: 83228.4\tvalid_1's l1: 123008\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 78537.7\tvalid_1's l1: 132629\n",
      "Early stopping, best iteration is:\n",
      "[780]\ttraining's l1: 67486.4\tvalid_1's l1: 130544\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 77818.9\tvalid_1's l1: 124448\n",
      "Early stopping, best iteration is:\n",
      "[602]\ttraining's l1: 72891.6\tvalid_1's l1: 123635\n",
      "Elapsed 0.56 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 130555.09444208977\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 135373.87393671068\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 128035.76712682226\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 125706.92651497274\n",
      "\n",
      "\n",
      "Average Val MAE: 129917.9155051516\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:211614.67219\tvalidation_1-mae:228936.90439\n",
      "[125]\tvalidation_0-mae:116717.98079\tvalidation_1-mae:134148.66680\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:216950.23757\tvalidation_1-mae:218237.58085\n",
      "[99]\tvalidation_0-mae:121467.50719\tvalidation_1-mae:122035.00691\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:223553.96416\tvalidation_1-mae:204869.29936\n",
      "[93]\tvalidation_0-mae:124399.43048\tvalidation_1-mae:118033.82616\n",
      "Elapsed 0.24 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 134069.05664858557\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 121802.87535200699\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 117910.03267653314\n",
      "\n",
      "\n",
      "Average Val MAE: 124664.59781519778\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 208115.9783123\ttest: 208115.9783123\ttest1: 225684.0510560\tbest: 225684.0510560 (0)\ttotal: 163ms\tremaining: 27m 5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128904.6581\n",
      "bestIteration = 348\n",
      "\n",
      "Shrink model to first 349 iterations.\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 213724.7627552\ttest: 213724.7627552\ttest1: 214530.2193080\tbest: 214530.2193080 (0)\ttotal: 11.4ms\tremaining: 1m 53s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117890.4553\n",
      "bestIteration = 374\n",
      "\n",
      "Shrink model to first 375 iterations.\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 220060.4801864\ttest: 220060.4801864\ttest1: 201645.8248890\tbest: 201645.8248890 (0)\ttotal: 11.5ms\tremaining: 1m 55s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 113473.1213\n",
      "bestIteration = 276\n",
      "\n",
      "Shrink model to first 277 iterations.\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 128904.65808434553\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 117890.45533152089\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 113473.12133335082\n",
      "\n",
      "\n",
      "Average Val MAE: 120154.91086548244\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:228955.71177\tvalidation_1-mae:242714.56814\n",
      "[110]\tvalidation_0-mae:105203.15783\tvalidation_1-mae:134820.19857\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:235330.03300\tvalidation_1-mae:230108.90573\n",
      "[148]\tvalidation_0-mae:106608.93857\tvalidation_1-mae:122946.80888\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:236510.54992\tvalidation_1-mae:228002.74933\n",
      "[133]\tvalidation_0-mae:105025.67325\tvalidation_1-mae:129564.34014\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:215026.88515\tvalidation_1-mae:234416.47147\n",
      "[499]\tvalidation_0-mae:87430.80141\tvalidation_1-mae:134746.85296\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:208541.37258\tvalidation_1-mae:247845.10137\n",
      "[164]\tvalidation_0-mae:103763.39668\tvalidation_1-mae:139055.00845\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:240308.27485\tvalidation_1-mae:181947.08323\n",
      "[61]\tvalidation_0-mae:128627.07893\tvalidation_1-mae:110633.19123\n",
      "Elapsed 0.33 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:210745.84335\tvalidation_1-mae:209812.89894\n",
      "[102]\tvalidation_0-mae:104059.19104\tvalidation_1-mae:128512.68225\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:218959.90892\tvalidation_1-mae:191813.83465\n",
      "[72]\tvalidation_0-mae:114699.96945\tvalidation_1-mae:113579.18179\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:201152.45179\tvalidation_1-mae:229851.70497\n",
      "[244]\tvalidation_0-mae:94527.76293\tvalidation_1-mae:131875.33226\n",
      "Elapsed 0.49 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:215057.79862\tvalidation_1-mae:183510.34999\n",
      "[87]\tvalidation_0-mae:110053.42764\tvalidation_1-mae:109684.33421\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:199431.59664\tvalidation_1-mae:215086.27214\n",
      "[153]\tvalidation_0-mae:95305.11160\tvalidation_1-mae:132169.58685\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:199038.04543\tvalidation_1-mae:215485.48496\n",
      "[167]\tvalidation_0-mae:94734.32221\tvalidation_1-mae:123695.44539\n",
      "Elapsed 0.63 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 129048.64175251701\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 128009.98019618682\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 124167.8515311142\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 121516.80772983303\n",
      "\n",
      "\n",
      "Average Val MAE: 125685.82030241277\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 124658\tvalid_1's l1: 142906\n",
      "Early stopping, best iteration is:\n",
      "[652]\ttraining's l1: 123149\tvalid_1's l1: 141597\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 128956\tvalid_1's l1: 136530\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 128272\tvalid_1's l1: 136262\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 133857\tvalid_1's l1: 127129\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 141596.98791065282\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 136261.9653216873\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 127128.65434553268\n",
      "\n",
      "\n",
      "Average Val MAE: 135043.50220129188\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 208160.8584076\ttest: 208160.8584076\ttest1: 225687.7553716\tbest: 225687.7553716 (0)\ttotal: 11.5ms\tremaining: 1m 55s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129609.7524\n",
      "bestIteration = 378\n",
      "\n",
      "Shrink model to first 379 iterations.\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 213450.4281370\ttest: 213450.4281370\ttest1: 214252.9895942\tbest: 214252.9895942 (0)\ttotal: 11.9ms\tremaining: 1m 58s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120072.0538\n",
      "bestIteration = 397\n",
      "\n",
      "Shrink model to first 398 iterations.\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 220084.5196273\ttest: 220084.5196273\ttest1: 201695.4804131\tbest: 201695.4804131 (0)\ttotal: 11.7ms\tremaining: 1m 57s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 112666.6751\n",
      "bestIteration = 293\n",
      "\n",
      "Shrink model to first 294 iterations.\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 129609.75241741797\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 120072.05378329026\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 112666.67509554216\n",
      "\n",
      "\n",
      "Average Val MAE: 120847.68888901094\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 224076.3182389\ttest: 224076.3182389\ttest1: 237385.1895550\tbest: 237385.1895550 (0)\ttotal: 6.74ms\tremaining: 1m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130390.5095\n",
      "bestIteration = 229\n",
      "\n",
      "Shrink model to first 230 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 230198.6463875\ttest: 230198.6463875\ttest1: 225505.0084769\tbest: 225505.0084769 (0)\ttotal: 7.47ms\tremaining: 1m 14s\n",
      "500:\tlearn: 109091.9314649\ttest: 109091.9314649\ttest1: 113980.6077027\tbest: 113980.6077027 (500)\ttotal: 2.98s\tremaining: 56.4s\n",
      "1000:\tlearn: 99905.1940937\ttest: 99905.1940937\ttest1: 110485.5432254\tbest: 110477.7812608 (998)\ttotal: 5.9s\tremaining: 53s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 109902.6582\n",
      "bestIteration = 1146\n",
      "\n",
      "Shrink model to first 1147 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 231493.3849389\ttest: 231493.3849389\ttest1: 222841.2956816\tbest: 222841.2956816 (0)\ttotal: 7.34ms\tremaining: 1m 13s\n",
      "500:\tlearn: 105742.5131045\ttest: 105742.5131045\ttest1: 122296.1383910\tbest: 122289.9936514 (499)\ttotal: 2.94s\tremaining: 55.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 122000.9847\n",
      "bestIteration = 554\n",
      "\n",
      "Shrink model to first 555 iterations.\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 210946.9475846\ttest: 210946.9475846\ttest1: 229948.9635221\tbest: 229948.9635221 (0)\ttotal: 6.34ms\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130726.6332\n",
      "bestIteration = 286\n",
      "\n",
      "Shrink model to first 287 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 204884.8631558\ttest: 204884.8631558\ttest1: 243621.5498675\tbest: 243621.5498675 (0)\ttotal: 7.31ms\tremaining: 1m 13s\n",
      "500:\tlearn: 106132.0015635\ttest: 106132.0015635\ttest1: 133555.2477692\tbest: 133555.2477692 (500)\ttotal: 3.05s\tremaining: 57.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 131979.8886\n",
      "bestIteration = 726\n",
      "\n",
      "Shrink model to first 727 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 236447.0176304\ttest: 236447.0176304\ttest1: 178767.2326281\tbest: 178767.2326281 (0)\ttotal: 8.35ms\tremaining: 1m 23s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 108592.2121\n",
      "bestIteration = 152\n",
      "\n",
      "Shrink model to first 153 iterations.\n",
      "Elapsed 0.33 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 207836.2475064\ttest: 207836.2475064\ttest1: 206063.3839595\tbest: 206063.3839595 (0)\ttotal: 6.9ms\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 118618.9151\n",
      "bestIteration = 366\n",
      "\n",
      "Shrink model to first 367 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 215492.8345186\ttest: 215492.8345186\ttest1: 190009.6723965\tbest: 190009.6723965 (0)\ttotal: 7.26ms\tremaining: 1m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 109961.8054\n",
      "bestIteration = 246\n",
      "\n",
      "Shrink model to first 247 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 197893.9759902\ttest: 197893.9759902\ttest1: 225112.0378428\tbest: 225112.0378428 (0)\ttotal: 7.35ms\tremaining: 1m 13s\n",
      "500:\tlearn: 101762.9188375\ttest: 101762.9188375\ttest1: 127534.4278872\tbest: 127534.4278872 (500)\ttotal: 3.09s\tremaining: 58.6s\n",
      "1000:\tlearn: 94402.1623716\ttest: 94402.1623716\ttest1: 124221.0314105\tbest: 124207.7686900 (992)\ttotal: 6.07s\tremaining: 54.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124202.3632\n",
      "bestIteration = 1001\n",
      "\n",
      "Shrink model to first 1002 iterations.\n",
      "Elapsed 0.51 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 212870.1133008\ttest: 212870.1133008\ttest1: 180067.5700907\tbest: 180067.5700907 (0)\ttotal: 6.73ms\tremaining: 1m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 104344.0684\n",
      "bestIteration = 181\n",
      "\n",
      "Shrink model to first 182 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 196392.5865120\ttest: 196392.5865120\ttest1: 213507.9687316\tbest: 213507.9687316 (0)\ttotal: 7.56ms\tremaining: 1m 15s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 122367.4619\n",
      "bestIteration = 424\n",
      "\n",
      "Shrink model to first 425 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 196522.5441805\ttest: 196522.5441805\ttest1: 213083.1331310\tbest: 213083.1331310 (0)\ttotal: 8.05ms\tremaining: 1m 20s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116553.3087\n",
      "bestIteration = 380\n",
      "\n",
      "Shrink model to first 381 iterations.\n",
      "Elapsed 0.62 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 120840.34897760519\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 123813.12897178011\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 117605.55712432039\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 114344.09609998335\n",
      "\n",
      "\n",
      "Average Val MAE: 119150.78279342002\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 124818\tvalid_1's l1: 141003\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's l1: 124228\tvalid_1's l1: 140557\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 129783\tvalid_1's l1: 136877\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 134386\tvalid_1's l1: 128883\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 140557.11046224867\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 136877.2290393476\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 128882.99107913006\n",
      "\n",
      "\n",
      "Average Val MAE: 135475.8194406665\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:211597.20938\tvalidation_1-mae:228884.96556\n",
      "[105]\tvalidation_0-mae:116662.31104\tvalidation_1-mae:132032.47325\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:216928.57803\tvalidation_1-mae:218280.40376\n",
      "[93]\tvalidation_0-mae:121042.86601\tvalidation_1-mae:123840.12908\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:223538.32563\tvalidation_1-mae:204817.14165\n",
      "[84]\tvalidation_0-mae:124910.54525\tvalidation_1-mae:115863.04571\n",
      "Elapsed 0.24 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 131889.41941735553\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 123606.55796078997\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 115685.26424036804\n",
      "\n",
      "\n",
      "Average Val MAE: 123786.79812426545\n",
      "Blended MAE: 120062.16593364044\n"
     ]
    }
   ],
   "source": [
    "from fossil.models.gbdt import FossilGBDT\n",
    "gbdt_models = FossilGBDT()\n",
    "\n",
    "oof_preds, cv_models, blended_mae = gbdt_models.blend_cv_models(principal_features, base_data, fossil_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71e5d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_models.save_cv_models(cv_models, MODEL_CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8cb0b9",
   "metadata": {},
   "source": [
    "### Walk Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f04b3842",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3ef0b20001411198c0ae8bd2023f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba863b4eb56341d7abad00a989abcf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttraining's l1: 98718.5\tvalid_1's l1: 121310\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 52942\tvalid_1's l1: 139219\n",
      "Early stopping, best iteration is:\n",
      "[641]\ttraining's l1: 47190\tvalid_1's l1: 136694\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[299]\ttraining's l1: 75113.1\tvalid_1's l1: 141033\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[486]\ttraining's l1: 60494.3\tvalid_1's l1: 98833.8\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 57054.5\tvalid_1's l1: 121886\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttraining's l1: 55299\tvalid_1's l1: 121516\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[310]\ttraining's l1: 69122.1\tvalid_1's l1: 136216\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\ttraining's l1: 61631.4\tvalid_1's l1: 81876.7\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[436]\ttraining's l1: 60337\tvalid_1's l1: 93318.2\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 40871.8\tvalid_1's l1: 132787\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's l1: 41071.9\tvalid_1's l1: 132784\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[419]\ttraining's l1: 70761.1\tvalid_1's l1: 103169\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 42610.5\tvalid_1's l1: 177333\n",
      "Early stopping, best iteration is:\n",
      "[529]\ttraining's l1: 41519.2\tvalid_1's l1: 176998\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's l1: 119767\tvalid_1's l1: 130381\n",
      "Elapsed 0.18 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 133781.86603790696\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 120128.01118639318\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 103833.38295555026\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 139424.47492426337\n",
      "\n",
      "\n",
      "Average Val MAE: 124291.93377602827\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:233468.09349\tvalidation_1-mae:131476.89997\n",
      "[39]\tvalidation_0-mae:139051.70642\tvalidation_1-mae:91788.93052\n",
      "Elapsed 0.01 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:185635.43362\tvalidation_1-mae:239139.52345\n",
      "[131]\tvalidation_0-mae:82113.49745\tvalidation_1-mae:148451.14764\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:191518.81699\tvalidation_1-mae:228954.35652\n",
      "[86]\tvalidation_0-mae:89537.89222\tvalidation_1-mae:138418.94062\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 90136.46843869767\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 148402.61935043792\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 138096.9925429445\n",
      "\n",
      "\n",
      "Average Val MAE: 128016.89687312423\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 231133.0753449\ttest: 231133.0753449\ttest1: 135892.9465882\tbest: 135892.9465882 (0)\ttotal: 3.5ms\tremaining: 35s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 75210.67945\n",
      "bestIteration = 145\n",
      "\n",
      "Shrink model to first 146 iterations.\n",
      "Elapsed 0.01 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 183942.9482947\ttest: 183942.9482947\ttest1: 236726.1079157\tbest: 236726.1079157 (0)\ttotal: 2.95ms\tremaining: 29.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 145637.6741\n",
      "bestIteration = 159\n",
      "\n",
      "Shrink model to first 160 iterations.\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 190243.1849039\ttest: 190243.1849039\ttest1: 226746.0096320\tbest: 226746.0096320 (0)\ttotal: 3.12ms\tremaining: 31.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130087.7045\n",
      "bestIteration = 111\n",
      "\n",
      "Shrink model to first 112 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 75210.67945234863\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 145637.67410684298\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 130087.7045318514\n",
      "\n",
      "\n",
      "Average Val MAE: 119914.7401940082\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:267492.34691\tvalidation_1-mae:116403.69689\n",
      "[52]\tvalidation_0-mae:125424.75052\tvalidation_1-mae:68518.46469\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:192200.02784\tvalidation_1-mae:282708.53399\n",
      "[386]\tvalidation_0-mae:29807.56010\tvalidation_1-mae:133644.06186\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:208742.38602\tvalidation_1-mae:253868.40256\n",
      "[237]\tvalidation_0-mae:37424.31142\tvalidation_1-mae:129217.44906\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:216675.75068\tvalidation_1-mae:185306.11206\n",
      "[278]\tvalidation_0-mae:45819.28606\tvalidation_1-mae:101083.64220\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:209637.08288\tvalidation_1-mae:202473.50412\n",
      "[56]\tvalidation_0-mae:92087.52858\tvalidation_1-mae:122168.18785\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:194736.21913\tvalidation_1-mae:230241.18645\n",
      "[66]\tvalidation_0-mae:76310.23830\tvalidation_1-mae:127297.96852\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:214800.43542\tvalidation_1-mae:113372.18314\n",
      "[91]\tvalidation_0-mae:72702.53317\tvalidation_1-mae:57732.52317\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:194944.25155\tvalidation_1-mae:169293.16579\n",
      "[90]\tvalidation_0-mae:64726.52819\tvalidation_1-mae:87291.58961\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:144965.16372\tvalidation_1-mae:263279.10251\n",
      "[293]\tvalidation_0-mae:22235.40795\tvalidation_1-mae:122719.77366\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:235296.58551\tvalidation_1-mae:115028.56456\n",
      "[33]\tvalidation_0-mae:139133.57378\tvalidation_1-mae:62877.59497\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:146168.99660\tvalidation_1-mae:301117.45600\n",
      "[420]\tvalidation_0-mae:18700.08693\tvalidation_1-mae:184135.14841\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:217922.40290\tvalidation_1-mae:168423.22322\n",
      "[42]\tvalidation_0-mae:112794.07150\tvalidation_1-mae:85352.07104\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 111968.82280630548\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 116907.37066452733\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 90944.32511489792\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 112901.74537752545\n",
      "\n",
      "\n",
      "Average Val MAE: 108180.56599081405\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 114417\tvalid_1's l1: 96086.5\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's l1: 112709\tvalid_1's l1: 95175.4\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 90638.8\tvalid_1's l1: 136427\n",
      "Early stopping, best iteration is:\n",
      "[517]\ttraining's l1: 90423.7\tvalid_1's l1: 136381\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttraining's l1: 107794\tvalid_1's l1: 146723\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 95175.44291404303\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 136381.0202036183\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 146722.89786407197\n",
      "\n",
      "\n",
      "Average Val MAE: 128133.47252368878\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 230386.1502018\ttest: 230386.1502018\ttest1: 135192.3481590\tbest: 135192.3481590 (0)\ttotal: 3.45ms\tremaining: 34.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 70979.90069\n",
      "bestIteration = 172\n",
      "\n",
      "Shrink model to first 173 iterations.\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 183628.5550371\ttest: 183628.5550371\ttest1: 235902.6289246\tbest: 235902.6289246 (0)\ttotal: 3.18ms\tremaining: 31.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 134482.8259\n",
      "bestIteration = 184\n",
      "\n",
      "Shrink model to first 185 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 190283.7303044\ttest: 190283.7303044\ttest1: 226981.9945832\tbest: 226981.9945832 (0)\ttotal: 2.98ms\tremaining: 29.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 122570.0429\n",
      "bestIteration = 120\n",
      "\n",
      "Shrink model to first 121 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 70979.90068974881\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 134482.82592333373\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 122570.04288959417\n",
      "\n",
      "\n",
      "Average Val MAE: 112026.63017918095\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 262933.7945859\ttest: 262933.7945859\ttest1: 121832.8678322\tbest: 121832.8678322 (0)\ttotal: 3.26ms\tremaining: 32.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 81463.40971\n",
      "bestIteration = 46\n",
      "\n",
      "Shrink model to first 47 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 189660.8768465\ttest: 189660.8768465\ttest1: 279564.6511808\tbest: 279564.6511808 (0)\ttotal: 3.6ms\tremaining: 36s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 165086.5494\n",
      "bestIteration = 264\n",
      "\n",
      "Shrink model to first 265 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 206789.4679854\ttest: 206789.4679854\ttest1: 249102.5452777\tbest: 249102.5452777 (0)\ttotal: 3.38ms\tremaining: 33.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128510.2574\n",
      "bestIteration = 210\n",
      "\n",
      "Shrink model to first 211 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 213779.9145544\ttest: 213779.9145544\ttest1: 188022.4483724\tbest: 188022.4483724 (0)\ttotal: 2.25ms\tremaining: 22.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 108433.0835\n",
      "bestIteration = 245\n",
      "\n",
      "Shrink model to first 246 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 208009.9446565\ttest: 208009.9446565\ttest1: 201752.3634712\tbest: 201752.3634712 (0)\ttotal: 3.3ms\tremaining: 33s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 110624.027\n",
      "bestIteration = 140\n",
      "\n",
      "Shrink model to first 141 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 193604.5871263\ttest: 193604.5871263\ttest1: 229033.9015708\tbest: 229033.9015708 (0)\ttotal: 2.26ms\tremaining: 22.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 114071.4272\n",
      "bestIteration = 221\n",
      "\n",
      "Shrink model to first 222 iterations.\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 211542.1740719\ttest: 211542.1740719\ttest1: 117029.6958419\tbest: 117029.6958419 (0)\ttotal: 3.61ms\tremaining: 36.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 61040.35455\n",
      "bestIteration = 137\n",
      "\n",
      "Shrink model to first 138 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 193209.4935007\ttest: 193209.4935007\ttest1: 167805.2741732\tbest: 167805.2741732 (0)\ttotal: 4.83ms\tremaining: 48.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 72502.27757\n",
      "bestIteration = 298\n",
      "\n",
      "Shrink model to first 299 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 143552.9040123\ttest: 143552.9040123\ttest1: 262501.3326077\tbest: 262501.3326077 (0)\ttotal: 3.89ms\tremaining: 38.9s\n",
      "500:\tlearn: 46480.9739262\ttest: 46480.9739262\ttest1: 134724.9601733\tbest: 134724.9601733 (500)\ttotal: 1.72s\tremaining: 32.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 132914.9444\n",
      "bestIteration = 627\n",
      "\n",
      "Shrink model to first 628 iterations.\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 233502.2638947\ttest: 233502.2638947\ttest1: 116779.4810243\tbest: 116779.4810243 (0)\ttotal: 3.32ms\tremaining: 33.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 59897.26229\n",
      "bestIteration = 138\n",
      "\n",
      "Shrink model to first 139 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 145150.5576522\ttest: 145150.5576522\ttest1: 300031.8601253\tbest: 300031.8601253 (0)\ttotal: 3.91ms\tremaining: 39.1s\n",
      "500:\tlearn: 47075.0286078\ttest: 47075.0286078\ttest1: 186314.8067618\tbest: 186314.8067618 (500)\ttotal: 1.65s\tremaining: 31.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 180847.4229\n",
      "bestIteration = 836\n",
      "\n",
      "Shrink model to first 837 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 217230.7072306\ttest: 217230.7072306\ttest1: 168092.0355041\tbest: 168092.0355041 (0)\ttotal: 3.8ms\tremaining: 38s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 85717.54761\n",
      "bestIteration = 115\n",
      "\n",
      "Shrink model to first 116 iterations.\n",
      "Elapsed 0.24 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 128205.76471594263\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 111199.40500691973\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 90341.30075273979\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 112727.87020378544\n",
      "\n",
      "\n",
      "Average Val MAE: 110618.58516984667\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[437]\ttraining's l1: 112790\tvalid_1's l1: 123629\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 94995.9\tvalid_1's l1: 139918\n",
      "Early stopping, best iteration is:\n",
      "[535]\ttraining's l1: 94683.2\tvalid_1's l1: 139837\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's l1: 133969\tvalid_1's l1: 186844\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 123628.97147209434\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 139837.2794078891\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 186844.0295539041\n",
      "\n",
      "\n",
      "Average Val MAE: 151618.38345487622\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:233470.20175\tvalidation_1-mae:132377.53004\n",
      "[48]\tvalidation_0-mae:127778.71381\tvalidation_1-mae:92906.35827\n",
      "Elapsed 0.01 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:185627.04016\tvalidation_1-mae:239172.12101\n",
      "[149]\tvalidation_0-mae:87808.31398\tvalidation_1-mae:136465.14040\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:191495.98808\tvalidation_1-mae:227649.64670\n",
      "[53]\tvalidation_0-mae:99750.80120\tvalidation_1-mae:131507.23337\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 91929.5942193949\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 136279.308718568\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 130323.39348675271\n",
      "\n",
      "\n",
      "Average Val MAE: 121423.32192556061\n",
      "Blended MAE: 113991.02641707445\n",
      "Walk forward MAE:  57474.05995692443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3c7b3fa80f455a93cdbff610b67e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d67537658c4c6889fa8c80f6a9bac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\ttraining's l1: 87471.1\tvalid_1's l1: 173746\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[491]\ttraining's l1: 56909.4\tvalid_1's l1: 122354\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 56095.1\tvalid_1's l1: 103280\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's l1: 49258.9\tvalid_1's l1: 101596\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttraining's l1: 80109.5\tvalid_1's l1: 200926\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 60114.6\tvalid_1's l1: 115708\n",
      "Early stopping, best iteration is:\n",
      "[512]\ttraining's l1: 59358.8\tvalid_1's l1: 115526\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\ttraining's l1: 91600.5\tvalid_1's l1: 133652\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's l1: 90256.1\tvalid_1's l1: 188778\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 63079.3\tvalid_1's l1: 120230\n",
      "Early stopping, best iteration is:\n",
      "[551]\ttraining's l1: 59794.5\tvalid_1's l1: 119775\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 66617.3\tvalid_1's l1: 112867\n",
      "Early stopping, best iteration is:\n",
      "[561]\ttraining's l1: 62650.7\tvalid_1's l1: 112109\n",
      "Elapsed 0.21 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's l1: 86452.7\tvalid_1's l1: 210372\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[491]\ttraining's l1: 63203.8\tvalid_1's l1: 116263\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[454]\ttraining's l1: 62226.1\tvalid_1's l1: 150557\n",
      "Elapsed 0.28 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 132882.80914205694\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 150231.88443894265\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 140519.78098607133\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 159191.81409312773\n",
      "\n",
      "\n",
      "Average Val MAE: 145706.57216504932\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:212747.96604\tvalidation_1-mae:232197.56754\n",
      "[87]\tvalidation_0-mae:100713.09963\tvalidation_1-mae:172164.20691\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:221550.79620\tvalidation_1-mae:213569.80344\n",
      "[66]\tvalidation_0-mae:119768.64361\tvalidation_1-mae:117276.77356\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:223377.18463\tvalidation_1-mae:209744.97948\n",
      "[55]\tvalidation_0-mae:121018.10511\tvalidation_1-mae:132023.09353\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 171493.97967229525\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 116217.11487438212\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 131024.76539884426\n",
      "\n",
      "\n",
      "Average Val MAE: 139687.04069218403\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 211577.2979947\ttest: 211577.2979947\ttest1: 231779.2501151\tbest: 231779.2501151 (0)\ttotal: 3.79ms\tremaining: 37.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 164675.3267\n",
      "bestIteration = 221\n",
      "\n",
      "Shrink model to first 222 iterations.\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 220455.7850476\ttest: 220455.7850476\ttest1: 213051.9186638\tbest: 213051.9186638 (0)\ttotal: 4.03ms\tremaining: 40.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 111229.7712\n",
      "bestIteration = 135\n",
      "\n",
      "Shrink model to first 136 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 222416.1702088\ttest: 222416.1702088\ttest1: 209538.2009477\tbest: 209538.2009477 (0)\ttotal: 4.26ms\tremaining: 42.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121356.5056\n",
      "bestIteration = 123\n",
      "\n",
      "Shrink model to first 124 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 164675.32674094744\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 111229.77120369773\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 121356.50560773676\n",
      "\n",
      "\n",
      "Average Val MAE: 132551.62564714256\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:222105.25578\tvalidation_1-mae:212360.83057\n",
      "[65]\tvalidation_0-mae:93498.01505\tvalidation_1-mae:134310.04108\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:217416.62509\tvalidation_1-mae:222408.05269\n",
      "[100]\tvalidation_0-mae:74398.94691\tvalidation_1-mae:124159.96654\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:217654.38307\tvalidation_1-mae:222543.24632\n",
      "[270]\tvalidation_0-mae:48549.90565\tvalidation_1-mae:107651.59357\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:202832.25609\tvalidation_1-mae:269047.08007\n",
      "[161]\tvalidation_0-mae:57351.51541\tvalidation_1-mae:157400.10077\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:223736.79646\tvalidation_1-mae:226795.34056\n",
      "[148]\tvalidation_0-mae:65311.40653\tvalidation_1-mae:119700.52748\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:247353.38795\tvalidation_1-mae:176723.29327\n",
      "[60]\tvalidation_0-mae:110337.96625\tvalidation_1-mae:89433.54189\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:210515.16108\tvalidation_1-mae:251550.58717\n",
      "[82]\tvalidation_0-mae:77739.60939\tvalidation_1-mae:181174.07394\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:227294.45494\tvalidation_1-mae:217448.77400\n",
      "[94]\tvalidation_0-mae:83953.90215\tvalidation_1-mae:117488.56057\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:234372.96527\tvalidation_1-mae:203097.91315\n",
      "[138]\tvalidation_0-mae:73764.97695\tvalidation_1-mae:105002.55995\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:215846.07448\tvalidation_1-mae:196744.93490\n",
      "[60]\tvalidation_0-mae:94885.91606\tvalidation_1-mae:161763.16269\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:217999.84972\tvalidation_1-mae:192156.11534\n",
      "[60]\tvalidation_0-mae:102470.49484\tvalidation_1-mae:119512.94372\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:194323.38707\tvalidation_1-mae:240929.84840\n",
      "[61]\tvalidation_0-mae:90586.32107\tvalidation_1-mae:158243.60115\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 121612.49632090358\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 120919.42708837264\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 134619.90569322085\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 145868.59514062852\n",
      "\n",
      "\n",
      "Average Val MAE: 130755.1060607814\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[469]\ttraining's l1: 101944\tvalid_1's l1: 162091\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's l1: 149318\tvalid_1's l1: 176633\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[330]\ttraining's l1: 133002\tvalid_1's l1: 148587\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 162090.89715182874\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 176633.44199077802\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 148587.23286868611\n",
      "\n",
      "\n",
      "Average Val MAE: 162560.02674615392\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 211061.4614286\ttest: 211061.4614286\ttest1: 231155.8185215\tbest: 231155.8185215 (0)\ttotal: 3.69ms\tremaining: 36.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 148587.1192\n",
      "bestIteration = 231\n",
      "\n",
      "Shrink model to first 232 iterations.\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 220542.2953829\ttest: 220542.2953829\ttest1: 213049.6551992\tbest: 213049.6551992 (0)\ttotal: 5.85ms\tremaining: 58.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121825.3516\n",
      "bestIteration = 132\n",
      "\n",
      "Shrink model to first 133 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 222435.3480591\ttest: 222435.3480591\ttest1: 209716.1550548\tbest: 209716.1550548 (0)\ttotal: 3.51ms\tremaining: 35.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 118736.1593\n",
      "bestIteration = 161\n",
      "\n",
      "Shrink model to first 162 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 148587.11920712408\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 121825.35157891331\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 118736.15926108453\n",
      "\n",
      "\n",
      "Average Val MAE: 129832.9925187849\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 220583.7242063\ttest: 220583.7242063\ttest1: 209680.1559316\tbest: 209680.1559316 (0)\ttotal: 3.68ms\tremaining: 36.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115327.6023\n",
      "bestIteration = 178\n",
      "\n",
      "Shrink model to first 179 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 215423.0686308\ttest: 215423.0686308\ttest1: 220353.4564889\tbest: 220353.4564889 (0)\ttotal: 4.07ms\tremaining: 40.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124059.496\n",
      "bestIteration = 175\n",
      "\n",
      "Shrink model to first 176 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 215358.1969520\ttest: 215358.1969520\ttest1: 220675.9058019\tbest: 220675.9058019 (0)\ttotal: 4.09ms\tremaining: 40.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116818.3306\n",
      "bestIteration = 208\n",
      "\n",
      "Shrink model to first 209 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 201289.6349235\ttest: 201289.6349235\ttest1: 267400.1749940\tbest: 267400.1749940 (0)\ttotal: 3.9ms\tremaining: 39s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 170233.5025\n",
      "bestIteration = 219\n",
      "\n",
      "Shrink model to first 220 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 222899.4242611\ttest: 222899.4242611\ttest1: 225082.6863636\tbest: 225082.6863636 (0)\ttotal: 4.59ms\tremaining: 45.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 111410.9638\n",
      "bestIteration = 173\n",
      "\n",
      "Shrink model to first 174 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 246501.8879177\ttest: 246501.8879177\ttest1: 177343.9468090\tbest: 177343.9468090 (0)\ttotal: 4.35ms\tremaining: 43.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 96154.27695\n",
      "bestIteration = 98\n",
      "\n",
      "Shrink model to first 99 iterations.\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 209776.6792994\ttest: 209776.6792994\ttest1: 250668.4001764\tbest: 250668.4001764 (0)\ttotal: 4.03ms\tremaining: 40.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 144875.0977\n",
      "bestIteration = 192\n",
      "\n",
      "Shrink model to first 193 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 226023.4867307\ttest: 226023.4867307\ttest1: 216887.5706732\tbest: 216887.5706732 (0)\ttotal: 4.34ms\tremaining: 43.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119085.0241\n",
      "bestIteration = 197\n",
      "\n",
      "Shrink model to first 198 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 233254.1257848\ttest: 233254.1257848\ttest1: 201007.1316627\tbest: 201007.1316627 (0)\ttotal: 4.18ms\tremaining: 41.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 99886.51145\n",
      "bestIteration = 216\n",
      "\n",
      "Shrink model to first 217 iterations.\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 215147.8292731\ttest: 215147.8292731\ttest1: 196847.2904693\tbest: 196847.2904693 (0)\ttotal: 14.8ms\tremaining: 2m 27s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 145158.7347\n",
      "bestIteration = 60\n",
      "\n",
      "Shrink model to first 61 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 217729.4762177\ttest: 217729.4762177\ttest1: 191963.9651179\tbest: 191963.9651179 (0)\ttotal: 3.88ms\tremaining: 38.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 109123.1183\n",
      "bestIteration = 128\n",
      "\n",
      "Shrink model to first 129 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 194075.5669018\ttest: 194075.5669018\ttest1: 239782.4248356\tbest: 239782.4248356 (0)\ttotal: 5.04ms\tremaining: 50.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 139952.0611\n",
      "bestIteration = 199\n",
      "\n",
      "Shrink model to first 200 iterations.\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 118748.73903639574\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 126242.66647614629\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 121496.41917597885\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 131349.26991795166\n",
      "\n",
      "\n",
      "Average Val MAE: 124459.27365161642\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 105677\tvalid_1's l1: 160312\n",
      "Early stopping, best iteration is:\n",
      "[573]\ttraining's l1: 104782\tvalid_1's l1: 159899\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's l1: 150882\tvalid_1's l1: 171653\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's l1: 149782\tvalid_1's l1: 173185\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 159898.54715073112\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 171653.06991403553\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 173185.4529083641\n",
      "\n",
      "\n",
      "Average Val MAE: 168193.29576046192\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:212741.81230\tvalidation_1-mae:232203.19955\n",
      "[78]\tvalidation_0-mae:105192.17702\tvalidation_1-mae:144206.75743\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:221531.44702\tvalidation_1-mae:213628.47880\n",
      "[58]\tvalidation_0-mae:121751.23918\tvalidation_1-mae:126473.30849\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:223344.26615\tvalidation_1-mae:210108.37065\n",
      "[53]\tvalidation_0-mae:122892.66798\tvalidation_1-mae:141890.95205\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 143867.93517656514\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 125299.48459406385\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 140713.61023907294\n",
      "\n",
      "\n",
      "Average Val MAE: 136597.99929707867\n",
      "Blended MAE: 132863.33130479528\n",
      "Walk forward MAE:  90878.89147800686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2799185b23ee4726a0fc245e20b71e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd85d797dd074562a89d8f9f19fb163b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's l1: 161054\tvalid_1's l1: 264027\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\ttraining's l1: 73259\tvalid_1's l1: 132897\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[446]\ttraining's l1: 67239.2\tvalid_1's l1: 151337\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's l1: 266165\tvalid_1's l1: 346815\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[493]\ttraining's l1: 68701\tvalid_1's l1: 132362\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[366]\ttraining's l1: 79964.1\tvalid_1's l1: 159932\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's l1: 283005\tvalid_1's l1: 336237\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\ttraining's l1: 112806\tvalid_1's l1: 141321\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 62067.3\tvalid_1's l1: 147734\n",
      "Early stopping, best iteration is:\n",
      "[573]\ttraining's l1: 57828.5\tvalid_1's l1: 147045\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's l1: 277043\tvalid_1's l1: 325391\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 67521.3\tvalid_1's l1: 113859\n",
      "Early stopping, best iteration is:\n",
      "[522]\ttraining's l1: 65957.1\tvalid_1's l1: 113594\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's l1: 78202.5\tvalid_1's l1: 119378\n",
      "Elapsed 0.25 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 180677.16881777946\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 209681.86376759515\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 205459.78286316604\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 183149.05843440385\n",
      "\n",
      "\n",
      "Average Val MAE: 194741.96847073638\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:205649.86209\tvalidation_1-mae:242347.07227\n",
      "[69]\tvalidation_0-mae:126083.50193\tvalidation_1-mae:210526.78234\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:227042.93827\tvalidation_1-mae:198603.48623\n",
      "[71]\tvalidation_0-mae:160496.01207\tvalidation_1-mae:125096.82600\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:219030.09070\tvalidation_1-mae:213258.90803\n",
      "[76]\tvalidation_0-mae:148631.54869\tvalidation_1-mae:162256.75156\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 210390.96629550937\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 124274.18618298894\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 161706.97165415424\n",
      "\n",
      "\n",
      "Average Val MAE: 163691.1114718993\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 204290.7432310\ttest: 204290.7432310\ttest1: 241616.2454871\tbest: 241616.2454871 (0)\ttotal: 5.04ms\tremaining: 50.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 201246.2064\n",
      "bestIteration = 195\n",
      "\n",
      "Shrink model to first 196 iterations.\n",
      "Elapsed 0.02 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 226830.6613690\ttest: 226830.6613690\ttest1: 197450.3575051\tbest: 197450.3575051 (0)\ttotal: 4.76ms\tremaining: 47.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119380.8043\n",
      "bestIteration = 108\n",
      "\n",
      "Shrink model to first 109 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 218395.7887532\ttest: 218395.7887532\ttest1: 212275.8394300\tbest: 212275.8394300 (0)\ttotal: 5.12ms\tremaining: 51.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 140130.5362\n",
      "bestIteration = 161\n",
      "\n",
      "Shrink model to first 162 iterations.\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 201246.20639116818\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 119380.80428822603\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 140130.5362258028\n",
      "\n",
      "\n",
      "Average Val MAE: 152142.70884855808\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:224068.69557\tvalidation_1-mae:262732.70252\n",
      "[48]\tvalidation_0-mae:120190.30187\tvalidation_1-mae:213543.07551\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:246824.31685\tvalidation_1-mae:217835.50850\n",
      "[141]\tvalidation_0-mae:80612.63581\tvalidation_1-mae:120469.08266\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:238753.73777\tvalidation_1-mae:230942.10806\n",
      "[91]\tvalidation_0-mae:88767.13462\tvalidation_1-mae:142741.15014\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:212876.94206\tvalidation_1-mae:249854.02615\n",
      "[30]\tvalidation_0-mae:137509.01680\tvalidation_1-mae:229826.56034\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:225937.12088\tvalidation_1-mae:220121.24509\n",
      "[92]\tvalidation_0-mae:95599.77049\tvalidation_1-mae:131854.92515\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:234033.44423\tvalidation_1-mae:202712.51408\n",
      "[57]\tvalidation_0-mae:117125.96870\tvalidation_1-mae:133797.88441\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:192887.32828\tvalidation_1-mae:241104.15634\n",
      "[26]\tvalidation_0-mae:132414.07842\tvalidation_1-mae:230194.35416\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:228763.26995\tvalidation_1-mae:169028.10901\n",
      "[52]\tvalidation_0-mae:125173.33837\tvalidation_1-mae:95481.18084\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:202912.23090\tvalidation_1-mae:218361.75535\n",
      "[296]\tvalidation_0-mae:58333.48003\tvalidation_1-mae:141686.77003\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:185899.63025\tvalidation_1-mae:229936.08924\n",
      "[176]\tvalidation_0-mae:64021.16237\tvalidation_1-mae:183968.56628\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:193413.79456\tvalidation_1-mae:209963.17371\n",
      "[198]\tvalidation_0-mae:69946.71947\tvalidation_1-mae:117518.38123\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:218336.28035\tvalidation_1-mae:157669.06850\n",
      "[61]\tvalidation_0-mae:108829.69039\tvalidation_1-mae:99920.36141\n",
      "Elapsed 0.18 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 155251.0776923182\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 161860.3036633363\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 152106.23519550936\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 132572.04814131447\n",
      "\n",
      "\n",
      "Average Val MAE: 150447.4161731196\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 127440\tvalid_1's l1: 181276\n",
      "Early stopping, best iteration is:\n",
      "[871]\ttraining's l1: 123353\tvalid_1's l1: 177600\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 146905\tvalid_1's l1: 154827\n",
      "Early stopping, best iteration is:\n",
      "[543]\ttraining's l1: 145496\tvalid_1's l1: 154519\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 143530\tvalid_1's l1: 150702\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 177600.07799149223\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 154519.24734692965\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 150701.83664259678\n",
      "\n",
      "\n",
      "Average Val MAE: 160687.25915434211\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 204281.2443576\ttest: 204281.2443576\ttest1: 241089.1183150\tbest: 241089.1183150 (0)\ttotal: 5.28ms\tremaining: 52.8s\n",
      "500:\tlearn: 115067.2712474\ttest: 115067.2712474\ttest1: 174189.2126551\tbest: 174189.2126551 (500)\ttotal: 2.41s\tremaining: 45.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 172962.1566\n",
      "bestIteration = 673\n",
      "\n",
      "Shrink model to first 674 iterations.\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 226724.0694482\ttest: 226724.0694482\ttest1: 197710.3924668\tbest: 197710.3924668 (0)\ttotal: 5.29ms\tremaining: 52.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120936.543\n",
      "bestIteration = 136\n",
      "\n",
      "Shrink model to first 137 iterations.\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 217893.4208931\ttest: 217893.4208931\ttest1: 211549.9578264\tbest: 211549.9578264 (0)\ttotal: 5.45ms\tremaining: 54.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 132274.3686\n",
      "bestIteration = 274\n",
      "\n",
      "Shrink model to first 275 iterations.\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 172962.15660537675\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 120936.54295613467\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 132274.36859251198\n",
      "\n",
      "\n",
      "Average Val MAE: 141169.97110690537\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 222688.9386312\ttest: 222688.9386312\ttest1: 261646.0493823\tbest: 261646.0493823 (0)\ttotal: 4.43ms\tremaining: 44.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 157737.7651\n",
      "bestIteration = 164\n",
      "\n",
      "Shrink model to first 165 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 245470.2965964\ttest: 245470.2965964\ttest1: 215375.6705703\tbest: 215375.6705703 (0)\ttotal: 4.31ms\tremaining: 43.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120789.4082\n",
      "bestIteration = 248\n",
      "\n",
      "Shrink model to first 249 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 236626.3136737\ttest: 236626.3136737\ttest1: 230068.9211784\tbest: 230068.9211784 (0)\ttotal: 4.6ms\tremaining: 46s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 144486.7422\n",
      "bestIteration = 151\n",
      "\n",
      "Shrink model to first 152 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 211367.9952080\ttest: 211367.9952080\ttest1: 247924.7943338\tbest: 247924.7943338 (0)\ttotal: 4.62ms\tremaining: 46.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 173165.7608\n",
      "bestIteration = 135\n",
      "\n",
      "Shrink model to first 136 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 224946.7724689\ttest: 224946.7724689\ttest1: 219231.5774758\tbest: 219231.5774758 (0)\ttotal: 5.01ms\tremaining: 50.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 118356.2195\n",
      "bestIteration = 191\n",
      "\n",
      "Shrink model to first 192 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 232092.3845885\ttest: 232092.3845885\ttest1: 202111.1565090\tbest: 202111.1565090 (0)\ttotal: 5.17ms\tremaining: 51.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128801.1884\n",
      "bestIteration = 136\n",
      "\n",
      "Shrink model to first 137 iterations.\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 192415.9279686\ttest: 192415.9279686\ttest1: 240251.5397441\tbest: 240251.5397441 (0)\ttotal: 4.17ms\tremaining: 41.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 164229.2596\n",
      "bestIteration = 268\n",
      "\n",
      "Shrink model to first 269 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 228039.9609500\ttest: 228039.9609500\ttest1: 168847.4816369\tbest: 168847.4816369 (0)\ttotal: 5.51ms\tremaining: 55.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 100543.8593\n",
      "bestIteration = 110\n",
      "\n",
      "Shrink model to first 111 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 202345.7976927\ttest: 202345.7976927\ttest1: 218121.4539966\tbest: 218121.4539966 (0)\ttotal: 4.94ms\tremaining: 49.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 138267.6003\n",
      "bestIteration = 413\n",
      "\n",
      "Shrink model to first 414 iterations.\n",
      "Elapsed 0.18 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 185405.5843248\ttest: 185405.5843248\ttest1: 228637.5010514\tbest: 228637.5010514 (0)\ttotal: 5.35ms\tremaining: 53.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 166622.4926\n",
      "bestIteration = 155\n",
      "\n",
      "Shrink model to first 156 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 193453.3862436\ttest: 193453.3862436\ttest1: 209762.2585748\tbest: 209762.2585748 (0)\ttotal: 6.02ms\tremaining: 1m\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 114648.3256\n",
      "bestIteration = 429\n",
      "\n",
      "Shrink model to first 430 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 218019.9641657\ttest: 218019.9641657\ttest1: 157466.9523215\tbest: 157466.9523215 (0)\ttotal: 5.13ms\tremaining: 51.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 103674.1163\n",
      "bestIteration = 114\n",
      "\n",
      "Shrink model to first 115 iterations.\n",
      "Elapsed 0.25 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 140125.37355363672\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 139196.35003397203\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 132881.0228289044\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 127782.79457947629\n",
      "\n",
      "\n",
      "Average Val MAE: 134996.38524899897\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 130015\tvalid_1's l1: 161640\n",
      "Early stopping, best iteration is:\n",
      "[916]\ttraining's l1: 126526\tvalid_1's l1: 157643\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 140499\tvalid_1's l1: 149996\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 139058\tvalid_1's l1: 149650\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 139828\tvalid_1's l1: 145402\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 157643.33357266503\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 149650.49553316255\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 145401.7450462246\n",
      "\n",
      "\n",
      "Average Val MAE: 150857.41266205264\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:205558.64887\tvalidation_1-mae:241867.37771\n",
      "[154]\tvalidation_0-mae:120480.63298\tvalidation_1-mae:156366.27061\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:226812.41295\tvalidation_1-mae:198825.07834\n",
      "[66]\tvalidation_0-mae:135257.06995\tvalidation_1-mae:123904.55597\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:218752.71574\tvalidation_1-mae:212867.86747\n",
      "[98]\tvalidation_0-mae:128655.22364\tvalidation_1-mae:136048.32532\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 156356.41978602207\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 123119.86382201908\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 135592.46247035085\n",
      "\n",
      "\n",
      "Average Val MAE: 137705.9647551772\n",
      "Blended MAE: 143789.66241182576\n",
      "Walk forward MAE:  81314.89935724746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23704118f094e09b3b638181356084b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d05e2e7fc64f6689276ddb7dec881f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's l1: 116899\tvalid_1's l1: 229728\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 68183.2\tvalid_1's l1: 116270\n",
      "Early stopping, best iteration is:\n",
      "[617]\ttraining's l1: 61092.6\tvalid_1's l1: 114984\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[380]\ttraining's l1: 79783.6\tvalid_1's l1: 145416\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's l1: 169919\tvalid_1's l1: 265984\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 62897.4\tvalid_1's l1: 127661\n",
      "Early stopping, best iteration is:\n",
      "[597]\ttraining's l1: 57146.6\tvalid_1's l1: 126844\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's l1: 81955.7\tvalid_1's l1: 140101\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's l1: 126713\tvalid_1's l1: 258928\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 65561.6\tvalid_1's l1: 111558\n",
      "Early stopping, best iteration is:\n",
      "[585]\ttraining's l1: 60123.2\tvalid_1's l1: 110703\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 62582.1\tvalid_1's l1: 124489\n",
      "Early stopping, best iteration is:\n",
      "[596]\ttraining's l1: 56749.6\tvalid_1's l1: 123727\n",
      "Elapsed 0.26 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's l1: 109626\tvalid_1's l1: 224105\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 64370.6\tvalid_1's l1: 110304\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's l1: 57100.7\tvalid_1's l1: 109254\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's l1: 98061.1\tvalid_1's l1: 155362\n",
      "Elapsed 0.34 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 160942.46148972888\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 174353.10787945212\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 160932.39936720967\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 160695.9511963264\n",
      "\n",
      "\n",
      "Average Val MAE: 164230.979983179\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:202897.07718\tvalidation_1-mae:240455.47033\n",
      "[130]\tvalidation_0-mae:122159.45165\tvalidation_1-mae:154618.61913\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:222626.27936\tvalidation_1-mae:197871.03046\n",
      "[64]\tvalidation_0-mae:136727.83089\tvalidation_1-mae:127104.11513\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:217814.62600\tvalidation_1-mae:207231.19573\n",
      "[63]\tvalidation_0-mae:128917.19497\tvalidation_1-mae:148556.00945\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 154546.3901687376\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126621.52062143451\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 148136.30879825543\n",
      "\n",
      "\n",
      "Average Val MAE: 142711.50403832906\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 201569.8399586\ttest: 201569.8399586\ttest1: 238460.5651242\tbest: 238460.5651242 (0)\ttotal: 6.38ms\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 152600.3103\n",
      "bestIteration = 315\n",
      "\n",
      "Shrink model to first 316 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 221174.7692558\ttest: 221174.7692558\ttest1: 196599.1255307\tbest: 196599.1255307 (0)\ttotal: 6.43ms\tremaining: 1m 4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124902.2547\n",
      "bestIteration = 155\n",
      "\n",
      "Shrink model to first 156 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 217332.9961622\ttest: 217332.9961622\ttest1: 207723.2642732\tbest: 207723.2642732 (0)\ttotal: 6.19ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 137250.3121\n",
      "bestIteration = 147\n",
      "\n",
      "Shrink model to first 148 iterations.\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 152600.3102830007\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 124902.25472866616\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 137250.31212658028\n",
      "\n",
      "\n",
      "Average Val MAE: 137735.29013465057\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:221189.99681\tvalidation_1-mae:262656.91599\n",
      "[100]\tvalidation_0-mae:88513.96578\tvalidation_1-mae:189916.86110\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:231124.95071\tvalidation_1-mae:238044.85962\n",
      "[121]\tvalidation_0-mae:87829.67974\tvalidation_1-mae:120071.02423\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:248994.70102\tvalidation_1-mae:203825.59493\n",
      "[69]\tvalidation_0-mae:110746.94394\tvalidation_1-mae:126503.21820\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:222668.96173\tvalidation_1-mae:209147.89776\n",
      "[41]\tvalidation_0-mae:127734.53734\tvalidation_1-mae:163367.15715\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:199160.90663\tvalidation_1-mae:256126.00980\n",
      "[311]\tvalidation_0-mae:66949.94759\tvalidation_1-mae:130199.34604\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:233689.36478\tvalidation_1-mae:190187.47710\n",
      "[84]\tvalidation_0-mae:100984.68689\tvalidation_1-mae:119069.20266\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:195814.47422\tvalidation_1-mae:217072.74498\n",
      "[80]\tvalidation_0-mae:90161.93957\tvalidation_1-mae:177016.69753\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:209645.53525\tvalidation_1-mae:186461.76703\n",
      "[59]\tvalidation_0-mae:108550.18262\tvalidation_1-mae:121657.65240\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:200596.53038\tvalidation_1-mae:204771.59023\n",
      "[161]\tvalidation_0-mae:75940.65955\tvalidation_1-mae:114323.81345\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:197689.54856\tvalidation_1-mae:216108.73950\n",
      "[165]\tvalidation_0-mae:72565.08294\tvalidation_1-mae:157350.44519\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:205788.97367\tvalidation_1-mae:197831.42056\n",
      "[163]\tvalidation_0-mae:76691.81397\tvalidation_1-mae:110369.06215\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:205907.72575\tvalidation_1-mae:196958.67210\n",
      "[64]\tvalidation_0-mae:104758.88875\tvalidation_1-mae:115139.08425\n",
      "Elapsed 0.24 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 142879.6098601853\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 135376.5694629553\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 135846.03792522082\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 126087.73970638505\n",
      "\n",
      "\n",
      "Average Val MAE: 135047.4892386866\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 126266\tvalid_1's l1: 157657\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 125193\tvalid_1's l1: 157192\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 137859\tvalid_1's l1: 132042\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 131333\tvalid_1's l1: 151444\n",
      "Early stopping, best iteration is:\n",
      "[503]\ttraining's l1: 131288\tvalid_1's l1: 151420\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 157191.90319768258\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 132041.8872043595\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 151420.41152110053\n",
      "\n",
      "\n",
      "Average Val MAE: 146533.59888648507\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 201596.5223615\ttest: 201596.5223615\ttest1: 238447.0764984\tbest: 238447.0764984 (0)\ttotal: 6.14ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 145234.1696\n",
      "bestIteration = 295\n",
      "\n",
      "Shrink model to first 296 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 221293.2591995\ttest: 221293.2591995\ttest1: 196583.7699044\tbest: 196583.7699044 (0)\ttotal: 5.84ms\tremaining: 58.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 114444.1466\n",
      "bestIteration = 235\n",
      "\n",
      "Shrink model to first 236 iterations.\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 217396.9230829\ttest: 217396.9230829\ttest1: 207567.1720798\tbest: 207567.1720798 (0)\ttotal: 7.21ms\tremaining: 1m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 133940.1263\n",
      "bestIteration = 181\n",
      "\n",
      "Shrink model to first 182 iterations.\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 145234.16964449149\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 114444.1465929016\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 133940.12625246524\n",
      "\n",
      "\n",
      "Average Val MAE: 130715.64087846105\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 219587.6732037\ttest: 219587.6732037\ttest1: 260334.0315874\tbest: 260334.0315874 (0)\ttotal: 4.64ms\tremaining: 46.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 149758.7867\n",
      "bestIteration = 189\n",
      "\n",
      "Shrink model to first 190 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 229802.7898829\ttest: 229802.7898829\ttest1: 236902.6493946\tbest: 236902.6493946 (0)\ttotal: 6.05ms\tremaining: 1m\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 123990.6604\n",
      "bestIteration = 285\n",
      "\n",
      "Shrink model to first 286 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 247895.3808954\ttest: 247895.3808954\ttest1: 203038.5259859\tbest: 203038.5259859 (0)\ttotal: 5.19ms\tremaining: 51.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115110.6558\n",
      "bestIteration = 117\n",
      "\n",
      "Shrink model to first 118 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 220896.3878219\ttest: 220896.3878219\ttest1: 208164.3294044\tbest: 208164.3294044 (0)\ttotal: 4.77ms\tremaining: 47.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128284.9003\n",
      "bestIteration = 210\n",
      "\n",
      "Shrink model to first 211 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 198052.9585662\ttest: 198052.9585662\ttest1: 255474.9994381\tbest: 255474.9994381 (0)\ttotal: 4.95ms\tremaining: 49.5s\n",
      "500:\tlearn: 92089.3162947\ttest: 92089.3162947\ttest1: 135029.0044774\tbest: 135026.3919754 (499)\ttotal: 2.45s\tremaining: 46.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 134620.9763\n",
      "bestIteration = 533\n",
      "\n",
      "Shrink model to first 534 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 232245.7008667\ttest: 232245.7008667\ttest1: 187978.5087499\tbest: 187978.5087499 (0)\ttotal: 5.1ms\tremaining: 51s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115014.8365\n",
      "bestIteration = 116\n",
      "\n",
      "Shrink model to first 117 iterations.\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 194630.4831437\ttest: 194630.4831437\ttest1: 215097.1972330\tbest: 215097.1972330 (0)\ttotal: 4.96ms\tremaining: 49.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 137807.3508\n",
      "bestIteration = 249\n",
      "\n",
      "Shrink model to first 250 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 208811.8949706\ttest: 208811.8949706\ttest1: 185870.9219248\tbest: 185870.9219248 (0)\ttotal: 5.23ms\tremaining: 52.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 103873.7732\n",
      "bestIteration = 217\n",
      "\n",
      "Shrink model to first 218 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 199968.2648428\ttest: 199968.2648428\ttest1: 203644.8498543\tbest: 203644.8498543 (0)\ttotal: 4.94ms\tremaining: 49.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119419.0763\n",
      "bestIteration = 257\n",
      "\n",
      "Shrink model to first 258 iterations.\n",
      "Elapsed 0.22 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 197129.6079436\ttest: 197129.6079436\ttest1: 215257.0224804\tbest: 215257.0224804 (0)\ttotal: 5.06ms\tremaining: 50.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 127346.7215\n",
      "bestIteration = 313\n",
      "\n",
      "Shrink model to first 314 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 205208.8220523\ttest: 205208.8220523\ttest1: 197098.5423844\tbest: 197098.5423844 (0)\ttotal: 6.19ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 118748.4025\n",
      "bestIteration = 225\n",
      "\n",
      "Shrink model to first 226 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 205003.3990237\ttest: 205003.3990237\ttest1: 196272.1043823\tbest: 196272.1043823 (0)\ttotal: 6.54ms\tremaining: 1m 5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 114262.9387\n",
      "bestIteration = 165\n",
      "\n",
      "Shrink model to first 166 iterations.\n",
      "Elapsed 0.29 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 128848.24980143954\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 125850.9087122443\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 119740.95944517804\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 119839.995915134\n",
      "\n",
      "\n",
      "Average Val MAE: 123570.02846849938\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 127125\tvalid_1's l1: 144056\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 133138\tvalid_1's l1: 133468\n",
      "Early stopping, best iteration is:\n",
      "[725]\ttraining's l1: 130447\tvalid_1's l1: 131771\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[465]\ttraining's l1: 131470\tvalid_1's l1: 142031\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 144055.50365578433\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 131770.82134631934\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 142031.00939396638\n",
      "\n",
      "\n",
      "Average Val MAE: 139125.65792277988\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:202816.88101\tvalidation_1-mae:240118.31858\n",
      "[118]\tvalidation_0-mae:117574.10141\tvalidation_1-mae:132510.29506\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:222531.46926\tvalidation_1-mae:198145.13064\n",
      "[79]\tvalidation_0-mae:123769.22003\tvalidation_1-mae:124211.18182\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:217786.81456\tvalidation_1-mae:207250.40412\n",
      "[87]\tvalidation_0-mae:120864.41866\tvalidation_1-mae:126772.28526\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 132390.390922571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 123912.98475435765\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 126578.07124545505\n",
      "\n",
      "\n",
      "Average Val MAE: 127453.34425824563\n",
      "Blended MAE: 130076.94248611356\n",
      "Walk forward MAE:  78364.23307283546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94855b34bd7f40f29ee3740c4a891634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1054 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010a4ca6995946a193ca800866736ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[447]\ttraining's l1: 72277.7\tvalid_1's l1: 151805\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 72314.6\tvalid_1's l1: 128564\n",
      "Early stopping, best iteration is:\n",
      "[684]\ttraining's l1: 61427.9\tvalid_1's l1: 126670\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[483]\ttraining's l1: 69142.4\tvalid_1's l1: 151023\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttraining's l1: 75751\tvalid_1's l1: 134644\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 64012.2\tvalid_1's l1: 153512\n",
      "Early stopping, best iteration is:\n",
      "[718]\ttraining's l1: 52633.1\tvalid_1's l1: 151741\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[445]\ttraining's l1: 78276.7\tvalid_1's l1: 140403\n",
      "Elapsed 0.23 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 70975.1\tvalid_1's l1: 131210\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's l1: 67993.3\tvalid_1's l1: 130756\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 66368.5\tvalid_1's l1: 143617\n",
      "Early stopping, best iteration is:\n",
      "[548]\ttraining's l1: 63046\tvalid_1's l1: 143228\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[403]\ttraining's l1: 77645.9\tvalid_1's l1: 147656\n",
      "Elapsed 0.34 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 64764\tvalid_1's l1: 144840\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttraining's l1: 62896.8\tvalid_1's l1: 144641\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 70599.4\tvalid_1's l1: 114601\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttraining's l1: 68461.5\tvalid_1's l1: 114288\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 64432.2\tvalid_1's l1: 150856\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's l1: 61027.8\tvalid_1's l1: 150395\n",
      "Elapsed 0.46 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 143290.69878747658\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 142200.05165328292\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 140555.23312109703\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 136620.47974534912\n",
      "\n",
      "\n",
      "Average Val MAE: 140666.61582680664\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:227654.83466\tvalidation_1-mae:233736.52177\n",
      "[111]\tvalidation_0-mae:124301.01371\tvalidation_1-mae:138938.91654\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:243877.49247\tvalidation_1-mae:199986.74906\n",
      "[91]\tvalidation_0-mae:135317.72041\tvalidation_1-mae:120658.36583\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:217012.44525\tvalidation_1-mae:254219.77666\n",
      "[96]\tvalidation_0-mae:120476.19173\tvalidation_1-mae:149218.73240\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 138780.49886022334\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 120442.96097333643\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 148960.61560696273\n",
      "\n",
      "\n",
      "Average Val MAE: 136197.99473858566\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 226907.4391131\ttest: 226907.4391131\ttest1: 232109.0707036\tbest: 232109.0707036 (0)\ttotal: 8.3ms\tremaining: 1m 22s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 135157.5407\n",
      "bestIteration = 234\n",
      "\n",
      "Shrink model to first 235 iterations.\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 242724.7899634\ttest: 242724.7899634\ttest1: 199765.7960392\tbest: 199765.7960392 (0)\ttotal: 8.25ms\tremaining: 1m 22s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117808.0692\n",
      "bestIteration = 172\n",
      "\n",
      "Shrink model to first 173 iterations.\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 216413.2517041\ttest: 216413.2517041\ttest1: 254150.1435389\tbest: 254150.1435389 (0)\ttotal: 7.25ms\tremaining: 1m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 145532.1398\n",
      "bestIteration = 223\n",
      "\n",
      "Shrink model to first 224 iterations.\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 135157.540720747\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 117808.06916435798\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 145532.13978017212\n",
      "\n",
      "\n",
      "Average Val MAE: 132965.01597591006\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:236986.78320\tvalidation_1-mae:257352.15880\n",
      "[112]\tvalidation_0-mae:91801.81544\tvalidation_1-mae:151993.72829\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:252656.16983\tvalidation_1-mae:224857.78261\n",
      "[80]\tvalidation_0-mae:110214.53044\tvalidation_1-mae:129963.31343\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:241329.48179\tvalidation_1-mae:248876.77905\n",
      "[136]\tvalidation_0-mae:89958.27338\tvalidation_1-mae:146803.13319\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:237661.62267\tvalidation_1-mae:229373.33757\n",
      "[94]\tvalidation_0-mae:106466.28745\tvalidation_1-mae:151429.45302\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:215256.78319\tvalidation_1-mae:276397.49010\n",
      "[191]\tvalidation_0-mae:78899.96875\tvalidation_1-mae:157483.23525\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:252443.67423\tvalidation_1-mae:199461.84179\n",
      "[63]\tvalidation_0-mae:125754.96617\tvalidation_1-mae:122054.64366\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:235880.97566\tvalidation_1-mae:205265.52640\n",
      "[90]\tvalidation_0-mae:106365.26130\tvalidation_1-mae:138362.97450\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:221111.91694\tvalidation_1-mae:234846.02190\n",
      "[118]\tvalidation_0-mae:90954.92588\tvalidation_1-mae:142211.04516\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:219843.28035\tvalidation_1-mae:237219.03021\n",
      "[111]\tvalidation_0-mae:98067.09380\tvalidation_1-mae:137783.59493\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:211687.65925\tvalidation_1-mae:220082.18702\n",
      "[180]\tvalidation_0-mae:82833.98741\tvalidation_1-mae:144986.77346\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:230942.14253\tvalidation_1-mae:179070.49851\n",
      "[70]\tvalidation_0-mae:112839.85736\tvalidation_1-mae:105816.27222\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:199842.54554\tvalidation_1-mae:242564.52604\n",
      "[117]\tvalidation_0-mae:89421.73304\tvalidation_1-mae:137701.08801\n",
      "Elapsed 0.26 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 142756.99531676827\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 143222.8084240189\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 139103.06567366153\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 129424.15525200969\n",
      "\n",
      "\n",
      "Average Val MAE: 138626.7561666146\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 137032\tvalid_1's l1: 148161\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's l1: 145830\tvalid_1's l1: 141503\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 131052\tvalid_1's l1: 166525\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 148161.05287912497\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 141503.17819514556\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 166525.258607733\n",
      "\n",
      "\n",
      "Average Val MAE: 152175.13060824753\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 226919.0403823\ttest: 226919.0403823\ttest1: 232200.0744405\tbest: 232200.0744405 (0)\ttotal: 8.48ms\tremaining: 1m 24s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 135759.6059\n",
      "bestIteration = 254\n",
      "\n",
      "Shrink model to first 255 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 242547.5442517\ttest: 242547.5442517\ttest1: 199578.6084965\tbest: 199578.6084965 (0)\ttotal: 8.11ms\tremaining: 1m 21s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121431.0196\n",
      "bestIteration = 177\n",
      "\n",
      "Shrink model to first 178 iterations.\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 215813.4043818\ttest: 215813.4043818\ttest1: 253483.5975858\tbest: 253483.5975858 (0)\ttotal: 9.62ms\tremaining: 1m 36s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 147057.3564\n",
      "bestIteration = 262\n",
      "\n",
      "Shrink model to first 263 iterations.\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 135759.6058575609\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 121431.01955727903\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 147057.356372085\n",
      "\n",
      "\n",
      "Average Val MAE: 134870.30509586568\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 235577.7335430\ttest: 235577.7335430\ttest1: 255341.5881000\tbest: 255341.5881000 (0)\ttotal: 5.08ms\tremaining: 50.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 139605.5392\n",
      "bestIteration = 171\n",
      "\n",
      "Shrink model to first 172 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 251315.2270339\ttest: 251315.2270339\ttest1: 224035.6259014\tbest: 224035.6259014 (0)\ttotal: 8.23ms\tremaining: 1m 22s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121445.9317\n",
      "bestIteration = 207\n",
      "\n",
      "Shrink model to first 208 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 239769.3907805\ttest: 239769.3907805\ttest1: 247136.0095699\tbest: 247136.0095699 (0)\ttotal: 6.42ms\tremaining: 1m 4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 146516.9787\n",
      "bestIteration = 176\n",
      "\n",
      "Shrink model to first 177 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 236073.6635699\ttest: 236073.6635699\ttest1: 228433.4140473\tbest: 228433.4140473 (0)\ttotal: 5.2ms\tremaining: 52s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124491.9939\n",
      "bestIteration = 271\n",
      "\n",
      "Shrink model to first 272 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 213810.8668570\ttest: 213810.8668570\ttest1: 274168.2694606\tbest: 274168.2694606 (0)\ttotal: 5.62ms\tremaining: 56.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 153621.186\n",
      "bestIteration = 347\n",
      "\n",
      "Shrink model to first 348 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 251031.8414799\ttest: 251031.8414799\ttest1: 199205.9492235\tbest: 199205.9492235 (0)\ttotal: 5.78ms\tremaining: 57.8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115942.4838\n",
      "bestIteration = 168\n",
      "\n",
      "Shrink model to first 169 iterations.\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 234457.4893895\ttest: 234457.4893895\ttest1: 203140.9010182\tbest: 203140.9010182 (0)\ttotal: 5.21ms\tremaining: 52.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115139.6608\n",
      "bestIteration = 301\n",
      "\n",
      "Shrink model to first 302 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 220447.8000249\ttest: 220447.8000249\ttest1: 234280.9724915\tbest: 234280.9724915 (0)\ttotal: 5.58ms\tremaining: 55.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 147352.0206\n",
      "bestIteration = 222\n",
      "\n",
      "Shrink model to first 223 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 219105.9108136\ttest: 219105.9108136\ttest1: 236616.9873229\tbest: 236616.9873229 (0)\ttotal: 6.76ms\tremaining: 1m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 139887.7176\n",
      "bestIteration = 224\n",
      "\n",
      "Shrink model to first 225 iterations.\n",
      "Elapsed 0.22 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 211023.5246480\ttest: 211023.5246480\ttest1: 218861.7063848\tbest: 218861.7063848 (0)\ttotal: 6.17ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130734.4319\n",
      "bestIteration = 289\n",
      "\n",
      "Shrink model to first 290 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 230453.1224384\ttest: 230453.1224384\ttest1: 178668.6865500\tbest: 178668.6865500 (0)\ttotal: 7.77ms\tremaining: 1m 17s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 107147.4195\n",
      "bestIteration = 170\n",
      "\n",
      "Shrink model to first 171 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 198963.9055315\ttest: 198963.9055315\ttest1: 242208.2638244\tbest: 242208.2638244 (0)\ttotal: 6.65ms\tremaining: 1m 6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 133286.1824\n",
      "bestIteration = 339\n",
      "\n",
      "Shrink model to first 340 iterations.\n",
      "Elapsed 0.31 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 135977.9841521219\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 131167.2428441179\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 134067.6825959995\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 123853.609110991\n",
      "\n",
      "\n",
      "Average Val MAE: 131266.6296758085\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 139932\tvalid_1's l1: 143447\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 146590\tvalid_1's l1: 139974\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 145532\tvalid_1's l1: 139236\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 132979\tvalid_1's l1: 163358\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 143446.59761356376\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 139236.42291724842\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 163357.9365425211\n",
      "\n",
      "\n",
      "Average Val MAE: 148786.4023393538\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:227639.28324\tvalidation_1-mae:233456.49834\n",
      "[91]\tvalidation_0-mae:129070.02155\tvalidation_1-mae:135312.51752\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:243841.97489\tvalidation_1-mae:200080.91922\n",
      "[78]\tvalidation_0-mae:136273.76814\tvalidation_1-mae:126728.27554\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:216994.23974\tvalidation_1-mae:254626.84984\n",
      "[100]\tvalidation_0-mae:122229.18655\tvalidation_1-mae:149399.73432\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 135207.13275028573\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126524.55360873729\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 149302.6860139192\n",
      "\n",
      "\n",
      "Average Val MAE: 137115.5854160311\n",
      "Blended MAE: 132718.15932442126\n",
      "Walk forward MAE:  113908.78268623159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616012f6c831451682e4897d7d253df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c0439451f34c00875851be8c247034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's l1: 94380.4\tvalid_1's l1: 155853\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 74094.9\tvalid_1's l1: 131230\n",
      "Early stopping, best iteration is:\n",
      "[629]\ttraining's l1: 65942.7\tvalid_1's l1: 130079\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[417]\ttraining's l1: 81660.1\tvalid_1's l1: 141387\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 77650.5\tvalid_1's l1: 125069\n",
      "Early stopping, best iteration is:\n",
      "[595]\ttraining's l1: 71104.4\tvalid_1's l1: 123858\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 65372.2\tvalid_1's l1: 171520\n",
      "Early stopping, best iteration is:\n",
      "[576]\ttraining's l1: 60667.3\tvalid_1's l1: 170731\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's l1: 81978.6\tvalid_1's l1: 138157\n",
      "Elapsed 0.21 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[380]\ttraining's l1: 82979\tvalid_1's l1: 130161\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 70961.4\tvalid_1's l1: 126507\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttraining's l1: 64718.9\tvalid_1's l1: 125769\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 65358.6\tvalid_1's l1: 148273\n",
      "Early stopping, best iteration is:\n",
      "[584]\ttraining's l1: 60244.3\tvalid_1's l1: 147610\n",
      "Elapsed 0.32 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's l1: 65530.3\tvalid_1's l1: 142731\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 67757.8\tvalid_1's l1: 127361\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's l1: 60518.1\tvalid_1's l1: 126209\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's l1: 80223.1\tvalid_1's l1: 146971\n",
      "Elapsed 0.43 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 142178.19769158392\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 144804.10576958527\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 134336.39040745219\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 138379.57731382153\n",
      "\n",
      "\n",
      "Average Val MAE: 139924.56779560872\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:235410.99589\tvalidation_1-mae:216902.48369\n",
      "[92]\tvalidation_0-mae:129437.74051\tvalidation_1-mae:125349.17979\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:239462.23212\tvalidation_1-mae:210495.76657\n",
      "[99]\tvalidation_0-mae:129215.57026\tvalidation_1-mae:126606.90905\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:213593.03955\tvalidation_1-mae:262116.88735\n",
      "[111]\tvalidation_0-mae:118156.53770\tvalidation_1-mae:148653.59260\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 125225.03997058152\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126468.02685237142\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 148614.4010391064\n",
      "\n",
      "\n",
      "Average Val MAE: 133297.80919800198\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 233743.4225184\ttest: 233743.4225184\ttest1: 215625.3107015\tbest: 215625.3107015 (0)\ttotal: 9.58ms\tremaining: 1m 35s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 122933.8286\n",
      "bestIteration = 211\n",
      "\n",
      "Shrink model to first 212 iterations.\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 238384.3637156\ttest: 238384.3637156\ttest1: 209464.3769370\tbest: 209464.3769370 (0)\ttotal: 8.15ms\tremaining: 1m 21s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120320.5635\n",
      "bestIteration = 350\n",
      "\n",
      "Shrink model to first 351 iterations.\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 212312.5550317\ttest: 212312.5550317\ttest1: 260606.4910694\tbest: 260606.4910694 (0)\ttotal: 9.66ms\tremaining: 1m 36s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 146796.3466\n",
      "bestIteration = 247\n",
      "\n",
      "Shrink model to first 248 iterations.\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 122933.8285656729\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 120320.56353151739\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 146796.34655724157\n",
      "\n",
      "\n",
      "Average Val MAE: 129822.263528805\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:247406.23120\tvalidation_1-mae:263173.26624\n",
      "[117]\tvalidation_0-mae:99119.67966\tvalidation_1-mae:146033.13265\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:254107.24835\tvalidation_1-mae:249159.53184\n",
      "[92]\tvalidation_0-mae:106595.28310\tvalidation_1-mae:136151.11632\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:256113.42199\tvalidation_1-mae:245104.00103\n",
      "[105]\tvalidation_0-mae:101500.78310\tvalidation_1-mae:131720.52422\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:245711.41862\tvalidation_1-mae:217876.27962\n",
      "[84]\tvalidation_0-mae:116334.39923\tvalidation_1-mae:123219.55533\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:208140.77415\tvalidation_1-mae:292146.76949\n",
      "[200]\tvalidation_0-mae:82629.68328\tvalidation_1-mae:171598.04206\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:255474.14743\tvalidation_1-mae:197129.88941\n",
      "[69]\tvalidation_0-mae:122672.80950\tvalidation_1-mae:119195.34314\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:225774.21721\tvalidation_1-mae:207914.71320\n",
      "[101]\tvalidation_0-mae:102985.07162\tvalidation_1-mae:126102.43999\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:227920.00491\tvalidation_1-mae:204534.38843\n",
      "[74]\tvalidation_0-mae:111951.97126\tvalidation_1-mae:126960.37246\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:206478.23838\tvalidation_1-mae:248646.75668\n",
      "[137]\tvalidation_0-mae:88809.68552\tvalidation_1-mae:149705.09124\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:208554.10453\tvalidation_1-mae:208568.51255\n",
      "[98]\tvalidation_0-mae:94638.96250\tvalidation_1-mae:140378.93363\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:213404.13165\tvalidation_1-mae:199609.59293\n",
      "[128]\tvalidation_0-mae:91035.34207\tvalidation_1-mae:127325.52493\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:203699.33260\tvalidation_1-mae:217763.67937\n",
      "[74]\tvalidation_0-mae:103097.13552\tvalidation_1-mae:126223.83786\n",
      "Elapsed 0.27 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 137699.1415908084\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 138232.75539921125\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 133975.4044019516\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 130860.47157223606\n",
      "\n",
      "\n",
      "Average Val MAE: 135191.94324105183\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 140032\tvalid_1's l1: 139628\n",
      "Early stopping, best iteration is:\n",
      "[652]\ttraining's l1: 137716\tvalid_1's l1: 137685\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 141696\tvalid_1's l1: 136413\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's l1: 140460\tvalid_1's l1: 135691\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 129131\tvalid_1's l1: 166100\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 137685.01544946272\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 135691.19521666877\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 166100.4504417722\n",
      "\n",
      "\n",
      "Average Val MAE: 146275.94228453108\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 234134.6824652\ttest: 234134.6824652\ttest1: 215920.9101383\tbest: 215920.9101383 (0)\ttotal: 9.21ms\tremaining: 1m 32s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 122573.5016\n",
      "bestIteration = 278\n",
      "\n",
      "Shrink model to first 279 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 238310.8783177\ttest: 238310.8783177\ttest1: 209403.8817483\tbest: 209403.8817483 (0)\ttotal: 8.69ms\tremaining: 1m 26s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121027.1301\n",
      "bestIteration = 421\n",
      "\n",
      "Shrink model to first 422 iterations.\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 212538.9902800\ttest: 212538.9902800\ttest1: 260868.6051691\tbest: 260868.6051691 (0)\ttotal: 8.55ms\tremaining: 1m 25s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 148547.7116\n",
      "bestIteration = 255\n",
      "\n",
      "Shrink model to first 256 iterations.\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 122573.50161029465\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 121027.13009132985\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 148547.71155582386\n",
      "\n",
      "\n",
      "Average Val MAE: 130522.24812438714\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 244861.5068735\ttest: 244861.5068735\ttest1: 261140.7783145\tbest: 261140.7783145 (0)\ttotal: 6.14ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 138437.4585\n",
      "bestIteration = 214\n",
      "\n",
      "Shrink model to first 215 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 251643.1002492\ttest: 251643.1002492\ttest1: 246443.2652500\tbest: 246443.2652500 (0)\ttotal: 5.67ms\tremaining: 56.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 126294.2769\n",
      "bestIteration = 449\n",
      "\n",
      "Shrink model to first 450 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 253414.7944725\ttest: 253414.7944725\ttest1: 243005.6818738\tbest: 243005.6818738 (0)\ttotal: 5.56ms\tremaining: 55.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 137209.0306\n",
      "bestIteration = 154\n",
      "\n",
      "Shrink model to first 155 iterations.\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 244039.1884085\ttest: 244039.1884085\ttest1: 216588.7404083\tbest: 216588.7404083 (0)\ttotal: 5.03ms\tremaining: 50.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116010.323\n",
      "bestIteration = 472\n",
      "\n",
      "Shrink model to first 473 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 206749.0563702\ttest: 206749.0563702\ttest1: 289831.6777365\tbest: 289831.6777365 (0)\ttotal: 5.81ms\tremaining: 58.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 165238.8567\n",
      "bestIteration = 440\n",
      "\n",
      "Shrink model to first 441 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 253789.2634355\ttest: 253789.2634355\ttest1: 196802.8429185\tbest: 196802.8429185 (0)\ttotal: 6ms\tremaining: 1m\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 122876.9357\n",
      "bestIteration = 101\n",
      "\n",
      "Shrink model to first 102 iterations.\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 224093.4308469\ttest: 224093.4308469\ttest1: 206189.9483430\tbest: 206189.9483430 (0)\ttotal: 5.79ms\tremaining: 57.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 112901.5463\n",
      "bestIteration = 425\n",
      "\n",
      "Shrink model to first 426 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 226755.5315348\ttest: 226755.5315348\ttest1: 203113.8120773\tbest: 203113.8120773 (0)\ttotal: 6.49ms\tremaining: 1m 4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 112785.392\n",
      "bestIteration = 218\n",
      "\n",
      "Shrink model to first 219 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 205067.5117566\ttest: 205067.5117566\ttest1: 247286.2840883\tbest: 247286.2840883 (0)\ttotal: 6.8ms\tremaining: 1m 8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 142703.713\n",
      "bestIteration = 342\n",
      "\n",
      "Shrink model to first 343 iterations.\n",
      "Elapsed 0.30 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 207690.1633047\ttest: 207690.1633047\ttest1: 207685.1289114\tbest: 207685.1289114 (0)\ttotal: 6.01ms\tremaining: 1m\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129885.8661\n",
      "bestIteration = 187\n",
      "\n",
      "Shrink model to first 188 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 212750.8061687\ttest: 212750.8061687\ttest1: 198187.1621374\tbest: 198187.1621374 (0)\ttotal: 6.28ms\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120119.6473\n",
      "bestIteration = 214\n",
      "\n",
      "Shrink model to first 215 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 203021.5520440\ttest: 203021.5520440\ttest1: 218853.8482313\tbest: 218853.8482313 (0)\ttotal: 7.31ms\tremaining: 1m 13s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121048.6866\n",
      "bestIteration = 312\n",
      "\n",
      "Shrink model to first 313 iterations.\n",
      "Elapsed 0.38 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 133819.9554193638\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 135346.0390766286\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 122597.44824126494\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 123607.91365884065\n",
      "\n",
      "\n",
      "Average Val MAE: 128842.83909902535\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 139719\tvalid_1's l1: 142142\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 138906\tvalid_1's l1: 141604\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 142054\tvalid_1's l1: 140023\n",
      "Early stopping, best iteration is:\n",
      "[686]\ttraining's l1: 139636\tvalid_1's l1: 138049\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's l1: 132281\tvalid_1's l1: 163168\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 141603.66500042655\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 138048.60088297384\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 163167.70465239152\n",
      "\n",
      "\n",
      "Average Val MAE: 147414.1996496475\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:235376.63126\tvalidation_1-mae:216949.82191\n",
      "[89]\tvalidation_0-mae:129969.98879\tvalidation_1-mae:127828.27419\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:239432.02649\tvalidation_1-mae:210430.64078\n",
      "[92]\tvalidation_0-mae:132011.38148\tvalidation_1-mae:126579.57411\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:213564.60080\tvalidation_1-mae:261900.81157\n",
      "[92]\tvalidation_0-mae:121211.41252\tvalidation_1-mae:147232.94012\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 127607.43261279042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126369.7072365288\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 147038.05864400114\n",
      "\n",
      "\n",
      "Average Val MAE: 133525.58391223286\n",
      "Blended MAE: 129271.99493476943\n",
      "Walk forward MAE:  65319.87550517163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb84e703d6a4697a1733e8ae6819cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a593a1aa0f435790145cc7313c0d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[304]\ttraining's l1: 90525.6\tvalid_1's l1: 161768\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 77696.2\tvalid_1's l1: 118821\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's l1: 69129.2\tvalid_1's l1: 117264\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[441]\ttraining's l1: 79528.1\tvalid_1's l1: 136779\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[463]\ttraining's l1: 76796.5\tvalid_1's l1: 133494\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[476]\ttraining's l1: 72064.5\tvalid_1's l1: 158654\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[469]\ttraining's l1: 80221.7\tvalid_1's l1: 132198\n",
      "Elapsed 0.21 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 71003.6\tvalid_1's l1: 129575\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's l1: 67599.9\tvalid_1's l1: 128900\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[456]\ttraining's l1: 76994.6\tvalid_1's l1: 124628\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 67368.5\tvalid_1's l1: 138317\n",
      "Early stopping, best iteration is:\n",
      "[651]\ttraining's l1: 59154.5\tvalid_1's l1: 137151\n",
      "Elapsed 0.34 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 61578.5\tvalid_1's l1: 160990\n",
      "Early stopping, best iteration is:\n",
      "[536]\ttraining's l1: 59403.6\tvalid_1's l1: 160411\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 70850.5\tvalid_1's l1: 125359\n",
      "Early stopping, best iteration is:\n",
      "[613]\ttraining's l1: 63668.2\tvalid_1's l1: 124715\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's l1: 93361\tvalid_1's l1: 140723\n",
      "Elapsed 0.45 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 138717.49231587752\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 141599.5247835822\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 130088.91723541159\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 142036.08994420027\n",
      "\n",
      "\n",
      "Average Val MAE: 138110.5060697668\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:219490.48722\tvalidation_1-mae:235942.86484\n",
      "[142]\tvalidation_0-mae:123587.00163\tvalidation_1-mae:130480.38114\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:233843.65373\tvalidation_1-mae:207506.61022\n",
      "[95]\tvalidation_0-mae:127953.67665\tvalidation_1-mae:123714.54849\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:221558.40573\tvalidation_1-mae:231929.37791\n",
      "[83]\tvalidation_0-mae:122063.07711\tvalidation_1-mae:138555.16661\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 130443.10481341748\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 123544.81946562891\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 138321.74401696064\n",
      "\n",
      "\n",
      "Average Val MAE: 130623.64741457214\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 217559.5257132\ttest: 217559.5257132\ttest1: 234065.3390983\tbest: 234065.3390983 (0)\ttotal: 10.8ms\tremaining: 1m 48s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129725.1176\n",
      "bestIteration = 358\n",
      "\n",
      "Shrink model to first 359 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 232573.8831334\ttest: 232573.8831334\ttest1: 205983.4191278\tbest: 205983.4191278 (0)\ttotal: 8.96ms\tremaining: 1m 29s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119822.5853\n",
      "bestIteration = 235\n",
      "\n",
      "Shrink model to first 236 iterations.\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 220404.3468497\ttest: 220404.3468497\ttest1: 230811.1762663\tbest: 230811.1762663 (0)\ttotal: 10.3ms\tremaining: 1m 42s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 134007.6171\n",
      "bestIteration = 224\n",
      "\n",
      "Shrink model to first 225 iterations.\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 129725.11759082825\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 119822.58527367793\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 134007.6171003353\n",
      "\n",
      "\n",
      "Average Val MAE: 127739.82700980603\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:235896.63950\tvalidation_1-mae:268837.52487\n",
      "[87]\tvalidation_0-mae:101431.08596\tvalidation_1-mae:157030.59082\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:251409.18985\tvalidation_1-mae:237904.15799\n",
      "[87]\tvalidation_0-mae:112045.87531\tvalidation_1-mae:122983.79869\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:253558.91359\tvalidation_1-mae:232923.97527\n",
      "[99]\tvalidation_0-mae:103497.90017\tvalidation_1-mae:127902.03023\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:233071.30796\tvalidation_1-mae:225815.84106\n",
      "[120]\tvalidation_0-mae:101322.67376\tvalidation_1-mae:136552.86174\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:210259.55178\tvalidation_1-mae:271204.99817\n",
      "[169]\tvalidation_0-mae:90625.47730\tvalidation_1-mae:157416.04633\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:247800.71877\tvalidation_1-mae:192607.24758\n",
      "[61]\tvalidation_0-mae:126344.36432\tvalidation_1-mae:113769.92822\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:216809.47497\tvalidation_1-mae:212084.82211\n",
      "[129]\tvalidation_0-mae:94900.31851\tvalidation_1-mae:129440.06655\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:224548.81232\tvalidation_1-mae:195969.86482\n",
      "[70]\tvalidation_0-mae:113459.07568\tvalidation_1-mae:115774.43787\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:204602.55980\tvalidation_1-mae:238771.43245\n",
      "[294]\tvalidation_0-mae:80499.02532\tvalidation_1-mae:139432.17440\n",
      "Elapsed 0.25 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:191778.89083\tvalidation_1-mae:237391.70723\n",
      "[234]\tvalidation_0-mae:75529.52241\tvalidation_1-mae:161772.90990\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:216732.80555\tvalidation_1-mae:188255.30075\n",
      "[82]\tvalidation_0-mae:104804.29478\tvalidation_1-mae:111769.01972\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:212698.04964\tvalidation_1-mae:194341.00162\n",
      "[63]\tvalidation_0-mae:111385.59884\tvalidation_1-mae:113183.52253\n",
      "Elapsed 0.34 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 135968.56255738143\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 135326.78739296785\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 127641.22038847425\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 128893.07520519552\n",
      "\n",
      "\n",
      "Average Val MAE: 131957.41138600477\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 134341\tvalid_1's l1: 141021\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 133492\tvalid_1's l1: 140456\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 138026\tvalid_1's l1: 144107\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 130833\tvalid_1's l1: 151909\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 140456.15365490163\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 144106.8877789735\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 151909.13027761318\n",
      "\n",
      "\n",
      "Average Val MAE: 145350.287187857\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 218032.9599900\ttest: 218032.9599900\ttest1: 234418.4956704\tbest: 234418.4956704 (0)\ttotal: 9.71ms\tremaining: 1m 37s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129836.8373\n",
      "bestIteration = 398\n",
      "\n",
      "Shrink model to first 399 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 232610.7312814\ttest: 232610.7312814\ttest1: 206101.9937049\tbest: 206101.9937049 (0)\ttotal: 10ms\tremaining: 1m 40s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121886.0043\n",
      "bestIteration = 232\n",
      "\n",
      "Shrink model to first 233 iterations.\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 219787.5445831\ttest: 219787.5445831\ttest1: 230123.0015858\tbest: 230123.0015858 (0)\ttotal: 10ms\tremaining: 1m 39s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 134300.4954\n",
      "bestIteration = 333\n",
      "\n",
      "Shrink model to first 334 iterations.\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 129836.83732155368\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 121886.00433807474\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 134300.49541721397\n",
      "\n",
      "\n",
      "Average Val MAE: 128570.2681953289\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 233506.1698815\ttest: 233506.1698815\ttest1: 266689.3525978\tbest: 266689.3525978 (0)\ttotal: 5.83ms\tremaining: 58.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 144230.4348\n",
      "bestIteration = 200\n",
      "\n",
      "Shrink model to first 201 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 249170.0431333\ttest: 249170.0431333\ttest1: 235792.2668094\tbest: 235792.2668094 (0)\ttotal: 6.39ms\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 109561.5036\n",
      "bestIteration = 410\n",
      "\n",
      "Shrink model to first 411 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 250705.9325712\ttest: 250705.9325712\ttest1: 230496.9579084\tbest: 230496.9579084 (0)\ttotal: 6.22ms\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130325.0107\n",
      "bestIteration = 148\n",
      "\n",
      "Shrink model to first 149 iterations.\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 231851.6529337\ttest: 231851.6529337\ttest1: 224490.4116699\tbest: 224490.4116699 (0)\ttotal: 5.54ms\tremaining: 55.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129121.866\n",
      "bestIteration = 166\n",
      "\n",
      "Shrink model to first 167 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 209268.0607899\ttest: 209268.0607899\ttest1: 269315.1414674\tbest: 269315.1414674 (0)\ttotal: 5.93ms\tremaining: 59.3s\n",
      "500:\tlearn: 100471.4158929\ttest: 100471.4158929\ttest1: 148351.7204298\tbest: 148351.7204298 (500)\ttotal: 2.58s\tremaining: 49s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 147624.3599\n",
      "bestIteration = 603\n",
      "\n",
      "Shrink model to first 604 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 245816.5092901\ttest: 245816.5092901\ttest1: 191905.7314290\tbest: 191905.7314290 (0)\ttotal: 6.25ms\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116476.187\n",
      "bestIteration = 139\n",
      "\n",
      "Shrink model to first 140 iterations.\n",
      "Elapsed 0.18 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 215357.9418687\ttest: 215357.9418687\ttest1: 211211.2436865\tbest: 211211.2436865 (0)\ttotal: 5.37ms\tremaining: 53.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117704.6251\n",
      "bestIteration = 299\n",
      "\n",
      "Shrink model to first 300 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 222962.6302667\ttest: 222962.6302667\ttest1: 194335.9066733\tbest: 194335.9066733 (0)\ttotal: 5.67ms\tremaining: 56.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 102979.2427\n",
      "bestIteration = 278\n",
      "\n",
      "Shrink model to first 279 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 203001.9471291\ttest: 203001.9471291\ttest1: 236725.5824755\tbest: 236725.5824755 (0)\ttotal: 6.31ms\tremaining: 1m 3s\n",
      "500:\tlearn: 98323.9877072\ttest: 98323.9877072\ttest1: 135500.1879556\tbest: 135500.1879556 (500)\ttotal: 2.81s\tremaining: 53.2s\n",
      "1000:\tlearn: 88476.0660884\ttest: 88476.0660884\ttest1: 131042.3199726\tbest: 131042.3199726 (1000)\ttotal: 5.63s\tremaining: 50.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130499.6909\n",
      "bestIteration = 1135\n",
      "\n",
      "Shrink model to first 1136 iterations.\n",
      "Elapsed 0.36 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 190744.1922526\ttest: 190744.1922526\ttest1: 236439.6005293\tbest: 236439.6005293 (0)\ttotal: 6.15ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 147831.4802\n",
      "bestIteration = 381\n",
      "\n",
      "Shrink model to first 382 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 215983.4635738\ttest: 215983.4635738\ttest1: 186858.0656782\tbest: 186858.0656782 (0)\ttotal: 6.36ms\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 110421.2685\n",
      "bestIteration = 199\n",
      "\n",
      "Shrink model to first 200 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 211618.2518717\ttest: 211618.2518717\ttest1: 193991.2741922\tbest: 193991.2741922 (0)\ttotal: 7.58ms\tremaining: 1m 15s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 104684.3377\n",
      "bestIteration = 192\n",
      "\n",
      "Shrink model to first 193 iterations.\n",
      "Elapsed 0.45 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 128050.00107023164\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 131348.05805393538\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 116805.1062743082\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 121383.3163992374\n",
      "\n",
      "\n",
      "Average Val MAE: 124396.62044942775\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 132518\tvalid_1's l1: 143793\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 131947\tvalid_1's l1: 143347\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 138575\tvalid_1's l1: 140225\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 137870\tvalid_1's l1: 139542\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's l1: 151065\tvalid_1's l1: 167927\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 143346.62932754515\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 139541.99017286085\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 167927.36615680528\n",
      "\n",
      "\n",
      "Average Val MAE: 149909.18733104112\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:219460.93815\tvalidation_1-mae:235785.27226\n",
      "[106]\tvalidation_0-mae:122958.63877\tvalidation_1-mae:132860.04464\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:233818.34341\tvalidation_1-mae:207459.33321\n",
      "[85]\tvalidation_0-mae:129151.45454\tvalidation_1-mae:122123.24565\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:221530.91724\tvalidation_1-mae:231830.13035\n",
      "[79]\tvalidation_0-mae:121132.58665\tvalidation_1-mae:134197.24590\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 132757.12932529385\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 121897.3018072686\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 133733.15609861157\n",
      "\n",
      "\n",
      "Average Val MAE: 129391.63674472539\n",
      "Blended MAE: 126945.47679821507\n",
      "Walk forward MAE:  59185.23411198189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f560986c0f2460d80a8e560423bc88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88ea0d6b7314f3dbc4b2a506779d8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttraining's l1: 81626.8\tvalid_1's l1: 143121\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 73680.7\tvalid_1's l1: 131020\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's l1: 68672.1\tvalid_1's l1: 130012\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[432]\ttraining's l1: 83870.2\tvalid_1's l1: 132030\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 78302.8\tvalid_1's l1: 125936\n",
      "Early stopping, best iteration is:\n",
      "[582]\ttraining's l1: 73069.7\tvalid_1's l1: 125183\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 71852.1\tvalid_1's l1: 150319\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's l1: 63052.4\tvalid_1's l1: 148900\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 80507.8\tvalid_1's l1: 124413\n",
      "Early stopping, best iteration is:\n",
      "[559]\ttraining's l1: 76483.3\tvalid_1's l1: 123989\n",
      "Elapsed 0.25 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 69918.7\tvalid_1's l1: 135734\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's l1: 66730.9\tvalid_1's l1: 135111\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 79413.1\tvalid_1's l1: 113939\n",
      "Early stopping, best iteration is:\n",
      "[561]\ttraining's l1: 75120.4\tvalid_1's l1: 113372\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 71558.3\tvalid_1's l1: 136410\n",
      "Early stopping, best iteration is:\n",
      "[565]\ttraining's l1: 67589\tvalid_1's l1: 135872\n",
      "Elapsed 0.38 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 67549.6\tvalid_1's l1: 135327\n",
      "Early stopping, best iteration is:\n",
      "[515]\ttraining's l1: 66614.8\tvalid_1's l1: 135175\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 72903\tvalid_1's l1: 117992\n",
      "Early stopping, best iteration is:\n",
      "[584]\ttraining's l1: 67691.4\tvalid_1's l1: 117165\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 69718.1\tvalid_1's l1: 138478\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttraining's l1: 68052.1\tvalid_1's l1: 138249\n",
      "Elapsed 0.51 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 135031.1651300906\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 132702.00055928345\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 128107.99792300642\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 130191.11231069552\n",
      "\n",
      "\n",
      "Average Val MAE: 131508.06898076928\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:239666.58940\tvalidation_1-mae:202722.85934\n",
      "[91]\tvalidation_0-mae:127995.89345\tvalidation_1-mae:116455.05800\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:223754.43676\tvalidation_1-mae:234837.47190\n",
      "[106]\tvalidation_0-mae:122108.74521\tvalidation_1-mae:128491.33542\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:218907.37702\tvalidation_1-mae:244562.68344\n",
      "[101]\tvalidation_0-mae:116175.23022\tvalidation_1-mae:139491.00995\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 116245.98943033279\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 128330.7800713707\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 139364.63317757583\n",
      "\n",
      "\n",
      "Average Val MAE: 128020.54531874658\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 237890.7749781\ttest: 237890.7749781\ttest1: 201809.3094285\tbest: 201809.3094285 (0)\ttotal: 10.7ms\tremaining: 1m 46s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 111954.4619\n",
      "bestIteration = 193\n",
      "\n",
      "Shrink model to first 194 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 221836.1497692\ttest: 221836.1497692\ttest1: 232527.6999104\tbest: 232527.6999104 (0)\ttotal: 11.5ms\tremaining: 1m 54s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124826.0658\n",
      "bestIteration = 267\n",
      "\n",
      "Shrink model to first 268 iterations.\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 216874.4895021\ttest: 216874.4895021\ttest1: 242338.2296963\tbest: 242338.2296963 (0)\ttotal: 10.5ms\tremaining: 1m 45s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 134714.3989\n",
      "bestIteration = 301\n",
      "\n",
      "Shrink model to first 302 iterations.\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 111954.46187905337\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 124826.06579486869\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 134714.39888525128\n",
      "\n",
      "\n",
      "Average Val MAE: 123871.62146996275\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:238189.28937\tvalidation_1-mae:258226.36584\n",
      "[82]\tvalidation_0-mae:106619.69553\tvalidation_1-mae:139694.61301\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:240942.96836\tvalidation_1-mae:252632.29699\n",
      "[160]\tvalidation_0-mae:90136.59423\tvalidation_1-mae:131682.85374\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:255319.55984\tvalidation_1-mae:223604.07966\n",
      "[84]\tvalidation_0-mae:112177.68865\tvalidation_1-mae:123109.54425\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:235431.45323\tvalidation_1-mae:228774.95801\n",
      "[102]\tvalidation_0-mae:108155.86597\tvalidation_1-mae:125343.57418\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:211691.22639\tvalidation_1-mae:277434.72637\n",
      "[409]\tvalidation_0-mae:79701.39094\tvalidation_1-mae:155194.79502\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:252883.85349\tvalidation_1-mae:193860.61650\n",
      "[60]\tvalidation_0-mae:128065.74965\tvalidation_1-mae:119154.75174\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:209728.46381\tvalidation_1-mae:244940.04987\n",
      "[260]\tvalidation_0-mae:81354.28208\tvalidation_1-mae:130795.88708\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:240722.27296\tvalidation_1-mae:180130.89917\n",
      "[44]\tvalidation_0-mae:137980.41743\tvalidation_1-mae:112943.34236\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:213432.67828\tvalidation_1-mae:237692.33731\n",
      "[200]\tvalidation_0-mae:88255.89887\tvalidation_1-mae:132164.96227\n",
      "Elapsed 0.33 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:209042.51557\tvalidation_1-mae:213272.65533\n",
      "[79]\tvalidation_0-mae:100369.29511\tvalidation_1-mae:129829.81830\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:220524.21914\tvalidation_1-mae:191020.10378\n",
      "[127]\tvalidation_0-mae:96040.02944\tvalidation_1-mae:118840.88582\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:202254.83257\tvalidation_1-mae:226841.41882\n",
      "[79]\tvalidation_0-mae:99977.56952\tvalidation_1-mae:131805.24706\n",
      "Elapsed 0.41 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 131260.10609782522\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 132741.73160423327\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 124792.03220891184\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 126363.42216111235\n",
      "\n",
      "\n",
      "Average Val MAE: 128789.32301802066\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 140601\tvalid_1's l1: 130098\n",
      "Elapsed 0.03 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[467]\ttraining's l1: 133732\tvalid_1's l1: 146134\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 127592\tvalid_1's l1: 156044\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 130098.16918253482\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 146133.74970227404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 156043.82017469683\n",
      "\n",
      "\n",
      "Average Val MAE: 144138.22000795015\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 237820.5252577\ttest: 237820.5252577\ttest1: 201746.7899631\tbest: 201746.7899631 (0)\ttotal: 10.7ms\tremaining: 1m 47s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 112844.6051\n",
      "bestIteration = 241\n",
      "\n",
      "Shrink model to first 242 iterations.\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 221766.5968055\ttest: 221766.5968055\ttest1: 232424.0552112\tbest: 232424.0552112 (0)\ttotal: 12ms\tremaining: 1m 59s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 126905.2756\n",
      "bestIteration = 283\n",
      "\n",
      "Shrink model to first 284 iterations.\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 217428.3430426\ttest: 217428.3430426\ttest1: 242915.9688169\tbest: 242915.9688169 (0)\ttotal: 9.84ms\tremaining: 1m 38s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 137077.0293\n",
      "bestIteration = 387\n",
      "\n",
      "Shrink model to first 388 iterations.\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 112844.60506388868\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126905.27558400242\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 137077.02930859796\n",
      "\n",
      "\n",
      "Average Val MAE: 125651.72718820524\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 235472.7772165\ttest: 235472.7772165\ttest1: 255543.9910082\tbest: 255543.9910082 (0)\ttotal: 5.41ms\tremaining: 54.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 132840.6909\n",
      "bestIteration = 246\n",
      "\n",
      "Shrink model to first 247 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 238159.3393873\ttest: 238159.3393873\ttest1: 249644.8524041\tbest: 249644.8524041 (0)\ttotal: 7.62ms\tremaining: 1m 16s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128879.2357\n",
      "bestIteration = 467\n",
      "\n",
      "Shrink model to first 468 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 252726.3030878\ttest: 252726.3030878\ttest1: 221533.0254540\tbest: 221533.0254540 (0)\ttotal: 6.15ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121923.8611\n",
      "bestIteration = 149\n",
      "\n",
      "Shrink model to first 150 iterations.\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 233413.9530622\ttest: 233413.9530622\ttest1: 227464.6297851\tbest: 227464.6297851 (0)\ttotal: 6.2ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 118456.6272\n",
      "bestIteration = 256\n",
      "\n",
      "Shrink model to first 257 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 209836.0860630\ttest: 209836.0860630\ttest1: 275075.0250414\tbest: 275075.0250414 (0)\ttotal: 6.29ms\tremaining: 1m 2s\n",
      "500:\tlearn: 99127.8387275\ttest: 99127.8387275\ttest1: 149567.9666386\tbest: 149567.9666386 (500)\ttotal: 2.68s\tremaining: 50.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 146991.1702\n",
      "bestIteration = 755\n",
      "\n",
      "Shrink model to first 756 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 251214.5097617\ttest: 251214.5097617\ttest1: 192329.7437087\tbest: 192329.7437087 (0)\ttotal: 6.17ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115064.5489\n",
      "bestIteration = 158\n",
      "\n",
      "Shrink model to first 159 iterations.\n",
      "Elapsed 0.22 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 207620.4207342\ttest: 207620.4207342\ttest1: 243097.5017627\tbest: 243097.5017627 (0)\ttotal: 7.03ms\tremaining: 1m 10s\n",
      "500:\tlearn: 98914.5676592\ttest: 98914.5676592\ttest1: 130522.8587692\tbest: 130522.8587692 (500)\ttotal: 2.82s\tremaining: 53.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128615.9281\n",
      "bestIteration = 735\n",
      "\n",
      "Shrink model to first 736 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 239525.7041730\ttest: 239525.7041730\ttest1: 180186.8083209\tbest: 180186.8083209 (0)\ttotal: 6.98ms\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 103129.8704\n",
      "bestIteration = 140\n",
      "\n",
      "Shrink model to first 141 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 211674.6094337\ttest: 211674.6094337\ttest1: 235926.8145985\tbest: 235926.8145985 (0)\ttotal: 7.35ms\tremaining: 1m 13s\n",
      "500:\tlearn: 101667.5352252\ttest: 101667.5352252\ttest1: 131106.5096376\tbest: 131106.5096376 (500)\ttotal: 2.87s\tremaining: 54.4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130542.0921\n",
      "bestIteration = 541\n",
      "\n",
      "Shrink model to first 542 iterations.\n",
      "Elapsed 0.37 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 208160.7913270\ttest: 208160.7913270\ttest1: 212850.7012274\tbest: 212850.7012274 (0)\ttotal: 6.5ms\tremaining: 1m 5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 123528.7812\n",
      "bestIteration = 278\n",
      "\n",
      "Shrink model to first 279 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 219642.2106687\ttest: 219642.2106687\ttest1: 189626.2181221\tbest: 189626.2181221 (0)\ttotal: 8.21ms\tremaining: 1m 22s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 108126.5429\n",
      "bestIteration = 341\n",
      "\n",
      "Shrink model to first 342 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 201293.3242967\ttest: 201293.3242967\ttest1: 226817.9132703\tbest: 226817.9132703 (0)\ttotal: 7.07ms\tremaining: 1m 10s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121587.9187\n",
      "bestIteration = 235\n",
      "\n",
      "Shrink model to first 236 iterations.\n",
      "Elapsed 0.47 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 127863.27489363775\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 126847.84847290684\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 120751.73835133229\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 117736.65448332748\n",
      "\n",
      "\n",
      "Average Val MAE: 123299.87905030126\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 140081\tvalid_1's l1: 129241\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 133604\tvalid_1's l1: 145476\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's l1: 133179\tvalid_1's l1: 145029\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 128073\tvalid_1's l1: 155263\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 129240.71617720799\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 145028.5072401009\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 155262.70075747822\n",
      "\n",
      "\n",
      "Average Val MAE: 143223.59283914758\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:239640.28797\tvalidation_1-mae:202778.92693\n",
      "[87]\tvalidation_0-mae:128869.82016\tvalidation_1-mae:116856.35012\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:223732.63795\tvalidation_1-mae:234766.29737\n",
      "[92]\tvalidation_0-mae:123623.25399\tvalidation_1-mae:127644.81931\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:218885.04231\tvalidation_1-mae:244568.15435\n",
      "[97]\tvalidation_0-mae:117551.22439\tvalidation_1-mae:139338.16288\n",
      "Elapsed 0.18 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 116678.63867330525\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 127355.07898329517\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 139176.68366862673\n",
      "\n",
      "\n",
      "Average Val MAE: 127775.22009610417\n",
      "Blended MAE: 124122.4426945424\n",
      "Walk forward MAE:  81508.23272702575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7519f967bf924342b8d099384395dc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0c9aa786c04cd1a43353897606a7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[357]\ttraining's l1: 88217.5\tvalid_1's l1: 146606\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 77223.6\tvalid_1's l1: 128445\n",
      "Early stopping, best iteration is:\n",
      "[572]\ttraining's l1: 72806.6\tvalid_1's l1: 127820\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 80860.1\tvalid_1's l1: 125207\n",
      "Early stopping, best iteration is:\n",
      "[619]\ttraining's l1: 73734.2\tvalid_1's l1: 123820\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 81180.7\tvalid_1's l1: 129561\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's l1: 71685.2\tvalid_1's l1: 128122\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 75520.5\tvalid_1's l1: 132875\n",
      "Early stopping, best iteration is:\n",
      "[593]\ttraining's l1: 70175.2\tvalid_1's l1: 132072\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 81435.9\tvalid_1's l1: 131928\n",
      "Early stopping, best iteration is:\n",
      "[551]\ttraining's l1: 78182.8\tvalid_1's l1: 131532\n",
      "Elapsed 0.27 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 72946.8\tvalid_1's l1: 134191\n",
      "Early stopping, best iteration is:\n",
      "[639]\ttraining's l1: 65551.7\tvalid_1's l1: 132912\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 75671.4\tvalid_1's l1: 118009\n",
      "Early stopping, best iteration is:\n",
      "[628]\ttraining's l1: 68309.9\tvalid_1's l1: 117174\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 75665.6\tvalid_1's l1: 136714\n",
      "Early stopping, best iteration is:\n",
      "[604]\ttraining's l1: 69657.9\tvalid_1's l1: 136042\n",
      "Elapsed 0.42 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 68366.4\tvalid_1's l1: 134344\n",
      "Early stopping, best iteration is:\n",
      "[542]\ttraining's l1: 65963.3\tvalid_1's l1: 133843\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 72126.9\tvalid_1's l1: 121256\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttraining's l1: 65282.5\tvalid_1's l1: 119973\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttraining's l1: 96603\tvalid_1's l1: 134684\n",
      "Elapsed 0.54 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 132962.8492520151\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 130537.28602995291\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 128775.16954028013\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 129568.17502234987\n",
      "\n",
      "\n",
      "Average Val MAE: 130460.86996113638\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:242283.03085\tvalidation_1-mae:191946.65924\n",
      "[80]\tvalidation_0-mae:127624.49768\tvalidation_1-mae:114614.47269\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:217684.42638\tvalidation_1-mae:240447.66203\n",
      "[117]\tvalidation_0-mae:116394.40810\tvalidation_1-mae:128860.67209\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:215706.30908\tvalidation_1-mae:244417.03889\n",
      "[117]\tvalidation_0-mae:117713.87310\tvalidation_1-mae:130830.54352\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 114357.16058883144\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 128749.72735312939\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 130740.25216403544\n",
      "\n",
      "\n",
      "Average Val MAE: 124457.31020443958\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 239261.1165343\ttest: 239261.1165343\ttest1: 192765.4894465\tbest: 192765.4894465 (0)\ttotal: 12.5ms\tremaining: 2m 4s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 110053.493\n",
      "bestIteration = 233\n",
      "\n",
      "Shrink model to first 234 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 216208.6062456\ttest: 216208.6062456\ttest1: 237263.7580166\tbest: 237263.7580166 (0)\ttotal: 10.6ms\tremaining: 1m 46s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 126580.7031\n",
      "bestIteration = 245\n",
      "\n",
      "Shrink model to first 246 iterations.\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 213652.3067972\ttest: 213652.3067972\ttest1: 242386.3932720\tbest: 242386.3932720 (0)\ttotal: 12.1ms\tremaining: 2m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 125564.4\n",
      "bestIteration = 363\n",
      "\n",
      "Shrink model to first 364 iterations.\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 110053.49304201714\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126580.70305614572\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 125564.40002962679\n",
      "\n",
      "\n",
      "Average Val MAE: 120567.81053405607\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:239355.64054\tvalidation_1-mae:261058.64178\n",
      "[117]\tvalidation_0-mae:99507.08140\tvalidation_1-mae:137085.60752\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:239563.89720\tvalidation_1-mae:261691.38968\n",
      "[202]\tvalidation_0-mae:91123.16522\tvalidation_1-mae:129149.79299\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:261049.71057\tvalidation_1-mae:217026.52033\n",
      "[82]\tvalidation_0-mae:115058.22305\tvalidation_1-mae:121091.32645\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:234831.15745\tvalidation_1-mae:226840.74075\n",
      "[116]\tvalidation_0-mae:106592.63549\tvalidation_1-mae:125003.51176\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:218644.79542\tvalidation_1-mae:260105.01215\n",
      "[152]\tvalidation_0-mae:95132.17547\tvalidation_1-mae:135925.71295\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:243234.12153\tvalidation_1-mae:209490.99475\n",
      "[81]\tvalidation_0-mae:116078.35971\tvalidation_1-mae:123904.12866\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:210536.41056\tvalidation_1-mae:227509.66215\n",
      "[195]\tvalidation_0-mae:88716.31234\tvalidation_1-mae:129029.23905\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:226120.95051\tvalidation_1-mae:195097.56448\n",
      "[68]\tvalidation_0-mae:113870.76548\tvalidation_1-mae:119374.70237\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:211914.25058\tvalidation_1-mae:225972.51382\n",
      "[152]\tvalidation_0-mae:95094.01902\tvalidation_1-mae:134192.31256\n",
      "Elapsed 0.30 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:199520.32038\tvalidation_1-mae:215667.64696\n",
      "[90]\tvalidation_0-mae:95370.21748\tvalidation_1-mae:132303.50638\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:205658.38332\tvalidation_1-mae:205355.76993\n",
      "[232]\tvalidation_0-mae:85821.49940\tvalidation_1-mae:126548.36535\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:210760.93362\tvalidation_1-mae:193489.59700\n",
      "[68]\tvalidation_0-mae:109172.45870\tvalidation_1-mae:107089.53128\n",
      "Elapsed 0.42 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 128102.87401565819\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 128027.77206383622\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 127422.5017248023\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 121767.86977567586\n",
      "\n",
      "\n",
      "Average Val MAE: 126330.25439499314\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 137070\tvalid_1's l1: 128256\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttraining's l1: 135566\tvalid_1's l1: 126469\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's l1: 130701\tvalid_1's l1: 142375\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 126938\tvalid_1's l1: 146676\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 126325\tvalid_1's l1: 146290\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 126469.38021065548\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 142374.8244283636\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 146290.17741400094\n",
      "\n",
      "\n",
      "Average Val MAE: 138194.32328953943\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 239540.5728766\ttest: 239540.5728766\ttest1: 193013.4816843\tbest: 193013.4816843 (0)\ttotal: 11.6ms\tremaining: 1m 55s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 111345.8078\n",
      "bestIteration = 292\n",
      "\n",
      "Shrink model to first 293 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 216460.3551562\ttest: 216460.3551562\ttest1: 237541.8029937\tbest: 237541.8029937 (0)\ttotal: 11.2ms\tremaining: 1m 52s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 126502.6668\n",
      "bestIteration = 303\n",
      "\n",
      "Shrink model to first 304 iterations.\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 213810.1460229\ttest: 213810.1460229\ttest1: 242539.6134880\tbest: 242539.6134880 (0)\ttotal: 12.7ms\tremaining: 2m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130566.5068\n",
      "bestIteration = 413\n",
      "\n",
      "Shrink model to first 414 iterations.\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 111345.8078241463\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126502.66682219417\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 130566.5067608685\n",
      "\n",
      "\n",
      "Average Val MAE: 122628.14318792582\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 236304.8449492\ttest: 236304.8449492\ttest1: 257980.9165015\tbest: 257980.9165015 (0)\ttotal: 6.1ms\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129560.8722\n",
      "bestIteration = 235\n",
      "\n",
      "Shrink model to first 236 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 236478.5079195\ttest: 236478.5079195\ttest1: 258234.6301983\tbest: 258234.6301983 (0)\ttotal: 6.4ms\tremaining: 1m 3s\n",
      "500:\tlearn: 101957.8448254\ttest: 101957.8448254\ttest1: 121079.3123994\tbest: 121079.3123994 (500)\ttotal: 2.86s\tremaining: 54.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119731.1879\n",
      "bestIteration = 661\n",
      "\n",
      "Shrink model to first 662 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 257601.4179161\ttest: 257601.4179161\ttest1: 214222.0940487\tbest: 214222.0940487 (0)\ttotal: 7.11ms\tremaining: 1m 11s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119726.6696\n",
      "bestIteration = 187\n",
      "\n",
      "Shrink model to first 188 iterations.\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 232591.6730859\ttest: 232591.6730859\ttest1: 224883.0881559\tbest: 224883.0881559 (0)\ttotal: 7.1ms\tremaining: 1m 10s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 118605.718\n",
      "bestIteration = 270\n",
      "\n",
      "Shrink model to first 271 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 216789.5157226\ttest: 216789.5157226\ttest1: 258149.9812598\tbest: 258149.9812598 (0)\ttotal: 6.79ms\tremaining: 1m 7s\n",
      "500:\tlearn: 102057.7063426\ttest: 102057.7063426\ttest1: 131618.3295744\tbest: 131618.3295744 (500)\ttotal: 2.88s\tremaining: 54.5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130188.7819\n",
      "bestIteration = 660\n",
      "\n",
      "Shrink model to first 661 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 241182.6444277\ttest: 241182.6444277\ttest1: 208498.2434987\tbest: 208498.2434987 (0)\ttotal: 6.78ms\tremaining: 1m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124303.8294\n",
      "bestIteration = 153\n",
      "\n",
      "Shrink model to first 154 iterations.\n",
      "Elapsed 0.24 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 208816.5938156\ttest: 208816.5938156\ttest1: 225597.0843653\tbest: 225597.0843653 (0)\ttotal: 6.3ms\tremaining: 1m 3s\n",
      "500:\tlearn: 101488.6917358\ttest: 101488.6917358\ttest1: 121471.6150135\tbest: 121471.6150135 (500)\ttotal: 2.83s\tremaining: 53.6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120182.0948\n",
      "bestIteration = 642\n",
      "\n",
      "Shrink model to first 643 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 224381.1795451\ttest: 224381.1795451\ttest1: 193572.3307541\tbest: 193572.3307541 (0)\ttotal: 9.11ms\tremaining: 1m 31s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 108556.8768\n",
      "bestIteration = 275\n",
      "\n",
      "Shrink model to first 276 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 210020.0581280\ttest: 210020.0581280\ttest1: 223866.9869881\tbest: 223866.9869881 (0)\ttotal: 7.02ms\tremaining: 1m 10s\n",
      "500:\tlearn: 103282.3830217\ttest: 103282.3830217\ttest1: 127654.0929225\tbest: 127654.0929225 (500)\ttotal: 2.97s\tremaining: 56.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124595.1979\n",
      "bestIteration = 868\n",
      "\n",
      "Shrink model to first 869 iterations.\n",
      "Elapsed 0.44 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 198290.2411049\ttest: 198290.2411049\ttest1: 215468.3573397\tbest: 215468.3573397 (0)\ttotal: 6.86ms\tremaining: 1m 8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119037.0874\n",
      "bestIteration = 329\n",
      "\n",
      "Shrink model to first 330 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 204328.2665246\ttest: 204328.2665246\ttest1: 203700.2301452\tbest: 203700.2301452 (0)\ttotal: 7.01ms\tremaining: 1m 10s\n",
      "500:\tlearn: 99793.4778748\ttest: 99793.4778748\ttest1: 115050.7889469\tbest: 115050.7889469 (500)\ttotal: 2.96s\tremaining: 56.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 114607.9548\n",
      "bestIteration = 612\n",
      "\n",
      "Shrink model to first 613 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 209598.3249871\ttest: 209598.3249871\ttest1: 192646.2604082\tbest: 192646.2604082 (0)\ttotal: 7ms\tremaining: 1m 10s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 105951.834\n",
      "bestIteration = 182\n",
      "\n",
      "Shrink model to first 183 iterations.\n",
      "Elapsed 0.57 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 123107.51686839583\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 124276.81441749769\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 117815.99919292422\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 113288.7311977043\n",
      "\n",
      "\n",
      "Average Val MAE: 119622.2654191291\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 136571\tvalid_1's l1: 131140\n",
      "Early stopping, best iteration is:\n",
      "[652]\ttraining's l1: 135018\tvalid_1's l1: 129223\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's l1: 130340\tvalid_1's l1: 138215\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 127851\tvalid_1's l1: 146205\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 129222.91794766528\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 138214.74637372105\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 146205.4085930337\n",
      "\n",
      "\n",
      "Average Val MAE: 137747.647960018\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:242260.19710\tvalidation_1-mae:191965.67624\n",
      "[78]\tvalidation_0-mae:127300.37237\tvalidation_1-mae:115696.12917\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:217661.99897\tvalidation_1-mae:240404.11809\n",
      "[103]\tvalidation_0-mae:118986.82752\tvalidation_1-mae:125375.70390\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:215682.50951\tvalidation_1-mae:244393.98263\n",
      "[101]\tvalidation_0-mae:118116.81598\tvalidation_1-mae:132250.08702\n",
      "Elapsed 0.21 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 115373.28935143394\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 125240.04800718177\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 132140.8625855517\n",
      "\n",
      "\n",
      "Average Val MAE: 124114.57014614031\n",
      "Blended MAE: 120658.0762038573\n",
      "Walk forward MAE:  66541.42156345992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af19f5be08f47b69b4389ee25d6f95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d4832e093048408fe8fda22d62a16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\ttraining's l1: 93811.2\tvalid_1's l1: 142115\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[462]\ttraining's l1: 80157.9\tvalid_1's l1: 126384\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 80084\tvalid_1's l1: 131172\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's l1: 69934\tvalid_1's l1: 129287\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[397]\ttraining's l1: 91146.1\tvalid_1's l1: 131789\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 73319\tvalid_1's l1: 132236\n",
      "Early stopping, best iteration is:\n",
      "[530]\ttraining's l1: 71597.9\tvalid_1's l1: 131979\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 82741.2\tvalid_1's l1: 124271\n",
      "Early stopping, best iteration is:\n",
      "[503]\ttraining's l1: 82546.5\tvalid_1's l1: 124239\n",
      "Elapsed 0.25 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[347]\ttraining's l1: 92821.1\tvalid_1's l1: 140968\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 75134.3\tvalid_1's l1: 119704\n",
      "Early stopping, best iteration is:\n",
      "[606]\ttraining's l1: 69306.4\tvalid_1's l1: 118936\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 72054.7\tvalid_1's l1: 128508\n",
      "Early stopping, best iteration is:\n",
      "[792]\ttraining's l1: 59690\tvalid_1's l1: 126140\n",
      "Elapsed 0.40 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\ttraining's l1: 77560\tvalid_1's l1: 145475\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 72323.9\tvalid_1's l1: 118039\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttraining's l1: 64238.2\tvalid_1's l1: 116251\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[471]\ttraining's l1: 72414.4\tvalid_1's l1: 127676\n",
      "Elapsed 0.53 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 132668.48433766692\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 129415.93641586299\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 128751.02904573064\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 129873.44502605274\n",
      "\n",
      "\n",
      "Average Val MAE: 130177.22370633022\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:218537.12406\tvalidation_1-mae:223787.99817\n",
      "[88]\tvalidation_0-mae:115437.85174\tvalidation_1-mae:130930.77649\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:211799.87051\tvalidation_1-mae:237789.57013\n",
      "[142]\tvalidation_0-mae:114360.21606\tvalidation_1-mae:128390.73612\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:230602.90082\tvalidation_1-mae:198410.15330\n",
      "[77]\tvalidation_0-mae:125372.48492\tvalidation_1-mae:115200.47534\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 130828.02614246093\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 128293.52045975123\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 114848.9276178413\n",
      "\n",
      "\n",
      "Average Val MAE: 124814.87195195435\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 215695.0270893\ttest: 215695.0270893\ttest1: 222760.7501817\tbest: 222760.7501817 (0)\ttotal: 11.7ms\tremaining: 1m 56s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 125481.5932\n",
      "bestIteration = 319\n",
      "\n",
      "Shrink model to first 320 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 209877.1762551\ttest: 209877.1762551\ttest1: 234498.2986751\tbest: 234498.2986751 (0)\ttotal: 12ms\tremaining: 1m 59s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 125124.4204\n",
      "bestIteration = 388\n",
      "\n",
      "Shrink model to first 389 iterations.\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 228202.1484055\ttest: 228202.1484055\ttest1: 196466.5400951\tbest: 196466.5400951 (0)\ttotal: 12.3ms\tremaining: 2m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 106981.2432\n",
      "bestIteration = 207\n",
      "\n",
      "Shrink model to first 208 iterations.\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 125481.59319522059\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 125124.42036676797\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 106981.2432053781\n",
      "\n",
      "\n",
      "Average Val MAE: 119388.83104464039\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:248341.74641\tvalidation_1-mae:228496.31514\n",
      "[77]\tvalidation_0-mae:115384.80429\tvalidation_1-mae:126290.90443\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:231241.70123\tvalidation_1-mae:262759.18239\n",
      "[187]\tvalidation_0-mae:91781.56484\tvalidation_1-mae:127793.68365\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:245755.21058\tvalidation_1-mae:233974.90504\n",
      "[170]\tvalidation_0-mae:95597.06721\tvalidation_1-mae:129616.05297\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:235822.15194\tvalidation_1-mae:207482.58665\n",
      "[133]\tvalidation_0-mae:104680.18853\tvalidation_1-mae:119141.51166\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:206117.13600\tvalidation_1-mae:265472.10498\n",
      "[154]\tvalidation_0-mae:91137.43719\tvalidation_1-mae:135527.69414\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:236359.93421\tvalidation_1-mae:204466.68046\n",
      "[77]\tvalidation_0-mae:116051.77507\tvalidation_1-mae:120265.57653\n",
      "Elapsed 0.21 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:225485.59488\tvalidation_1-mae:183394.15123\n",
      "[97]\tvalidation_0-mae:104783.73052\tvalidation_1-mae:110059.29111\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:211651.87558\tvalidation_1-mae:209584.51390\n",
      "[82]\tvalidation_0-mae:104943.13342\tvalidation_1-mae:123657.44969\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:196930.58247\tvalidation_1-mae:242477.21821\n",
      "[357]\tvalidation_0-mae:80646.03960\tvalidation_1-mae:132748.77087\n",
      "Elapsed 0.37 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:216192.03999\tvalidation_1-mae:175865.93915\n",
      "[118]\tvalidation_0-mae:99389.90236\tvalidation_1-mae:110545.16748\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:199887.53366\tvalidation_1-mae:208123.18463\n",
      "[169]\tvalidation_0-mae:89833.67924\tvalidation_1-mae:125004.48652\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:191681.81776\tvalidation_1-mae:224356.44712\n",
      "[74]\tvalidation_0-mae:99054.19707\tvalidation_1-mae:122238.58970\n",
      "Elapsed 0.49 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 127769.42235307001\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 124416.75275242525\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 121459.35003217876\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 118968.30898320375\n",
      "\n",
      "\n",
      "Average Val MAE: 123153.45853021945\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 124036\tvalid_1's l1: 140899\n",
      "Early stopping, best iteration is:\n",
      "[623]\ttraining's l1: 122479\tvalid_1's l1: 139900\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 124120\tvalid_1's l1: 138430\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 123356\tvalid_1's l1: 138137\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 133579\tvalid_1's l1: 124768\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 139900.362952006\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 138136.5684051756\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 124768.33317083308\n",
      "\n",
      "\n",
      "Average Val MAE: 134420.5828657381\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 215590.4224851\ttest: 215590.4224851\ttest1: 222620.9218045\tbest: 222620.9218045 (0)\ttotal: 12.4ms\tremaining: 2m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 125200.2025\n",
      "bestIteration = 259\n",
      "\n",
      "Shrink model to first 260 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 210132.5562854\ttest: 210132.5562854\ttest1: 234720.8468791\tbest: 234720.8468791 (0)\ttotal: 11.9ms\tremaining: 1m 58s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 125263.3839\n",
      "bestIteration = 292\n",
      "\n",
      "Shrink model to first 293 iterations.\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 228061.9411899\ttest: 228061.9411899\ttest1: 196362.5621669\tbest: 196362.5621669 (0)\ttotal: 12.7ms\tremaining: 2m 6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 107139.9633\n",
      "bestIteration = 363\n",
      "\n",
      "Shrink model to first 364 iterations.\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 125200.20252645717\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 125263.38391071853\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 107139.96330740271\n",
      "\n",
      "\n",
      "Average Val MAE: 119391.2819346356\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 244604.2819152\ttest: 244604.2819152\ttest1: 224976.2747193\tbest: 224976.2747193 (0)\ttotal: 6.8ms\tremaining: 1m 8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120593.3929\n",
      "bestIteration = 231\n",
      "\n",
      "Shrink model to first 232 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 228049.0939452\ttest: 228049.0939452\ttest1: 259076.5723368\tbest: 259076.5723368 (0)\ttotal: 6.59ms\tremaining: 1m 5s\n",
      "500:\tlearn: 101608.3611645\ttest: 101608.3611645\ttest1: 121489.3422489\tbest: 121489.3422489 (500)\ttotal: 2.91s\tremaining: 55.2s\n",
      "1000:\tlearn: 91814.7423288\ttest: 91814.7423288\ttest1: 117750.7164168\tbest: 117750.7164168 (1000)\ttotal: 5.75s\tremaining: 51.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117396.9972\n",
      "bestIteration = 1085\n",
      "\n",
      "Shrink model to first 1086 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 241773.0320014\ttest: 241773.0320014\ttest1: 230440.9386288\tbest: 230440.9386288 (0)\ttotal: 7.24ms\tremaining: 1m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 129673.4571\n",
      "bestIteration = 281\n",
      "\n",
      "Shrink model to first 282 iterations.\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 233569.8196812\ttest: 233569.8196812\ttest1: 204974.8613883\tbest: 204974.8613883 (0)\ttotal: 6.7ms\tremaining: 1m 6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 110863.1677\n",
      "bestIteration = 368\n",
      "\n",
      "Shrink model to first 369 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 203926.5875647\ttest: 203926.5875647\ttest1: 263301.3766541\tbest: 263301.3766541 (0)\ttotal: 6.63ms\tremaining: 1m 6s\n",
      "500:\tlearn: 98352.3441832\ttest: 98352.3441832\ttest1: 132910.9809012\tbest: 132910.9809012 (500)\ttotal: 2.94s\tremaining: 55.7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 131737.6886\n",
      "bestIteration = 610\n",
      "\n",
      "Shrink model to first 611 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 233712.6625745\ttest: 233712.6625745\ttest1: 202783.8817543\tbest: 202783.8817543 (0)\ttotal: 9.24ms\tremaining: 1m 32s\n",
      "500:\tlearn: 107984.6549706\ttest: 107984.6549706\ttest1: 113282.7641835\tbest: 113273.1139165 (498)\ttotal: 3.05s\tremaining: 57.9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 112204.9256\n",
      "bestIteration = 654\n",
      "\n",
      "Shrink model to first 655 iterations.\n",
      "Elapsed 0.36 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 223184.3964460\ttest: 223184.3964460\ttest1: 180560.5399678\tbest: 180560.5399678 (0)\ttotal: 7.31ms\tremaining: 1m 13s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 102840.8943\n",
      "bestIteration = 168\n",
      "\n",
      "Shrink model to first 169 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 209668.7426185\ttest: 209668.7426185\ttest1: 207986.6547570\tbest: 207986.6547570 (0)\ttotal: 6.99ms\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 112237.0068\n",
      "bestIteration = 258\n",
      "\n",
      "Shrink model to first 259 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 194389.5549106\ttest: 194389.5549106\ttest1: 239891.1052947\tbest: 239891.1052947 (0)\ttotal: 7.13ms\tremaining: 1m 11s\n",
      "500:\tlearn: 96368.8151233\ttest: 96368.8151233\ttest1: 133534.1709053\tbest: 133534.1709053 (500)\ttotal: 3.07s\tremaining: 58.1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 130467.5616\n",
      "bestIteration = 798\n",
      "\n",
      "Shrink model to first 799 iterations.\n",
      "Elapsed 0.50 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 214882.0182032\ttest: 214882.0182032\ttest1: 173578.8145982\tbest: 173578.8145982 (0)\ttotal: 6.98ms\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 103424.0141\n",
      "bestIteration = 161\n",
      "\n",
      "Shrink model to first 162 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 198246.2724241\ttest: 198246.2724241\ttest1: 206137.2307367\tbest: 206137.2307367 (0)\ttotal: 7.31ms\tremaining: 1m 13s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 114324.4921\n",
      "bestIteration = 411\n",
      "\n",
      "Shrink model to first 412 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 190349.3720120\ttest: 190349.3720120\ttest1: 224758.2235303\tbest: 224758.2235303 (0)\ttotal: 9.04ms\tremaining: 1m 30s\n",
      "500:\tlearn: 94019.0251513\ttest: 94019.0251513\ttest1: 115448.2419747\tbest: 115448.2419747 (500)\ttotal: 3.17s\tremaining: 1m\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115327.3389\n",
      "bestIteration = 514\n",
      "\n",
      "Shrink model to first 515 iterations.\n",
      "Elapsed 0.64 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 122446.64587253946\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 118336.24795481419\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 114928.20781407694\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 110942.84624485658\n",
      "\n",
      "\n",
      "Average Val MAE: 116663.48697157232\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 123651\tvalid_1's l1: 142926\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 124400\tvalid_1's l1: 135634\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 132221\tvalid_1's l1: 126964\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 131522\tvalid_1's l1: 126571\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 142926.41492417114\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 135634.1357824705\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 126570.65586040032\n",
      "\n",
      "\n",
      "Average Val MAE: 135187.10758246985\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:218510.15542\tvalidation_1-mae:224029.03806\n",
      "[98]\tvalidation_0-mae:114441.76523\tvalidation_1-mae:129781.98228\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:211771.84211\tvalidation_1-mae:237552.49489\n",
      "[114]\tvalidation_0-mae:115102.98212\tvalidation_1-mae:123742.77658\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:230583.17430\tvalidation_1-mae:198558.96132\n",
      "[78]\tvalidation_0-mae:123491.09441\tvalidation_1-mae:111522.13886\n",
      "Elapsed 0.22 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 129511.74934564978\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 123597.95308763739\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 111174.67247149275\n",
      "\n",
      "\n",
      "Average Val MAE: 121597.72392806875\n",
      "Blended MAE: 118584.91465205986\n",
      "Walk forward MAE:  70842.69983897085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53a2f94d75c4db78f3c979b888307dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2876e80a1bf54c308f7773014b1e399f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\ttraining's l1: 85539.7\tvalid_1's l1: 142073\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 81614\tvalid_1's l1: 120458\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's l1: 71801.9\tvalid_1's l1: 118684\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 80570.3\tvalid_1's l1: 133849\n",
      "Early stopping, best iteration is:\n",
      "[603]\ttraining's l1: 75170.2\tvalid_1's l1: 132463\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 81409.1\tvalid_1's l1: 134159\n",
      "Early stopping, best iteration is:\n",
      "[497]\ttraining's l1: 81589.3\tvalid_1's l1: 134105\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 77772.3\tvalid_1's l1: 130194\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's l1: 74871.1\tvalid_1's l1: 129666\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 84990.3\tvalid_1's l1: 127271\n",
      "Early stopping, best iteration is:\n",
      "[509]\ttraining's l1: 84428\tvalid_1's l1: 127211\n",
      "Elapsed 0.28 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[471]\ttraining's l1: 81217.9\tvalid_1's l1: 129045\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 79626.1\tvalid_1's l1: 121587\n",
      "Early stopping, best iteration is:\n",
      "[637]\ttraining's l1: 72289.3\tvalid_1's l1: 120714\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 76440.3\tvalid_1's l1: 136018\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's l1: 68420.2\tvalid_1's l1: 133953\n",
      "Elapsed 0.44 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttraining's l1: 74074.3\tvalid_1's l1: 142005\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 75449.3\tvalid_1's l1: 115715\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttraining's l1: 66204.9\tvalid_1's l1: 114516\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[436]\ttraining's l1: 79516.7\tvalid_1's l1: 121676\n",
      "Elapsed 0.58 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 131111.09809967224\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 130331.62886563849\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 127922.33719821491\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 126104.9963943801\n",
      "\n",
      "\n",
      "Average Val MAE: 128867.51513946457\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:223010.65288\tvalidation_1-mae:212286.26390\n",
      "[84]\tvalidation_0-mae:118530.38359\tvalidation_1-mae:127348.18858\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:217019.70483\tvalidation_1-mae:224307.55199\n",
      "[104]\tvalidation_0-mae:118367.14004\tvalidation_1-mae:127663.43766\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:218373.35361\tvalidation_1-mae:221828.93752\n",
      "[118]\tvalidation_0-mae:120754.69234\tvalidation_1-mae:119565.78012\n",
      "Elapsed 0.22 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 127163.26203448127\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 127396.3816423523\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 119494.2443639597\n",
      "\n",
      "\n",
      "Average Val MAE: 124679.73784080076\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 220470.8298328\ttest: 220470.8298328\ttest1: 210075.2100933\tbest: 210075.2100933 (0)\ttotal: 12.8ms\tremaining: 2m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 122615.7729\n",
      "bestIteration = 191\n",
      "\n",
      "Shrink model to first 192 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 214144.9267134\ttest: 214144.9267134\ttest1: 221883.7238849\tbest: 221883.7238849 (0)\ttotal: 13.1ms\tremaining: 2m 10s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 122855.1118\n",
      "bestIteration = 289\n",
      "\n",
      "Shrink model to first 290 iterations.\n",
      "Elapsed 0.11 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 215811.4731000\ttest: 215811.4731000\ttest1: 218612.6846985\tbest: 218612.6846985 (0)\ttotal: 12.7ms\tremaining: 2m 6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115583.7862\n",
      "bestIteration = 364\n",
      "\n",
      "Shrink model to first 365 iterations.\n",
      "Elapsed 0.20 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 122615.77290971567\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 122855.11175480731\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 115583.78621953136\n",
      "\n",
      "\n",
      "Average Val MAE: 120347.0240516348\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:244095.92154\tvalidation_1-mae:230393.65278\n",
      "[100]\tvalidation_0-mae:105598.67469\tvalidation_1-mae:131102.00554\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:234787.70972\tvalidation_1-mae:249502.60927\n",
      "[181]\tvalidation_0-mae:97346.36171\tvalidation_1-mae:120588.46238\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:239920.86915\tvalidation_1-mae:239192.91317\n",
      "[125]\tvalidation_0-mae:100695.18156\tvalidation_1-mae:133922.06546\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:226856.93056\tvalidation_1-mae:219953.04685\n",
      "[127]\tvalidation_0-mae:102372.96146\tvalidation_1-mae:130279.18926\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:206582.00874\tvalidation_1-mae:261326.45192\n",
      "[336]\tvalidation_0-mae:86185.56429\tvalidation_1-mae:134101.43161\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:240019.62723\tvalidation_1-mae:192801.49176\n",
      "[75]\tvalidation_0-mae:117336.16512\tvalidation_1-mae:110011.33809\n",
      "Elapsed 0.27 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:221843.51278\tvalidation_1-mae:193212.80621\n",
      "[93]\tvalidation_0-mae:105349.98049\tvalidation_1-mae:116452.92729\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:216596.93022\tvalidation_1-mae:202586.25372\n",
      "[60]\tvalidation_0-mae:116702.40980\tvalidation_1-mae:119953.54010\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:198610.74050\tvalidation_1-mae:240862.08010\n",
      "[198]\tvalidation_0-mae:91438.22173\tvalidation_1-mae:138560.66754\n",
      "Elapsed 0.39 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:200496.12478\tvalidation_1-mae:203999.10294\n",
      "[125]\tvalidation_0-mae:93972.57365\tvalidation_1-mae:131990.11849\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:202193.17106\tvalidation_1-mae:200169.35317\n",
      "[107]\tvalidation_0-mae:98064.41557\tvalidation_1-mae:116701.32923\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:202040.69822\tvalidation_1-mae:200281.47356\n",
      "[77]\tvalidation_0-mae:103582.53036\tvalidation_1-mae:113966.98265\n",
      "Elapsed 0.49 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 128393.34128290485\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 124268.61192301997\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 124800.15998068404\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 120562.65880395134\n",
      "\n",
      "\n",
      "Average Val MAE: 124506.19299764006\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's l1: 127976\tvalid_1's l1: 141522\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 126958\tvalid_1's l1: 139768\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 126113\tvalid_1's l1: 139392\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 129819\tvalid_1's l1: 133347\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 141522.08828247734\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 139392.43410952302\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 133346.6908734102\n",
      "\n",
      "\n",
      "Average Val MAE: 138086.29243781738\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 220153.7626167\ttest: 220153.7626167\ttest1: 209794.6378298\tbest: 209794.6378298 (0)\ttotal: 13.7ms\tremaining: 2m 17s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 123020.0264\n",
      "bestIteration = 237\n",
      "\n",
      "Shrink model to first 238 iterations.\n",
      "Elapsed 0.06 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 214181.7050037\ttest: 214181.7050037\ttest1: 221914.5156296\tbest: 221914.5156296 (0)\ttotal: 13.2ms\tremaining: 2m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 123631.5181\n",
      "bestIteration = 240\n",
      "\n",
      "Shrink model to first 241 iterations.\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 216430.0076661\ttest: 216430.0076661\ttest1: 219126.2296221\tbest: 219126.2296221 (0)\ttotal: 13.4ms\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117164.2782\n",
      "bestIteration = 398\n",
      "\n",
      "Shrink model to first 399 iterations.\n",
      "Elapsed 0.21 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 123020.02640274551\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 123631.51810066844\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 117164.27824081192\n",
      "\n",
      "\n",
      "Average Val MAE: 121267.39739822628\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 240190.7883132\ttest: 240190.7883132\ttest1: 226725.0726089\tbest: 226725.0726089 (0)\ttotal: 6.82ms\tremaining: 1m 8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124129.3427\n",
      "bestIteration = 196\n",
      "\n",
      "Shrink model to first 197 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 231098.0479675\ttest: 231098.0479675\ttest1: 245058.4169765\tbest: 245058.4169765 (0)\ttotal: 7.13ms\tremaining: 1m 11s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 118998.7308\n",
      "bestIteration = 455\n",
      "\n",
      "Shrink model to first 456 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 235578.1936767\ttest: 235578.1936767\ttest1: 235287.0976261\tbest: 235287.0976261 (0)\ttotal: 7.73ms\tremaining: 1m 17s\n",
      "500:\tlearn: 101995.3541529\ttest: 101995.3541529\ttest1: 127028.2706490\tbest: 127028.2706490 (500)\ttotal: 3.02s\tremaining: 57.3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 125336.4705\n",
      "bestIteration = 767\n",
      "\n",
      "Shrink model to first 768 iterations.\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 224158.5904489\ttest: 224158.5904489\ttest1: 216630.2969140\tbest: 216630.2969140 (0)\ttotal: 7.19ms\tremaining: 1m 11s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 123433.2377\n",
      "bestIteration = 299\n",
      "\n",
      "Shrink model to first 300 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 204072.8219415\ttest: 204072.8219415\ttest1: 257807.6716358\tbest: 257807.6716358 (0)\ttotal: 7.96ms\tremaining: 1m 19s\n",
      "500:\tlearn: 101935.0542568\ttest: 101935.0542568\ttest1: 130380.5858338\tbest: 130380.5858338 (500)\ttotal: 3.12s\tremaining: 59.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128565.2149\n",
      "bestIteration = 717\n",
      "\n",
      "Shrink model to first 718 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 236912.0107846\ttest: 236912.0107846\ttest1: 191441.6135363\tbest: 191441.6135363 (0)\ttotal: 7.4ms\tremaining: 1m 14s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 107178.6856\n",
      "bestIteration = 185\n",
      "\n",
      "Shrink model to first 186 iterations.\n",
      "Elapsed 0.31 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 219319.2651802\ttest: 219319.2651802\ttest1: 190390.7154073\tbest: 190390.7154073 (0)\ttotal: 7.59ms\tremaining: 1m 15s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 110374.3277\n",
      "bestIteration = 233\n",
      "\n",
      "Shrink model to first 234 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 214721.9278778\ttest: 214721.9278778\ttest1: 201717.6889013\tbest: 201717.6889013 (0)\ttotal: 7.42ms\tremaining: 1m 14s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 112640.3291\n",
      "bestIteration = 245\n",
      "\n",
      "Shrink model to first 246 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 195910.4132771\ttest: 195910.4132771\ttest1: 237933.4946483\tbest: 237933.4946483 (0)\ttotal: 8.06ms\tremaining: 1m 20s\n",
      "500:\tlearn: 98734.2685604\ttest: 98734.2685604\ttest1: 134294.5679184\tbest: 134294.5679184 (500)\ttotal: 3.22s\tremaining: 1m\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 131959.3859\n",
      "bestIteration = 703\n",
      "\n",
      "Shrink model to first 704 iterations.\n",
      "Elapsed 0.45 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 198911.4437094\ttest: 198911.4437094\ttest1: 201917.8126438\tbest: 201917.8126438 (0)\ttotal: 7.43ms\tremaining: 1m 14s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 119408.7644\n",
      "bestIteration = 334\n",
      "\n",
      "Shrink model to first 335 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 200271.2777286\ttest: 200271.2777286\ttest1: 198498.4697826\tbest: 198498.4697826 (0)\ttotal: 7.79ms\tremaining: 1m 17s\n",
      "500:\tlearn: 100693.7685902\ttest: 100693.7685902\ttest1: 110997.8262954\tbest: 110997.8262954 (500)\ttotal: 3.31s\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 109759.3457\n",
      "bestIteration = 753\n",
      "\n",
      "Shrink model to first 754 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 200357.5790594\ttest: 200357.5790594\ttest1: 199265.0726723\tbest: 199265.0726723 (0)\ttotal: 7.22ms\tremaining: 1m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 108300.4491\n",
      "bestIteration = 301\n",
      "\n",
      "Shrink model to first 302 iterations.\n",
      "Elapsed 0.63 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 122831.78594504025\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 119706.69439927085\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 118332.99797489775\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 112501.06280064955\n",
      "\n",
      "\n",
      "Average Val MAE: 118343.13527996553\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 127151\tvalid_1's l1: 140155\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 126549\tvalid_1's l1: 139852\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 128147\tvalid_1's l1: 137886\n",
      "Early stopping, best iteration is:\n",
      "[652]\ttraining's l1: 126771\tvalid_1's l1: 136666\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 130552\tvalid_1's l1: 133033\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 139851.55846286766\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 136665.99956430992\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 133033.28907301\n",
      "\n",
      "\n",
      "Average Val MAE: 136518.92855818008\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:222991.22269\tvalidation_1-mae:212337.50204\n",
      "[86]\tvalidation_0-mae:118442.53190\tvalidation_1-mae:126579.28710\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:217001.31975\tvalidation_1-mae:224301.33595\n",
      "[91]\tvalidation_0-mae:119024.07463\tvalidation_1-mae:123757.46418\n",
      "Elapsed 0.15 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:218350.87966\tvalidation_1-mae:221769.89042\n",
      "[107]\tvalidation_0-mae:121429.40259\tvalidation_1-mae:119740.76335\n",
      "Elapsed 0.24 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 126342.13839700138\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 123581.75374623724\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 119557.62124030633\n",
      "\n",
      "\n",
      "Average Val MAE: 123161.71055067341\n",
      "Blended MAE: 120281.84748588853\n",
      "Walk forward MAE:  82550.7206431577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e70ba58cce4e4f8b0eecc9964a4b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/818 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc80b12d56f4945a032c9448b64b81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[379]\ttraining's l1: 90131.2\tvalid_1's l1: 145394\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 82860.9\tvalid_1's l1: 123256\n",
      "Early stopping, best iteration is:\n",
      "[596]\ttraining's l1: 77657.5\tvalid_1's l1: 122610\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 83182.4\tvalid_1's l1: 133825\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's l1: 80194.5\tvalid_1's l1: 133133\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 83795.4\tvalid_1's l1: 126436\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's l1: 75276.7\tvalid_1's l1: 125069\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 78770.3\tvalid_1's l1: 143661\n",
      "Early stopping, best iteration is:\n",
      "[665]\ttraining's l1: 71143.1\tvalid_1's l1: 142577\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[458]\ttraining's l1: 90096.7\tvalid_1's l1: 127339\n",
      "Elapsed 0.29 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[478]\ttraining's l1: 79873.1\tvalid_1's l1: 124592\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 82484.4\tvalid_1's l1: 112722\n",
      "Early stopping, best iteration is:\n",
      "[580]\ttraining's l1: 78039.6\tvalid_1's l1: 112213\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 76187.8\tvalid_1's l1: 134479\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttraining's l1: 68910.3\tvalid_1's l1: 133231\n",
      "Elapsed 0.44 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 76799.8\tvalid_1's l1: 119338\n",
      "Early stopping, best iteration is:\n",
      "[603]\ttraining's l1: 71301.6\tvalid_1's l1: 118597\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 73676\tvalid_1's l1: 127606\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's l1: 65078.8\tvalid_1's l1: 126327\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[382]\ttraining's l1: 83881.3\tvalid_1's l1: 126774\n",
      "Elapsed 0.59 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 133801.45990405715\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 131612.5716327397\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 123352.09803086352\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 123858.40283362262\n",
      "\n",
      "\n",
      "Average Val MAE: 128156.13310032104\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:214450.57323\tvalidation_1-mae:214372.85676\n",
      "[95]\tvalidation_0-mae:118253.16499\tvalidation_1-mae:123661.21822\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:213296.98721\tvalidation_1-mae:217000.02618\n",
      "[117]\tvalidation_0-mae:117828.34348\tvalidation_1-mae:126775.29814\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:215625.55563\tvalidation_1-mae:211920.29319\n",
      "[92]\tvalidation_0-mae:121442.20067\tvalidation_1-mae:119318.03129\n",
      "Elapsed 0.23 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 123475.42521776361\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126719.45569009313\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 119099.26432542772\n",
      "\n",
      "\n",
      "Average Val MAE: 123101.86726805533\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 211613.9411123\ttest: 211613.9411123\ttest1: 211922.5328750\tbest: 211922.5328750 (0)\ttotal: 13.6ms\tremaining: 2m 15s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 118983.9192\n",
      "bestIteration = 309\n",
      "\n",
      "Shrink model to first 310 iterations.\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 210741.8701616\ttest: 210741.8701616\ttest1: 213264.0371286\tbest: 213264.0371286 (0)\ttotal: 12.7ms\tremaining: 2m 6s\n",
      "500:\tlearn: 113284.5929286\ttest: 113284.5929286\ttest1: 121430.3432998\tbest: 121430.2243607 (499)\ttotal: 5.98s\tremaining: 1m 53s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121420.0885\n",
      "bestIteration = 505\n",
      "\n",
      "Shrink model to first 506 iterations.\n",
      "Elapsed 0.19 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 212603.8028932\ttest: 212603.8028932\ttest1: 209844.2733123\tbest: 209844.2733123 (0)\ttotal: 12.7ms\tremaining: 2m 7s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 114174.1558\n",
      "bestIteration = 278\n",
      "\n",
      "Shrink model to first 279 iterations.\n",
      "Elapsed 0.26 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 118983.9191625789\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 121420.0885477908\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 114174.15575894408\n",
      "\n",
      "\n",
      "Average Val MAE: 118199.69064525625\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:238741.59421\tvalidation_1-mae:228071.56198\n",
      "[84]\tvalidation_0-mae:110847.53670\tvalidation_1-mae:130471.47681\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:232156.76934\tvalidation_1-mae:241488.37174\n",
      "[148]\tvalidation_0-mae:100868.41578\tvalidation_1-mae:123105.13442\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:234866.86239\tvalidation_1-mae:236419.61857\n",
      "[130]\tvalidation_0-mae:102839.42483\tvalidation_1-mae:135659.33182\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:226908.24038\tvalidation_1-mae:211012.36481\n",
      "[202]\tvalidation_0-mae:100354.73109\tvalidation_1-mae:123259.30786\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:199516.18538\tvalidation_1-mae:266366.28245\n",
      "[357]\tvalidation_0-mae:86386.10546\tvalidation_1-mae:146573.63806\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:237643.00988\tvalidation_1-mae:187030.82971\n",
      "[63]\tvalidation_0-mae:124813.04202\tvalidation_1-mae:112681.74587\n",
      "Elapsed 0.29 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:209099.43760\tvalidation_1-mae:200209.97956\n",
      "[107]\tvalidation_0-mae:100023.49457\tvalidation_1-mae:132986.94460\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:215302.61226\tvalidation_1-mae:185720.26513\n",
      "[59]\tvalidation_0-mae:119473.80034\tvalidation_1-mae:117574.16231\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:193385.04184\tvalidation_1-mae:232292.93536\n",
      "[364]\tvalidation_0-mae:84885.05938\tvalidation_1-mae:132726.65894\n",
      "Elapsed 0.47 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:209556.50108\tvalidation_1-mae:167808.70164\n",
      "[96]\tvalidation_0-mae:101862.17820\tvalidation_1-mae:106892.69374\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:185859.83304\tvalidation_1-mae:215741.39863\n",
      "[192]\tvalidation_0-mae:88454.29482\tvalidation_1-mae:135352.82658\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:191173.29730\tvalidation_1-mae:203516.98116\n",
      "[89]\tvalidation_0-mae:98717.79517\tvalidation_1-mae:116265.63008\n",
      "Elapsed 0.61 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 129590.3097989865\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 127149.00052512887\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 125997.5435097112\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 119284.66021485561\n",
      "\n",
      "\n",
      "Average Val MAE: 125505.37851217054\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 127454\tvalid_1's l1: 140808\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 127350\tvalid_1's l1: 137955\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttraining's l1: 126058\tvalid_1's l1: 136848\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 131231\tvalid_1's l1: 133866\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 140808.25049502516\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 136848.00482848723\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 133865.9760267473\n",
      "\n",
      "\n",
      "Average Val MAE: 137202.49055892002\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 211551.9132049\ttest: 211551.9132049\ttest1: 212064.2011946\tbest: 212064.2011946 (0)\ttotal: 15.4ms\tremaining: 2m 33s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121748.7656\n",
      "bestIteration = 217\n",
      "\n",
      "Shrink model to first 218 iterations.\n",
      "Elapsed 0.05 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 210996.3470932\ttest: 210996.3470932\ttest1: 213566.9162424\tbest: 213566.9162424 (0)\ttotal: 13.2ms\tremaining: 2m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124066.8693\n",
      "bestIteration = 332\n",
      "\n",
      "Shrink model to first 333 iterations.\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 212627.4244125\ttest: 212627.4244125\ttest1: 209863.6018712\tbest: 209863.6018712 (0)\ttotal: 12.8ms\tremaining: 2m 8s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115805.7456\n",
      "bestIteration = 300\n",
      "\n",
      "Shrink model to first 301 iterations.\n",
      "Elapsed 0.21 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 121748.7655869457\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 124066.86933347427\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 115805.74559982878\n",
      "\n",
      "\n",
      "Average Val MAE: 120550.7707105886\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 234729.3021782\ttest: 234729.3021782\ttest1: 223680.1279490\tbest: 223680.1279490 (0)\ttotal: 7.59ms\tremaining: 1m 15s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 127213.1733\n",
      "bestIteration = 174\n",
      "\n",
      "Shrink model to first 175 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 227864.3427383\ttest: 227864.3427383\ttest1: 236881.7036215\tbest: 236881.7036215 (0)\ttotal: 7.14ms\tremaining: 1m 11s\n",
      "500:\tlearn: 105061.6638188\ttest: 105061.6638188\ttest1: 117210.7095834\tbest: 117210.7095834 (500)\ttotal: 3.12s\tremaining: 59.2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115402.078\n",
      "bestIteration = 725\n",
      "\n",
      "Shrink model to first 726 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 230270.5181046\ttest: 230270.5181046\ttest1: 232536.7880865\tbest: 232536.7880865 (0)\ttotal: 7.92ms\tremaining: 1m 19s\n",
      "500:\tlearn: 103871.6898539\ttest: 103871.6898539\ttest1: 129380.9787322\tbest: 129380.9787322 (500)\ttotal: 3.19s\tremaining: 1m\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128566.8062\n",
      "bestIteration = 641\n",
      "\n",
      "Shrink model to first 642 iterations.\n",
      "Elapsed 0.18 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 223927.8932818\ttest: 223927.8932818\ttest1: 207273.3613500\tbest: 207273.3613500 (0)\ttotal: 8.45ms\tremaining: 1m 24s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116462.4737\n",
      "bestIteration = 377\n",
      "\n",
      "Shrink model to first 378 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 196707.0870386\ttest: 196707.0870386\ttest1: 262524.4405302\tbest: 262524.4405302 (0)\ttotal: 7.74ms\tremaining: 1m 17s\n",
      "500:\tlearn: 99866.7269929\ttest: 99866.7269929\ttest1: 141384.0086293\tbest: 141384.0086293 (500)\ttotal: 3.26s\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 140473.1627\n",
      "bestIteration = 583\n",
      "\n",
      "Shrink model to first 584 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 234043.9858456\ttest: 234043.9858456\ttest1: 185856.9992146\tbest: 185856.9992146 (0)\ttotal: 7.49ms\tremaining: 1m 14s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 107060.8634\n",
      "bestIteration = 193\n",
      "\n",
      "Shrink model to first 194 iterations.\n",
      "Elapsed 0.33 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 206839.0729854\ttest: 206839.0729854\ttest1: 196956.9248752\tbest: 196956.9248752 (0)\ttotal: 7.23ms\tremaining: 1m 12s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116367.4333\n",
      "bestIteration = 273\n",
      "\n",
      "Shrink model to first 274 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 213000.3182693\ttest: 213000.3182693\ttest1: 184151.2699104\tbest: 184151.2699104 (0)\ttotal: 7.82ms\tremaining: 1m 18s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 108712.4439\n",
      "bestIteration = 159\n",
      "\n",
      "Shrink model to first 160 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 191010.0112918\ttest: 191010.0112918\ttest1: 229770.0841911\tbest: 229770.0841911 (0)\ttotal: 7.96ms\tremaining: 1m 19s\n",
      "500:\tlearn: 97532.3943806\ttest: 97532.3943806\ttest1: 131190.0304777\tbest: 131190.0304777 (500)\ttotal: 3.37s\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 128377.6679\n",
      "bestIteration = 886\n",
      "\n",
      "Shrink model to first 887 iterations.\n",
      "Elapsed 0.49 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 207984.8070687\ttest: 207984.8070687\ttest1: 165258.9469844\tbest: 165258.9469844 (0)\ttotal: 7.5ms\tremaining: 1m 15s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 103131.7432\n",
      "bestIteration = 154\n",
      "\n",
      "Shrink model to first 155 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 183882.4239143\ttest: 183882.4239143\ttest1: 213758.8241764\tbest: 213758.8241764 (0)\ttotal: 8.51ms\tremaining: 1m 25s\n",
      "500:\tlearn: 94827.0610599\ttest: 94827.0610599\ttest1: 121956.6730329\tbest: 121956.6730329 (500)\ttotal: 3.36s\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 121657.9734\n",
      "bestIteration = 546\n",
      "\n",
      "Shrink model to first 547 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 189239.3038338\ttest: 189239.3038338\ttest1: 202658.2208538\tbest: 202658.2208538 (0)\ttotal: 9.85ms\tremaining: 1m 38s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 112242.4359\n",
      "bestIteration = 262\n",
      "\n",
      "Shrink model to first 263 iterations.\n",
      "Elapsed 0.63 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 123752.70251740786\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 121298.53686467817\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 117805.63692669988\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 112274.0415914897\n",
      "\n",
      "\n",
      "Average Val MAE: 118782.7294750682\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 127568\tvalid_1's l1: 139148\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 127385\tvalid_1's l1: 136157\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[465]\ttraining's l1: 131333\tvalid_1's l1: 135968\n",
      "Elapsed 0.13 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 139147.733077739\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 136156.68974148267\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 135967.57630489802\n",
      "\n",
      "\n",
      "Average Val MAE: 137106.5713219425\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:214433.02975\tvalidation_1-mae:214301.92476\n",
      "[84]\tvalidation_0-mae:118698.38454\tvalidation_1-mae:122859.24833\n",
      "Elapsed 0.07 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:213275.98720\tvalidation_1-mae:216936.09622\n",
      "[104]\tvalidation_0-mae:118534.61505\tvalidation_1-mae:126159.05371\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:215607.02885\tvalidation_1-mae:212088.15960\n",
      "[90]\tvalidation_0-mae:121052.14242\tvalidation_1-mae:118470.28036\n",
      "Elapsed 0.25 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 122542.1183588914\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 126027.05837492911\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 118320.85679878626\n",
      "\n",
      "\n",
      "Average Val MAE: 122299.48824589266\n",
      "Blended MAE: 119545.64422932631\n",
      "Walk forward MAE:  81535.83141721122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed24c876d67c43a480d5e1bf5d44bec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/883 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a2f99bc07d4266a1d4dda28b2372c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[344]\ttraining's l1: 97882.8\tvalid_1's l1: 142573\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 83198.4\tvalid_1's l1: 122483\n",
      "Early stopping, best iteration is:\n",
      "[663]\ttraining's l1: 75210.6\tvalid_1's l1: 121674\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 81483.4\tvalid_1's l1: 139148\n",
      "Early stopping, best iteration is:\n",
      "[589]\ttraining's l1: 77053.3\tvalid_1's l1: 137997\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 87282.4\tvalid_1's l1: 129647\n",
      "Early stopping, best iteration is:\n",
      "[561]\ttraining's l1: 83847.6\tvalid_1's l1: 129253\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 80692.1\tvalid_1's l1: 139860\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttraining's l1: 78657.7\tvalid_1's l1: 139477\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 84791.7\tvalid_1's l1: 124392\n",
      "Early stopping, best iteration is:\n",
      "[567]\ttraining's l1: 81172.6\tvalid_1's l1: 124100\n",
      "Elapsed 0.30 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 81208.8\tvalid_1's l1: 125103\n",
      "Early stopping, best iteration is:\n",
      "[546]\ttraining's l1: 78639\tvalid_1's l1: 124709\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 83770.9\tvalid_1's l1: 112954\n",
      "Early stopping, best iteration is:\n",
      "[598]\ttraining's l1: 78550.7\tvalid_1's l1: 112451\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 74792\tvalid_1's l1: 132894\n",
      "Early stopping, best iteration is:\n",
      "[642]\ttraining's l1: 68578.9\tvalid_1's l1: 131587\n",
      "Elapsed 0.46 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training lgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 80751.7\tvalid_1's l1: 126447\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttraining's l1: 77643\tvalid_1's l1: 126062\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 75987.9\tvalid_1's l1: 128275\n",
      "Early stopping, best iteration is:\n",
      "[707]\ttraining's l1: 67265.4\tvalid_1's l1: 126933\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 76158.5\tvalid_1's l1: 122606\n",
      "Early stopping, best iteration is:\n",
      "[578]\ttraining's l1: 72286.1\tvalid_1's l1: 122237\n",
      "Elapsed 0.63 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 134013.6707091687\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 130940.72799321469\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 122921.72909367476\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 125060.92224655232\n",
      "\n",
      "\n",
      "Average Val MAE: 128234.26251064037\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:209404.66950\tvalidation_1-mae:217859.86984\n",
      "[122]\tvalidation_0-mae:117056.29699\tvalidation_1-mae:128255.20717\n",
      "Elapsed 0.10 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:212693.13830\tvalidation_1-mae:210900.61298\n",
      "[95]\tvalidation_0-mae:120120.42876\tvalidation_1-mae:119534.52612\n",
      "Elapsed 0.18 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:214324.40003\tvalidation_1-mae:207849.86773\n",
      "[102]\tvalidation_0-mae:120064.54636\tvalidation_1-mae:120096.10474\n",
      "Elapsed 0.26 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 128245.1561168858\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 119295.84306447729\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 119921.8321449296\n",
      "\n",
      "\n",
      "Average Val MAE: 122428.19832279957\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 206210.8662611\ttest: 206210.8662611\ttest1: 215472.6646478\tbest: 215472.6646478 (0)\ttotal: 13.7ms\tremaining: 2m 17s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 123017.5602\n",
      "bestIteration = 338\n",
      "\n",
      "Shrink model to first 339 iterations.\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 209929.8969355\ttest: 209929.8969355\ttest1: 207490.9732154\tbest: 207490.9732154 (0)\ttotal: 13.5ms\tremaining: 2m 14s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116101.4392\n",
      "bestIteration = 287\n",
      "\n",
      "Shrink model to first 288 iterations.\n",
      "Elapsed 0.16 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 211263.3214869\ttest: 211263.3214869\ttest1: 204912.7663107\tbest: 204912.7663107 (0)\ttotal: 13.8ms\tremaining: 2m 18s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115387.5061\n",
      "bestIteration = 257\n",
      "\n",
      "Shrink model to first 258 iterations.\n",
      "Elapsed 0.23 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 123017.56015645846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 116101.43924315927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 115387.5061174901\n",
      "\n",
      "\n",
      "Average Val MAE: 118117.17627910379\n",
      "Training xgb model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:241222.93568\tvalidation_1-mae:210371.51223\n",
      "[77]\tvalidation_0-mae:116326.49628\tvalidation_1-mae:123482.32778\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:230320.02345\tvalidation_1-mae:233303.16474\n",
      "[150]\tvalidation_0-mae:100246.78991\tvalidation_1-mae:121680.29343\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:222227.92309\tvalidation_1-mae:249546.01201\n",
      "[192]\tvalidation_0-mae:95062.72283\tvalidation_1-mae:139291.06195\n",
      "Elapsed 0.12 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:229899.65642\tvalidation_1-mae:193689.48443\n",
      "[145]\tvalidation_0-mae:106945.19070\tvalidation_1-mae:115319.14230\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:201561.99398\tvalidation_1-mae:250996.41559\n",
      "[457]\tvalidation_0-mae:84931.82131\tvalidation_1-mae:143427.68258\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:222224.84701\tvalidation_1-mae:208864.61108\n",
      "[77]\tvalidation_0-mae:114804.42039\tvalidation_1-mae:125829.68822\n",
      "Elapsed 0.35 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:212626.82165\tvalidation_1-mae:184082.54893\n",
      "[106]\tvalidation_0-mae:103341.21266\tvalidation_1-mae:114784.93166\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:215241.67722\tvalidation_1-mae:178763.27103\n",
      "[66]\tvalidation_0-mae:116451.66298\tvalidation_1-mae:113380.47304\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:181783.08610\tvalidation_1-mae:246347.14595\n",
      "[205]\tvalidation_0-mae:87688.76372\tvalidation_1-mae:138291.94281\n",
      "Elapsed 0.49 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training xgb model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "[0]\tvalidation_0-mae:210807.27521\tvalidation_1-mae:165662.47696\n",
      "[86]\tvalidation_0-mae:107423.86783\tvalidation_1-mae:106870.68091\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "[0]\tvalidation_0-mae:190168.53988\tvalidation_1-mae:208377.08095\n",
      "[182]\tvalidation_0-mae:90792.78497\tvalidation_1-mae:130661.89130\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "[0]\tvalidation_0-mae:186996.53521\tvalidation_1-mae:213572.60397\n",
      "[79]\tvalidation_0-mae:100200.06551\tvalidation_1-mae:123025.89412\n",
      "Elapsed 0.62 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 128031.20561175415\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 128000.58069171154\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 120922.67647116949\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 120143.33590456232\n",
      "\n",
      "\n",
      "Average Val MAE: 124274.44966979937\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 125224\tvalid_1's l1: 139505\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 124543\tvalid_1's l1: 138811\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 129921\tvalid_1's l1: 130468\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 129170\tvalid_1's l1: 130255\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 129001\tvalid_1's l1: 134989\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 128223\tvalid_1's l1: 134537\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 138810.87390600677\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 130254.83269813274\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 134536.76807064982\n",
      "\n",
      "\n",
      "Average Val MAE: 134495.0240448508\n",
      "\n",
      "\n",
      "Training cat model fold 1\n",
      "0:\tlearn: 206256.3019145\ttest: 206256.3019145\ttest1: 215460.3574373\tbest: 215460.3574373 (0)\ttotal: 14.1ms\tremaining: 2m 20s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 124806.7693\n",
      "bestIteration = 336\n",
      "\n",
      "Shrink model to first 337 iterations.\n",
      "Elapsed 0.08 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 2\n",
      "0:\tlearn: 209995.6138169\ttest: 209995.6138169\ttest1: 207567.0579542\tbest: 207567.0579542 (0)\ttotal: 14ms\tremaining: 2m 20s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 115646.8401\n",
      "bestIteration = 339\n",
      "\n",
      "Shrink model to first 340 iterations.\n",
      "Elapsed 0.17 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training cat model fold 3\n",
      "0:\tlearn: 211316.6664833\ttest: 211316.6664833\ttest1: 204934.4123773\tbest: 204934.4123773 (0)\ttotal: 13.4ms\tremaining: 2m 14s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117076.603\n",
      "bestIteration = 286\n",
      "\n",
      "Shrink model to first 287 iterations.\n",
      "Elapsed 0.25 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 124806.76927939347\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 115646.84009645219\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 117076.60300081888\n",
      "\n",
      "\n",
      "Average Val MAE: 119119.7116285583\n",
      "Training cat model for timestep 1 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 236808.5502997\ttest: 236808.5502997\ttest1: 206036.8264473\tbest: 206036.8264473 (0)\ttotal: 7.9ms\tremaining: 1m 19s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 127695.3446\n",
      "bestIteration = 95\n",
      "\n",
      "Shrink model to first 96 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 225898.6008752\ttest: 225898.6008752\ttest1: 228427.1623953\tbest: 228427.1623953 (0)\ttotal: 9.64ms\tremaining: 1m 36s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 117688.8562\n",
      "bestIteration = 468\n",
      "\n",
      "Shrink model to first 469 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 217420.4129531\ttest: 217420.4129531\ttest1: 244833.8669584\tbest: 244833.8669584 (0)\ttotal: 7.49ms\tremaining: 1m 14s\n",
      "500:\tlearn: 101011.0016549\ttest: 101011.0016549\ttest1: 135766.0405780\tbest: 135766.0405780 (500)\ttotal: 3.3s\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 135420.9147\n",
      "bestIteration = 584\n",
      "\n",
      "Shrink model to first 585 iterations.\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 2 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 226487.4306862\ttest: 226487.4306862\ttest1: 190042.9187642\tbest: 190042.9187642 (0)\ttotal: 8.2ms\tremaining: 1m 21s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 111647.6492\n",
      "bestIteration = 270\n",
      "\n",
      "Shrink model to first 271 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 198524.0200825\ttest: 198524.0200825\ttest1: 246952.1028490\tbest: 246952.1028490 (0)\ttotal: 7.7ms\tremaining: 1m 16s\n",
      "500:\tlearn: 101463.8487101\ttest: 101463.8487101\ttest1: 136805.9974619\tbest: 136805.9974619 (500)\ttotal: 3.37s\tremaining: 1m 3s\n",
      "1000:\tlearn: 93399.1192904\ttest: 93399.1192904\ttest1: 133365.0377180\tbest: 133365.0377180 (1000)\ttotal: 6.69s\tremaining: 1m\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 132731.3684\n",
      "bestIteration = 1168\n",
      "\n",
      "Shrink model to first 1169 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 218794.3055940\ttest: 218794.3055940\ttest1: 206671.2469721\tbest: 206671.2469721 (0)\ttotal: 9.96ms\tremaining: 1m 39s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 116010.1056\n",
      "bestIteration = 240\n",
      "\n",
      "Shrink model to first 241 iterations.\n",
      "Elapsed 0.35 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 3 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 209923.0525409\ttest: 209923.0525409\ttest1: 180866.0057075\tbest: 180866.0057075 (0)\ttotal: 9.11ms\tremaining: 1m 31s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 106470.2244\n",
      "bestIteration = 297\n",
      "\n",
      "Shrink model to first 298 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 212841.0559573\ttest: 212841.0559573\ttest1: 176815.1858344\tbest: 176815.1858344 (0)\ttotal: 8.02ms\tremaining: 1m 20s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 104712.5548\n",
      "bestIteration = 230\n",
      "\n",
      "Shrink model to first 231 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 179276.3523147\ttest: 179276.3523147\ttest1: 243918.6376119\tbest: 243918.6376119 (0)\ttotal: 8.38ms\tremaining: 1m 23s\n",
      "500:\tlearn: 93664.8985522\ttest: 93664.8985522\ttest1: 136203.3880927\tbest: 136203.3880927 (500)\ttotal: 3.45s\tremaining: 1m 5s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 132979.3105\n",
      "bestIteration = 952\n",
      "\n",
      "Shrink model to first 953 iterations.\n",
      "Elapsed 0.55 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Training cat model for timestep 4 forecasting\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "0:\tlearn: 208982.0706747\ttest: 208982.0706747\ttest1: 163166.2662490\tbest: 163166.2662490 (0)\ttotal: 9.16ms\tremaining: 1m 31s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 100088.6748\n",
      "bestIteration = 355\n",
      "\n",
      "Shrink model to first 356 iterations.\n",
      "\n",
      "\n",
      "Training fold 2\n",
      "0:\tlearn: 187793.4136573\ttest: 187793.4136573\ttest1: 206057.6181185\tbest: 206057.6181185 (0)\ttotal: 8.99ms\tremaining: 1m 29s\n",
      "500:\tlearn: 96608.4478626\ttest: 96608.4478626\ttest1: 120794.9564574\tbest: 120794.9063041 (499)\ttotal: 3.5s\tremaining: 1m 6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 120685.411\n",
      "bestIteration = 512\n",
      "\n",
      "Shrink model to first 513 iterations.\n",
      "\n",
      "\n",
      "Training fold 3\n",
      "0:\tlearn: 185056.9548931\ttest: 185056.9548931\ttest1: 212118.3061314\tbest: 212118.3061314 (0)\ttotal: 8.86ms\tremaining: 1m 28s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 114300.895\n",
      "bestIteration = 464\n",
      "\n",
      "Shrink model to first 465 iterations.\n",
      "Elapsed 0.72 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Making timestep 1 predictions\n",
      "Val MAE: 126950.29993963834\n",
      "\n",
      "\n",
      "Making timestep 2 predictions\n",
      "Val MAE: 120196.54956411858\n",
      "\n",
      "\n",
      "Making timestep 3 predictions\n",
      "Val MAE: 114844.01524000801\n",
      "\n",
      "\n",
      "Making timestep 4 predictions\n",
      "Val MAE: 111804.68430994026\n",
      "\n",
      "\n",
      "Average Val MAE: 118448.8872634246\n",
      "\n",
      "\n",
      "Training lgb model fold 1\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 126123\tvalid_1's l1: 140547\n",
      "Elapsed 0.04 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 2\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[479]\ttraining's l1: 130204\tvalid_1's l1: 135829\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training lgb model fold 3\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[500]\ttraining's l1: 130002\tvalid_1's l1: 132297\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 129326\tvalid_1's l1: 131888\n",
      "Elapsed 0.14 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 140546.74414900117\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 135829.2486771848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 131888.40914304662\n",
      "\n",
      "\n",
      "Average Val MAE: 136036.3314701026\n",
      "\n",
      "\n",
      "Training xgb model fold 1\n",
      "[0]\tvalidation_0-mae:209390.72032\tvalidation_1-mae:217838.17125\n",
      "[100]\tvalidation_0-mae:117053.86715\tvalidation_1-mae:129215.31182\n",
      "Elapsed 0.09 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 2\n",
      "[0]\tvalidation_0-mae:212674.86255\tvalidation_1-mae:210960.78314\n",
      "[90]\tvalidation_0-mae:121295.19308\tvalidation_1-mae:119941.72364\n",
      "Elapsed 0.18 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training xgb model fold 3\n",
      "[0]\tvalidation_0-mae:214306.79873\tvalidation_1-mae:207768.92999\n",
      "[85]\tvalidation_0-mae:121446.78013\tvalidation_1-mae:120606.46301\n",
      "Elapsed 0.26 mins\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 1 predictions\n",
      "Val MAE: 128996.62092800786\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 2 predictions\n",
      "Val MAE: 119713.35120438233\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making fold 3 predictions\n",
      "Val MAE: 120378.41895454947\n",
      "\n",
      "\n",
      "Average Val MAE: 122967.90992003329\n",
      "Blended MAE: 118806.12758521311\n",
      "Walk forward MAE:  101800.44881709189\n"
     ]
    }
   ],
   "source": [
    "from fossil.models.gbdt import FossilGBDT\n",
    "from fossil.config import ModelsConfig\n",
    "from fossil.inference import make_predictions, prepare_test_context\n",
    "\n",
    "gbdt_models = FossilGBDT()\n",
    "\n",
    "target_cols = [f'target_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "pred_cols = [f'preds_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "\n",
    "principal_features = fossil_preproc.load_saved_items(f'{OUTPUT_DIR}/principal_features.pkl')\n",
    "cols = principal_features+['month','year']\n",
    "\n",
    "non_features = ['sku_name','sku_coded']+target_cols\n",
    "test = pd.read_csv(f'{TEST_DIR}/Test.csv')\n",
    "\n",
    "walk_forward_steps = len(dates)-ModelsConfig.N_STEPS-1\n",
    "\n",
    "mae_dict = dict(\n",
    "    month=[], \n",
    "    year=[], \n",
    "    Walk_forward_mae=[], \n",
    "    train_sku_count=[], \n",
    "    val_sku_count=[],\n",
    "    new_sku = [])\n",
    "\n",
    "for step in range(walk_forward_steps,0,-4):\n",
    "    train_dates = dates[:-(ModelsConfig.N_STEPS+step)]\n",
    "    val_dates = dates[-(ModelsConfig.N_STEPS+step):-step]\n",
    "    \n",
    "    if len(train_dates)<ModelsConfig.FOLDS:\n",
    "        continue\n",
    "        \n",
    "    train_data = base_data[base_data[['month','year']].apply(tuple,axis=1).isin(train_dates)]\n",
    "    val_context = base_data[base_data[['month','year']].apply(tuple,axis=1).isin([train_dates[-1]])]\n",
    "\n",
    "    val = base_data[base_data[['month','year']].apply(tuple,axis=1).isin(val_dates)]\n",
    "    val_context, _ = prepare_test_context(val_context, val, fossil_preproc)\n",
    "    \n",
    "    val_data = fossil_preproc.impute_missing(val_context, True, OUTPUT_DIR)\n",
    "    mae_dict['train_sku_count'].append(train_data['sku_name'].nunique())\n",
    "    mae_dict['val_sku_count'].append(val['sku_name'].nunique())\n",
    "    \n",
    "    val_data = val_data[val_data['sku_name'].isin(val['sku_name'].unique())]\n",
    "    y_true = val_data[[f'target_{i}' for i in range(ModelsConfig.N_STEPS)]].values.reshape(-1,)\n",
    "    \n",
    "    new_sku = set(val['sku_name'].unique()).difference(train_data['sku_name'].unique())\n",
    "    feature_cols = [c for c in base_data.columns if c not in non_features and c in cols]\n",
    "\n",
    "    oof_preds, cv_models, blended_mae = gbdt_models.blend_cv_models(principal_features, train_data, fossil_preproc)\n",
    "    sub_df = make_predictions(val, val_data, feature_cols, target_cols, pred_cols, cv_models)\n",
    "    \n",
    "    walk_forward_mae = np.absolute(np.subtract(sub_df['Target'], y_true)).mean()\n",
    "    \n",
    "    mae_dict['month'].append(val_dates[-1][0])\n",
    "    mae_dict['year'].append(val_dates[-1][1])\n",
    "    mae_dict['Walk_forward_mae'].append(walk_forward_mae)\n",
    "    mae_dict['new_sku'].append(len(new_sku))\n",
    "    \n",
    "    print(\"Walk forward MAE: \",walk_forward_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9cca283b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(mae_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5494f2e0-4e46-4953-b85c-23877387e7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='new_sku'>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df.sort_values('new_sku').plot.bar(x='new_sku',y='Walk_forward_mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "01b98f08-7c27-4f0c-9b37-7a0b18a00b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:xlabel='date'>, <AxesSubplot:xlabel='date'>,\n",
       "       <AxesSubplot:xlabel='date'>, <AxesSubplot:xlabel='date'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "eval_df['date'] = eval_df['month'].astype(str)+'/'+eval_df['year'].astype(str)\n",
    "# exp_train = exp_train.set_index(exp_train['date'])\n",
    "\n",
    "eval_df.sort_values(['year','month']).set_index(eval_df['date']).drop(columns=['month','year']).plot(subplots=True, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2aedede5-a92f-44c1-814a-2e0606d3018a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Walk_forward_mae</th>\n",
       "      <th>train_sku_count</th>\n",
       "      <th>val_sku_count</th>\n",
       "      <th>new_sku</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>57474.059957</td>\n",
       "      <td>1743</td>\n",
       "      <td>1850</td>\n",
       "      <td>481</td>\n",
       "      <td>9/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>90878.891478</td>\n",
       "      <td>2224</td>\n",
       "      <td>1562</td>\n",
       "      <td>228</td>\n",
       "      <td>1/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>81314.899357</td>\n",
       "      <td>2452</td>\n",
       "      <td>1530</td>\n",
       "      <td>168</td>\n",
       "      <td>5/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>78364.233073</td>\n",
       "      <td>2620</td>\n",
       "      <td>1213</td>\n",
       "      <td>101</td>\n",
       "      <td>9/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>113908.782686</td>\n",
       "      <td>2721</td>\n",
       "      <td>1040</td>\n",
       "      <td>104</td>\n",
       "      <td>1/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>65319.875505</td>\n",
       "      <td>2825</td>\n",
       "      <td>885</td>\n",
       "      <td>46</td>\n",
       "      <td>5/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>59185.234112</td>\n",
       "      <td>2871</td>\n",
       "      <td>1050</td>\n",
       "      <td>91</td>\n",
       "      <td>9/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>81508.232727</td>\n",
       "      <td>2962</td>\n",
       "      <td>1025</td>\n",
       "      <td>114</td>\n",
       "      <td>1/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>66541.421563</td>\n",
       "      <td>3076</td>\n",
       "      <td>968</td>\n",
       "      <td>67</td>\n",
       "      <td>5/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>70842.699839</td>\n",
       "      <td>3143</td>\n",
       "      <td>964</td>\n",
       "      <td>143</td>\n",
       "      <td>9/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>82550.720643</td>\n",
       "      <td>3286</td>\n",
       "      <td>1086</td>\n",
       "      <td>346</td>\n",
       "      <td>1/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>81535.831417</td>\n",
       "      <td>3632</td>\n",
       "      <td>784</td>\n",
       "      <td>112</td>\n",
       "      <td>5/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>101800.448817</td>\n",
       "      <td>3744</td>\n",
       "      <td>860</td>\n",
       "      <td>114</td>\n",
       "      <td>9/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  year  Walk_forward_mae  train_sku_count  val_sku_count  new_sku  \\\n",
       "0       9  2016      57474.059957             1743           1850      481   \n",
       "1       1  2017      90878.891478             2224           1562      228   \n",
       "2       5  2017      81314.899357             2452           1530      168   \n",
       "3       9  2017      78364.233073             2620           1213      101   \n",
       "4       1  2018     113908.782686             2721           1040      104   \n",
       "5       5  2018      65319.875505             2825            885       46   \n",
       "6       9  2018      59185.234112             2871           1050       91   \n",
       "7       1  2019      81508.232727             2962           1025      114   \n",
       "8       5  2019      66541.421563             3076            968       67   \n",
       "9       9  2019      70842.699839             3143            964      143   \n",
       "10      1  2021      82550.720643             3286           1086      346   \n",
       "11      5  2021      81535.831417             3632            784      112   \n",
       "12      9  2021     101800.448817             3744            860      114   \n",
       "\n",
       "      date  \n",
       "0   9/2016  \n",
       "1   1/2017  \n",
       "2   5/2017  \n",
       "3   9/2017  \n",
       "4   1/2018  \n",
       "5   5/2018  \n",
       "6   9/2018  \n",
       "7   1/2019  \n",
       "8   5/2019  \n",
       "9   9/2019  \n",
       "10  1/2021  \n",
       "11  5/2021  \n",
       "12  9/2021  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7e338",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "135517e3",
   "metadata": {
    "id": "6cdpG2ZoV1ig"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "\n",
    "TRAIN_DIR = f'{DATA_DIR}/train'\n",
    "TEST_DIR = f'{DATA_DIR}/test'\n",
    "\n",
    "PLOTS_DIR = f'{DATA_DIR}/plots'\n",
    "\n",
    "OUTPUT_DIR = f'{DATA_DIR}/output'\n",
    "MODEL_CHECKPOINT_DIR = f'{DATA_DIR}/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "214f3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "test = pd.read_csv(f'{TEST_DIR}/Test.csv')\n",
    "context = pd.read_csv(f'{OUTPUT_DIR}/context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46dc6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil.inference import prepare_test_context\n",
    "from fossil.config import ModelsConfig\n",
    "from fossil.preprocessing import FossilPreprocessor, LabelEncoder\n",
    "\n",
    "np.random.seed(ModelsConfig.SEED)\n",
    "sku_encoder = LabelEncoder(save_path=f'{OUTPUT_DIR}/sku_dict.pkl')\n",
    "\n",
    "\n",
    "fossil_preproc = FossilPreprocessor(sku_encoder)\n",
    "test_context, test_dates = prepare_test_context(context, test, fossil_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21fd8c49",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d7f451b801467481cf1d977e15220c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7518d69d34c349ff9b852b507df01bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453165e709e54ad2a9a572a18ed808d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a0b04306344fbdab79cc0a5ecefbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n",
      "C:\\Users\\nelso\\OneDrive\\Documents\\Misc\\Fossil\\implementation\\Round 2\\fossil\\preprocessing.py:181: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_{period}month_MM'] = group.transform(lambda x: x.rolling(period).median())\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcc6c27623c47ef96a47f4beddc2ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d98f184bf943b186373b321a3a0f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_cols = [c for c in test_context.columns if c not in ['sku_name', 'month', 'year']\n",
    "             and all(l not in c for l in ['target', 'channel','rel'])]\n",
    "\n",
    "dates = fossil_preproc.sort_dates(test_context)\n",
    "test_data = fossil_preproc.prepare_primary_data(test_context, dates, True, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8259bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa13522f49040ad9552fb5686c39198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2b74ba910d49de9e53abb9b9b64c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = fossil_preproc.impute_missing(test_context, True, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6ad23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[test_data[['month', 'year']].apply(tuple, axis=1).isin(test_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9e23d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [f'target_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "pred_cols = [f'preds_{i}' for i in range(ModelsConfig.N_STEPS)]\n",
    "\n",
    "principal_features = fossil_preproc.load_saved_items(f'{OUTPUT_DIR}/principal_features.pkl')\n",
    "cols = principal_features+['month','year']\n",
    "\n",
    "non_features = ['sku_name','sku_coded']+target_cols\n",
    "feature_cols = [c for c in test_data.columns if c not in non_features and c in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d339224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fossil.models.gbdt import FossilGBDT\n",
    "# gbdt_models = FossilGBDT()\n",
    "\n",
    "# cv_models = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddd7e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil.inference import make_predictions\n",
    "\n",
    "sub_df = make_predictions(test, test_data, feature_cols, target_cols, pred_cols, cv_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2808e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_name = f'{OUTPUT_DIR}/fossil_{ModelsConfig.BASE_MODEL}_{ModelsConfig.META_LEARNER}_{secondary_val_mae}.csv'\n",
    "# sub_df[['Item_ID','Target']].to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c052629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = f'{OUTPUT_DIR}/fossil_blended_{blended_mae}.csv'\n",
    "sub_df[sub_df['time_step']==3][['Item_ID','Target']].to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da384b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "      <th>Target</th>\n",
       "      <th>Item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68466.153822</td>\n",
       "      <td>3</td>\n",
       "      <td>113753.488072</td>\n",
       "      <td>ABEAHAMASHL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABEENNEARMAZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>42546.0</td>\n",
       "      <td>152963.0</td>\n",
       "      <td>58754.0</td>\n",
       "      <td>35455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>600709.0</td>\n",
       "      <td>68884.0</td>\n",
       "      <td>106365.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>106618.154844</td>\n",
       "      <td>3</td>\n",
       "      <td>129210.452511</td>\n",
       "      <td>ABEENNEARMAZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABEETTEABE</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>3352017.0</td>\n",
       "      <td>1211548.0</td>\n",
       "      <td>1095053.0</td>\n",
       "      <td>61793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2452473.0</td>\n",
       "      <td>534357.5</td>\n",
       "      <td>490292.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>857977.897245</td>\n",
       "      <td>3</td>\n",
       "      <td>866790.346150</td>\n",
       "      <td>ABEETTEABE_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ABERTHAKEVAZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>2366368.0</td>\n",
       "      <td>749620.0</td>\n",
       "      <td>729360.0</td>\n",
       "      <td>15195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>633125.0</td>\n",
       "      <td>31909.5</td>\n",
       "      <td>59260.5</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3640.0</td>\n",
       "      <td>152722.423691</td>\n",
       "      <td>3</td>\n",
       "      <td>145051.754819</td>\n",
       "      <td>ABERTHAKEVAZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ABEWARDREYZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>153976.0</td>\n",
       "      <td>47611.0</td>\n",
       "      <td>31403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>633125.0</td>\n",
       "      <td>31909.5</td>\n",
       "      <td>59260.5</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3241.0</td>\n",
       "      <td>76576.441269</td>\n",
       "      <td>3</td>\n",
       "      <td>96179.506677</td>\n",
       "      <td>ABEWARDREYZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>WHITSHIAALBEZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>888401.0</td>\n",
       "      <td>52676.0</td>\n",
       "      <td>13169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>809387.0</td>\n",
       "      <td>14688.5</td>\n",
       "      <td>25325.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>127199.317982</td>\n",
       "      <td>3</td>\n",
       "      <td>161279.340144</td>\n",
       "      <td>WHITSHIAALBEZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>YOSHILSEHOWAZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>246159.0</td>\n",
       "      <td>6078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>633125.0</td>\n",
       "      <td>31909.5</td>\n",
       "      <td>59260.5</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3586.0</td>\n",
       "      <td>63802.508036</td>\n",
       "      <td>3</td>\n",
       "      <td>79745.712803</td>\n",
       "      <td>YOSHILSEHOWAZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>YOSHLEENBART</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1664359.0</td>\n",
       "      <td>111430.0</td>\n",
       "      <td>67871.0</td>\n",
       "      <td>31403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>251224.0</td>\n",
       "      <td>171703.5</td>\n",
       "      <td>141820.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>219712.609461</td>\n",
       "      <td>3</td>\n",
       "      <td>326844.284459</td>\n",
       "      <td>YOSHLEENBART_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1527604.0</td>\n",
       "      <td>288705.0</td>\n",
       "      <td>199561.0</td>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>211717.0</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>345479.449555</td>\n",
       "      <td>3</td>\n",
       "      <td>361741.691253</td>\n",
       "      <td>YOSHRENECARL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>176136.846386</td>\n",
       "      <td>3</td>\n",
       "      <td>210243.214620</td>\n",
       "      <td>YOSHTLYNYOSHZZ_2_2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month  year  starting_inventory     sellin  \\\n",
       "3        ABEAHAMASHL      2  2022            410265.0    18234.0   \n",
       "7      ABEENNEARMAZZ      2  2022             42546.0   152963.0   \n",
       "11        ABEETTEABE      2  2022           3352017.0  1211548.0   \n",
       "15     ABERTHAKEVAZZ      2  2022           2366368.0   749620.0   \n",
       "19      ABEWARDREYZZ      2  2022            153976.0    47611.0   \n",
       "...              ...    ...   ...                 ...        ...   \n",
       "1479  WHITSHIAALBEZZ      2  2022            888401.0    52676.0   \n",
       "1483  YOSHILSEHOWAZZ      2  2022            246159.0     6078.0   \n",
       "1487    YOSHLEENBART      2  2022           1664359.0   111430.0   \n",
       "1491    YOSHRENECARL      2  2022           1527604.0   288705.0   \n",
       "1495  YOSHTLYNYOSHZZ      2  2022            156002.0   163093.0   \n",
       "\n",
       "      sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "3                  0.0               0.0               0.0            1013.0   \n",
       "7              58754.0           35455.0               0.0               0.0   \n",
       "11           1095053.0           61793.0               0.0               0.0   \n",
       "15            729360.0           15195.0               0.0               0.0   \n",
       "19             31403.0               0.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "1479           13169.0               0.0               0.0               0.0   \n",
       "1483               0.0               0.0               0.0               0.0   \n",
       "1487           67871.0           31403.0               0.0               0.0   \n",
       "1491          199561.0           79014.0               0.0               0.0   \n",
       "1495          122573.0           30390.0               0.0               0.0   \n",
       "\n",
       "      sellin_channel_5  ...  onhand_inventory_9month_MM  \\\n",
       "3                  0.0  ...                    291744.0   \n",
       "7                  0.0  ...                    600709.0   \n",
       "11                 0.0  ...                   2452473.0   \n",
       "15                 0.0  ...                    633125.0   \n",
       "19                 0.0  ...                    633125.0   \n",
       "...                ...  ...                         ...   \n",
       "1479               0.0  ...                    809387.0   \n",
       "1483               0.0  ...                    633125.0   \n",
       "1487               0.0  ...                    251224.0   \n",
       "1491               0.0  ...                    793179.0   \n",
       "1495               0.0  ...                    193483.0   \n",
       "\n",
       "      leftover_inventory_6month_MM  leftover_inventory_9month_MM  \\\n",
       "3                         -13675.5                      -16208.0   \n",
       "7                          68884.0                      106365.0   \n",
       "11                        534357.5                      490292.0   \n",
       "15                         31909.5                       59260.5   \n",
       "19                         31909.5                       59260.5   \n",
       "...                            ...                           ...   \n",
       "1479                       14688.5                       25325.0   \n",
       "1483                       31909.5                       59260.5   \n",
       "1487                      171703.5                      141820.0   \n",
       "1491                      211717.0                      214756.0   \n",
       "1495                      180820.5                      200574.0   \n",
       "\n",
       "      price_6month_MM  price_9month_MM  sku_coded          preds  time_step  \\\n",
       "3               149.0            149.0       74.0   68466.153822          3   \n",
       "7               129.0            129.0      633.0  106618.154844          3   \n",
       "11              159.0            159.0      789.0  857977.897245          3   \n",
       "15              135.0            135.0     3640.0  152722.423691          3   \n",
       "19              135.0            135.0     3241.0   76576.441269          3   \n",
       "...               ...              ...        ...            ...        ...   \n",
       "1479            169.0            169.0     1422.0  127199.317982          3   \n",
       "1483            135.0            135.0     3586.0   63802.508036          3   \n",
       "1487            129.0            129.0      725.0  219712.609461          3   \n",
       "1491            129.0            129.0      248.0  345479.449555          3   \n",
       "1495            149.0            149.0     1852.0  176136.846386          3   \n",
       "\n",
       "             Target                Item_ID  \n",
       "3     113753.488072     ABEAHAMASHL_2_2022  \n",
       "7     129210.452511   ABEENNEARMAZZ_2_2022  \n",
       "11    866790.346150      ABEETTEABE_2_2022  \n",
       "15    145051.754819   ABERTHAKEVAZZ_2_2022  \n",
       "19     96179.506677    ABEWARDREYZZ_2_2022  \n",
       "...             ...                    ...  \n",
       "1479  161279.340144  WHITSHIAALBEZZ_2_2022  \n",
       "1483   79745.712803  YOSHILSEHOWAZZ_2_2022  \n",
       "1487  326844.284459    YOSHLEENBART_2_2022  \n",
       "1491  361741.691253    YOSHRENECARL_2_2022  \n",
       "1495  210243.214620  YOSHTLYNYOSHZZ_2_2022  \n",
       "\n",
       "[382 rows x 77 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[sub_df['time_step']==3].sort_values(['sku_name','year','month'])#[['month','year','pred_month','pred_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90f9bd51-9f5e-4a1c-b880-2b2871bb9b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "      <th>Target</th>\n",
       "      <th>Item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64061.189814</td>\n",
       "      <td>3</td>\n",
       "      <td>87739.876614</td>\n",
       "      <td>ABEAHAMASHL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABEENNEARMAZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>42546.0</td>\n",
       "      <td>152963.0</td>\n",
       "      <td>58754.0</td>\n",
       "      <td>35455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>600709.0</td>\n",
       "      <td>68884.0</td>\n",
       "      <td>106365.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>73715.354114</td>\n",
       "      <td>3</td>\n",
       "      <td>86970.214678</td>\n",
       "      <td>ABEENNEARMAZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABEETTEABE</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>3352017.0</td>\n",
       "      <td>1211548.0</td>\n",
       "      <td>1095053.0</td>\n",
       "      <td>61793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2452473.0</td>\n",
       "      <td>534357.5</td>\n",
       "      <td>490292.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>713315.822861</td>\n",
       "      <td>3</td>\n",
       "      <td>588224.038332</td>\n",
       "      <td>ABEETTEABE_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ABERTHAKEVAZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>2366368.0</td>\n",
       "      <td>749620.0</td>\n",
       "      <td>729360.0</td>\n",
       "      <td>15195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>621475.5</td>\n",
       "      <td>28364.0</td>\n",
       "      <td>49637.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3640.0</td>\n",
       "      <td>106270.258608</td>\n",
       "      <td>3</td>\n",
       "      <td>106138.805276</td>\n",
       "      <td>ABERTHAKEVAZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ABEWARDREYZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>153976.0</td>\n",
       "      <td>47611.0</td>\n",
       "      <td>31403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>621475.5</td>\n",
       "      <td>28364.0</td>\n",
       "      <td>49637.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3241.0</td>\n",
       "      <td>52147.223107</td>\n",
       "      <td>3</td>\n",
       "      <td>61330.631241</td>\n",
       "      <td>ABEWARDREYZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>WHITSHIAALBEZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>888401.0</td>\n",
       "      <td>52676.0</td>\n",
       "      <td>13169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>809387.0</td>\n",
       "      <td>14688.5</td>\n",
       "      <td>25325.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>86019.201900</td>\n",
       "      <td>3</td>\n",
       "      <td>105930.560681</td>\n",
       "      <td>WHITSHIAALBEZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>YOSHILSEHOWAZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>246159.0</td>\n",
       "      <td>6078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>621475.5</td>\n",
       "      <td>28364.0</td>\n",
       "      <td>49637.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3586.0</td>\n",
       "      <td>49965.981924</td>\n",
       "      <td>3</td>\n",
       "      <td>50497.404207</td>\n",
       "      <td>YOSHILSEHOWAZZ_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>YOSHLEENBART</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1664359.0</td>\n",
       "      <td>111430.0</td>\n",
       "      <td>67871.0</td>\n",
       "      <td>31403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>251224.0</td>\n",
       "      <td>171703.5</td>\n",
       "      <td>141820.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>178213.334488</td>\n",
       "      <td>3</td>\n",
       "      <td>201740.085247</td>\n",
       "      <td>YOSHLEENBART_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1527604.0</td>\n",
       "      <td>288705.0</td>\n",
       "      <td>199561.0</td>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>211717.0</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>221611.377967</td>\n",
       "      <td>3</td>\n",
       "      <td>220856.688688</td>\n",
       "      <td>YOSHRENECARL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>152147.152451</td>\n",
       "      <td>3</td>\n",
       "      <td>169123.474859</td>\n",
       "      <td>YOSHTLYNYOSHZZ_2_2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month  year  starting_inventory     sellin  \\\n",
       "3        ABEAHAMASHL      2  2022            410265.0    18234.0   \n",
       "7      ABEENNEARMAZZ      2  2022             42546.0   152963.0   \n",
       "11        ABEETTEABE      2  2022           3352017.0  1211548.0   \n",
       "15     ABERTHAKEVAZZ      2  2022           2366368.0   749620.0   \n",
       "19      ABEWARDREYZZ      2  2022            153976.0    47611.0   \n",
       "...              ...    ...   ...                 ...        ...   \n",
       "1479  WHITSHIAALBEZZ      2  2022            888401.0    52676.0   \n",
       "1483  YOSHILSEHOWAZZ      2  2022            246159.0     6078.0   \n",
       "1487    YOSHLEENBART      2  2022           1664359.0   111430.0   \n",
       "1491    YOSHRENECARL      2  2022           1527604.0   288705.0   \n",
       "1495  YOSHTLYNYOSHZZ      2  2022            156002.0   163093.0   \n",
       "\n",
       "      sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "3                  0.0               0.0               0.0            1013.0   \n",
       "7              58754.0           35455.0               0.0               0.0   \n",
       "11           1095053.0           61793.0               0.0               0.0   \n",
       "15            729360.0           15195.0               0.0               0.0   \n",
       "19             31403.0               0.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "1479           13169.0               0.0               0.0               0.0   \n",
       "1483               0.0               0.0               0.0               0.0   \n",
       "1487           67871.0           31403.0               0.0               0.0   \n",
       "1491          199561.0           79014.0               0.0               0.0   \n",
       "1495          122573.0           30390.0               0.0               0.0   \n",
       "\n",
       "      sellin_channel_5  ...  onhand_inventory_9month_MM  \\\n",
       "3                  0.0  ...                    291744.0   \n",
       "7                  0.0  ...                    600709.0   \n",
       "11                 0.0  ...                   2452473.0   \n",
       "15                 0.0  ...                    621475.5   \n",
       "19                 0.0  ...                    621475.5   \n",
       "...                ...  ...                         ...   \n",
       "1479               0.0  ...                    809387.0   \n",
       "1483               0.0  ...                    621475.5   \n",
       "1487               0.0  ...                    251224.0   \n",
       "1491               0.0  ...                    793179.0   \n",
       "1495               0.0  ...                    193483.0   \n",
       "\n",
       "      leftover_inventory_6month_MM  leftover_inventory_9month_MM  \\\n",
       "3                         -13675.5                      -16208.0   \n",
       "7                          68884.0                      106365.0   \n",
       "11                        534357.5                      490292.0   \n",
       "15                         28364.0                       49637.0   \n",
       "19                         28364.0                       49637.0   \n",
       "...                            ...                           ...   \n",
       "1479                       14688.5                       25325.0   \n",
       "1483                       28364.0                       49637.0   \n",
       "1487                      171703.5                      141820.0   \n",
       "1491                      211717.0                      214756.0   \n",
       "1495                      180820.5                      200574.0   \n",
       "\n",
       "      price_6month_MM  price_9month_MM  sku_coded          preds  time_step  \\\n",
       "3               149.0            149.0       74.0   64061.189814          3   \n",
       "7               129.0            129.0      633.0   73715.354114          3   \n",
       "11              159.0            159.0      789.0  713315.822861          3   \n",
       "15              135.0            135.0     3640.0  106270.258608          3   \n",
       "19              135.0            135.0     3241.0   52147.223107          3   \n",
       "...               ...              ...        ...            ...        ...   \n",
       "1479            169.0            169.0     1422.0   86019.201900          3   \n",
       "1483            135.0            135.0     3586.0   49965.981924          3   \n",
       "1487            129.0            129.0      725.0  178213.334488          3   \n",
       "1491            129.0            129.0      248.0  221611.377967          3   \n",
       "1495            149.0            149.0     1852.0  152147.152451          3   \n",
       "\n",
       "             Target                Item_ID  \n",
       "3      87739.876614     ABEAHAMASHL_2_2022  \n",
       "7      86970.214678   ABEENNEARMAZZ_2_2022  \n",
       "11    588224.038332      ABEETTEABE_2_2022  \n",
       "15    106138.805276   ABERTHAKEVAZZ_2_2022  \n",
       "19     61330.631241    ABEWARDREYZZ_2_2022  \n",
       "...             ...                    ...  \n",
       "1479  105930.560681  WHITSHIAALBEZZ_2_2022  \n",
       "1483   50497.404207  YOSHILSEHOWAZZ_2_2022  \n",
       "1487  201740.085247    YOSHLEENBART_2_2022  \n",
       "1491  220856.688688    YOSHRENECARL_2_2022  \n",
       "1495  169123.474859  YOSHTLYNYOSHZZ_2_2022  \n",
       "\n",
       "[382 rows x 77 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[sub_df['time_step']==3].sort_values(['sku_name','year','month'])#[['month','year','pred_month','pred_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "821fcdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>starting_inventory</th>\n",
       "      <th>sellin</th>\n",
       "      <th>sellin_channel_1</th>\n",
       "      <th>sellin_channel_2</th>\n",
       "      <th>sellin_channel_3</th>\n",
       "      <th>sellin_channel_4</th>\n",
       "      <th>sellin_channel_5</th>\n",
       "      <th>...</th>\n",
       "      <th>onhand_inventory_9month_MM</th>\n",
       "      <th>leftover_inventory_6month_MM</th>\n",
       "      <th>leftover_inventory_9month_MM</th>\n",
       "      <th>price_6month_MM</th>\n",
       "      <th>price_9month_MM</th>\n",
       "      <th>sku_coded</th>\n",
       "      <th>preds</th>\n",
       "      <th>time_step</th>\n",
       "      <th>Target</th>\n",
       "      <th>Item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>35072.725079</td>\n",
       "      <td>0</td>\n",
       "      <td>47640.930020</td>\n",
       "      <td>ABEAHAMASHL_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>44672.654183</td>\n",
       "      <td>1</td>\n",
       "      <td>77943.376682</td>\n",
       "      <td>ABEAHAMASHL_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>43210.416403</td>\n",
       "      <td>2</td>\n",
       "      <td>87058.224649</td>\n",
       "      <td>ABEAHAMASHL_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEAHAMASHL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>410265.0</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>291744.0</td>\n",
       "      <td>-13675.5</td>\n",
       "      <td>-16208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>56187.085045</td>\n",
       "      <td>3</td>\n",
       "      <td>79939.259651</td>\n",
       "      <td>ABEAHAMASHL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEENNEARMAZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>42546.0</td>\n",
       "      <td>152963.0</td>\n",
       "      <td>58754.0</td>\n",
       "      <td>35455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>600709.0</td>\n",
       "      <td>68884.0</td>\n",
       "      <td>106365.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>159290.384286</td>\n",
       "      <td>0</td>\n",
       "      <td>203265.296056</td>\n",
       "      <td>ABEENNEARMAZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>YOSHRENECARL</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>1527604.0</td>\n",
       "      <td>288705.0</td>\n",
       "      <td>199561.0</td>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>793179.0</td>\n",
       "      <td>211717.0</td>\n",
       "      <td>214756.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>207297.427046</td>\n",
       "      <td>3</td>\n",
       "      <td>223475.074890</td>\n",
       "      <td>YOSHRENECARL_2_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>205218.138990</td>\n",
       "      <td>0</td>\n",
       "      <td>220793.851680</td>\n",
       "      <td>YOSHTLYNYOSHZZ_11_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>196515.846253</td>\n",
       "      <td>1</td>\n",
       "      <td>223099.976004</td>\n",
       "      <td>YOSHTLYNYOSHZZ_12_2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>140360.727007</td>\n",
       "      <td>2</td>\n",
       "      <td>189837.577327</td>\n",
       "      <td>YOSHTLYNYOSHZZ_1_2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>YOSHTLYNYOSHZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>156002.0</td>\n",
       "      <td>163093.0</td>\n",
       "      <td>122573.0</td>\n",
       "      <td>30390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193483.0</td>\n",
       "      <td>180820.5</td>\n",
       "      <td>200574.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>154050.194269</td>\n",
       "      <td>3</td>\n",
       "      <td>160543.516043</td>\n",
       "      <td>YOSHTLYNYOSHZZ_2_2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1528 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku_name  month  year  starting_inventory    sellin  \\\n",
       "0        ABEAHAMASHL     11  2021            410265.0   18234.0   \n",
       "1        ABEAHAMASHL     12  2021            410265.0   18234.0   \n",
       "2        ABEAHAMASHL      1  2022            410265.0   18234.0   \n",
       "3        ABEAHAMASHL      2  2022            410265.0   18234.0   \n",
       "4      ABEENNEARMAZZ     11  2021             42546.0  152963.0   \n",
       "...              ...    ...   ...                 ...       ...   \n",
       "1523    YOSHRENECARL      2  2022           1527604.0  288705.0   \n",
       "1524  YOSHTLYNYOSHZZ     11  2021            156002.0  163093.0   \n",
       "1525  YOSHTLYNYOSHZZ     12  2021            156002.0  163093.0   \n",
       "1526  YOSHTLYNYOSHZZ      1  2022            156002.0  163093.0   \n",
       "1527  YOSHTLYNYOSHZZ      2  2022            156002.0  163093.0   \n",
       "\n",
       "      sellin_channel_1  sellin_channel_2  sellin_channel_3  sellin_channel_4  \\\n",
       "0                  0.0               0.0               0.0            1013.0   \n",
       "1                  0.0               0.0               0.0            1013.0   \n",
       "2                  0.0               0.0               0.0            1013.0   \n",
       "3                  0.0               0.0               0.0            1013.0   \n",
       "4              58754.0           35455.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "1523          199561.0           79014.0               0.0               0.0   \n",
       "1524          122573.0           30390.0               0.0               0.0   \n",
       "1525          122573.0           30390.0               0.0               0.0   \n",
       "1526          122573.0           30390.0               0.0               0.0   \n",
       "1527          122573.0           30390.0               0.0               0.0   \n",
       "\n",
       "      sellin_channel_5  ...  onhand_inventory_9month_MM  \\\n",
       "0                  0.0  ...                    291744.0   \n",
       "1                  0.0  ...                    291744.0   \n",
       "2                  0.0  ...                    291744.0   \n",
       "3                  0.0  ...                    291744.0   \n",
       "4                  0.0  ...                    600709.0   \n",
       "...                ...  ...                         ...   \n",
       "1523               0.0  ...                    793179.0   \n",
       "1524               0.0  ...                    193483.0   \n",
       "1525               0.0  ...                    193483.0   \n",
       "1526               0.0  ...                    193483.0   \n",
       "1527               0.0  ...                    193483.0   \n",
       "\n",
       "      leftover_inventory_6month_MM  leftover_inventory_9month_MM  \\\n",
       "0                         -13675.5                      -16208.0   \n",
       "1                         -13675.5                      -16208.0   \n",
       "2                         -13675.5                      -16208.0   \n",
       "3                         -13675.5                      -16208.0   \n",
       "4                          68884.0                      106365.0   \n",
       "...                            ...                           ...   \n",
       "1523                      211717.0                      214756.0   \n",
       "1524                      180820.5                      200574.0   \n",
       "1525                      180820.5                      200574.0   \n",
       "1526                      180820.5                      200574.0   \n",
       "1527                      180820.5                      200574.0   \n",
       "\n",
       "      price_6month_MM  price_9month_MM  sku_coded          preds  time_step  \\\n",
       "0               149.0            149.0       74.0   35072.725079          0   \n",
       "1               149.0            149.0       74.0   44672.654183          1   \n",
       "2               149.0            149.0       74.0   43210.416403          2   \n",
       "3               149.0            149.0       74.0   56187.085045          3   \n",
       "4               129.0            129.0      633.0  159290.384286          0   \n",
       "...               ...              ...        ...            ...        ...   \n",
       "1523            129.0            129.0      248.0  207297.427046          3   \n",
       "1524            149.0            149.0     1852.0  205218.138990          0   \n",
       "1525            149.0            149.0     1852.0  196515.846253          1   \n",
       "1526            149.0            149.0     1852.0  140360.727007          2   \n",
       "1527            149.0            149.0     1852.0  154050.194269          3   \n",
       "\n",
       "             Target                 Item_ID  \n",
       "0      47640.930020     ABEAHAMASHL_11_2021  \n",
       "1      77943.376682     ABEAHAMASHL_12_2021  \n",
       "2      87058.224649      ABEAHAMASHL_1_2022  \n",
       "3      79939.259651      ABEAHAMASHL_2_2022  \n",
       "4     203265.296056   ABEENNEARMAZZ_11_2021  \n",
       "...             ...                     ...  \n",
       "1523  223475.074890     YOSHRENECARL_2_2022  \n",
       "1524  220793.851680  YOSHTLYNYOSHZZ_11_2021  \n",
       "1525  223099.976004  YOSHTLYNYOSHZZ_12_2021  \n",
       "1526  189837.577327   YOSHTLYNYOSHZZ_1_2022  \n",
       "1527  160543.516043   YOSHTLYNYOSHZZ_2_2022  \n",
       "\n",
       "[1528 rows x 83 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df#[['month','year','pred_month','pred_year']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbf680ab0d041687579e828cab4fb9db153ba8213f014eb51fcd37111a0cbbcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
